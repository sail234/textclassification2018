计算机 研究 与 发展 JOURNALOFCOMPUTERRESEARCHANDDEVELOPMENT 年 第卷 第期 VolNo 一种 基于 等价 的 联盟 演化 机制 徐晋晖 　 石 纯一 摘要 　 联盟 是 多 Agent 之间 一种 重要 的 合作 方法 多数 方法 没有 考虑 联盟 的 演化 问题 ， 难以避免 大量 的 计算 ； 而且 对于 联盟 值 是 已知 的 假设 也 是 不 实际 的 文中 给出 了 联盟 问题 的 等价 性 和 相应 的 联盟 演化 机制 ， 不 通过 对 联盟 值 预先 计算 ， 可 求得 联盟 问题 的 解 ， 可以 降低 计算 复杂度 与 ShehoryKraus 的 工作 相比 引入 了 联盟 的 等价 和 演化 ， 放松 了 对 联盟 值 已知 的 假设 限制 关键词 　 联盟 ， 联盟 值 ， 等价 ， 演化 中图法 分类号 　 TPAMECHANISMOFCOALITIONEVOLVEMENTBASEDONEQUIVALENCEXUJinHuiandSHIChunYiDepartmentofComputerScienceTsinghuaUniversityBeijing 　 Abstract 　 CoalitionisanimportantcooperativemethodinmultiagentsystemsMostofthemethodsdontconsiderevolvementofcoalitionsoitisdifficulttoavoidamassofcomputationandassumptionaboutcoalitionvalueknownisntrealisticInthepaperhereequivalenceofcoalitionandmechanismofevolvementarepresentedwhichcanobtainsolutionofcoalitionbynoncomputingofcoalitionvalueandmayreducecomputationalcomplexityTheworkofthepaperintroducesequivalenceandevolvementofcoalitionandreleasesrestrictionofassumptionaboutcoalitionvalueknowncomparedwiththeworkofShehoryKrausKeywords 　 coalitioncoalitionvalueequivalenceevolvement 　 引 　 　 言 　 　 自年 文献 ［ ］ 到 文献 ［ ］ 提出 联盟 方法 以来 ， 已 取得 了 一定 的 进展 通过 联盟 可以 提高 Agent 求解 问题 的 能力 ， 获得 更 多 的 报酬 ， 因而 联盟 是 多 Agent 系统 MAS 的 重要 合作 方法 　 问题 的 描述 　 　 设 Agent 集 NAA … An ， 资源 集 Qqq … qn ， 其中 qiqiqi … qkii ， qji 表示 Ai 第 j 种 资源 的 数量 ； 任务 集 TTT … Tn ， 其中 Tititi … tmii 是 Ai 的 任务 集 ， tji 是 Ai 的 第 j 个 任务 ， 对 每 一个 任务 有 对应 的 资源 需求 说明 ； 每 一个 Agent 开始 都 持有 一定 的 资源 　 　 MAS 的 合作 是 如何 在 Agent 之间 进行 资源 和 任务 的 重组 ， 使得 每 一个 Agent 既能 完成 任务 ， 又 能 节省 资源 取得 满意 的 报酬 ？ 这 可 通过 联盟 方法 来 完成 　 　 一个 联盟 C 可以 用 〈 NcqcQ ′ cTcT ′ cVcUc 〉 来 描述 ， 其中 Nc 是 N 的 子集 ， qc 是 C 拥有 的 资源 ， Q ′ c 是 资源分配 的 结果 ， Tc 是 C 的 任务 集合 ， T ′ c 是 任务分配 的 结果 ， Vc 是 联盟 的 值 ， Ucu … uc 是 Vc 对 C 成员 的 一个 分配 　 　 联盟 问题 是 求 一个 满足 稳定性 要求 的 UCS ， UCS 为 问题 求解 的 一个 中间状态 或 最后 结果 ， 其中 联盟 结构 CSCC … Cp 是 N 的 一个 划分 ， Uuu … un 是 每个 Agent 所得 报酬 的 描述 　 　 函数 V 是 N → R 的 映射 ， 如果 对 N 的 子集 S ， T ， 当 S ∩ T φ ， 有 VS ∪ T ≥ VSVT ， 称 V 满足 超加性 ， 否则 VS ∪ TVSVT ， 称 V 满足 次加性 ； 在 超加 情况 下 所有 的 Agent 应 组成 一个 大 联盟 ， 最后 的 CSN ； 相反 在 次加 情况 下应互 不结盟 ， 最后 的 CSAA … An 通常 以 Agent 通过 联盟 合作 带来 的 额外 效用 作为 联盟 的 值 ， 一般 有 VAi 　 联盟 的 形成 过程 　 　 联盟 的 形成 过程 ： ① 联盟 结构 CS 的 产生 ； ② 求解 联盟 值 ， 将 联盟 结构 每 一个 可能 的 联盟 的 资源 和 任务 进行 组合 分配 ， 求得 相应 的 联盟 值 ； ③ 将 联盟 值 在 成员 之间 进行 分配 ， 求得 一个 稳定 的 U 这步 是 互相 交互 的 ， 需 不断 反复 求得 一个 符合 稳定性 要求 的 UCS 　 　 作为 一种 联盟 方法 应 满足 最小 性质 要求 ： 　 　 方法 的 有效性 指 通过 联盟 带来 的 额外 效用 不 应该 比 形成 联盟 所 需 的 通信 和 计算资源 开销 小 ； 　 　 结果 的 稳定性 有 个人 、 群体 、 联盟 种 理性 要求 ， 即 ① 个人 理性 公式 ui ≥ VAi ② 群体 理性 公式 是 对于 ， 有 ∑ Ai ∈ SuiVS ， 有 的 文章 中 公式 是 ∑ Ai ∈ NuiVN ， 这 只 对 超加性 适用 ， ③ 联盟 理性 公式 是 ， 对于 ， 有且 ∑ Ai ∈ Tui ≥ VT ， 这 是 强 理性 要求 ， 往往 难以 保证 　 　 计算 的 分布 性 计算 和 通信 的 分布 ， 防止 通信 瓶颈 和 瘫痪 点 现象 的 发生 　 　 过程 的 简单 性 要求 得 一个 满意 的 结果 采用 穷尽 所有 可能 的 方案 是 不 现实 的 ， 因为 这是 一个 NP 问题 　 　 有 的 文章 中 也 提到 对称性 ［ ］ ， 非减 性 ［ ］ 等 　 相关 的 工作 分析 　 　 ShehoryKraus ［ ， ， ］ ZlotkinRosenschein ［ ］ Ketchpel ［ ， ］ 和 SandholmLesser ［ ， ］ 的 工作 没有 考虑 联盟 的 演化 ， 每当 新 的 任务 加入 任务 集时 ， 需要 依 形成 算法 重新 结盟 ， 而 当 任务 求解 完成 后 ， 联盟 解体 ， 这样 势必 有 大量 的 计算 和 通信 开销 ； 并且 所有 的 方法 均 假定 联盟 的 值 是 预先 求得 的 ， 但是 联盟 值 的 预先 计算 是 困难 的 ， 因为 只有 最后 合作 完成 ， 才能 实际 确定 联盟 的 值 　 　 针对 这些 问题 ， 本文 首先 给出 了 联盟 等价 的 定义 和 相应 的 命题 ， 进而 依 联盟 等价 给出 了 联盟 的 基本 过程 、 匹配 方法 、 调整 策略 等 演化 机制 　 联盟 等价 性 　 　 依 N 人 合作 对策 中 策略 等价 ， 引入 联盟 问题 的 等价 性 对策 论中 　 　 对策 Nv 与 Nu 称为 策略 等价 的 ， 如果 存在 正数 a 及 实数 β β … β n 使 　 　 这里 的 v 和 u 是 联盟 值 函数 ， 并 限定 VAi 　 　 定义 设有 联盟 问题 P 和 P ， 对应 的 联盟 值 函数 是 V 和 V ， 如果 有 正数 a ， 使 那么 称 P 和 P 在 联盟 值 函数 上 等价 　 　 命题 设 P 和 P 在 联盟 值 函数 上 等价 ， 如果 已 求得 P 的 一个 解 UCS ， 那么 aUCS 是 P 的 一个 解 　 　 联盟 问题 是 多解 的 ， 核心 、 核 、 稳定 集等 对策 解是 集合 的 含义 ， 这里 指 Shapley 值 、 核心 、 核 、 稳定 集等 的 一种 命题 从 不同 的 解 定义 来 证明 　 　 例设 N ， 对于 P 有 VVV ， VVV ， V ， 对于 P 有 VVV ， VVV ， V ， 可见 对 ， 有 VSVS ， 那么 P 和 P 在 联盟 值 函数 意义 上 等价 对于 P 求得 Shapley 值 意义 上 的 解是 （ UCS ） ， 并且 解 UCS 恰好 也 在 核心 、 核 和 稳定 集中 可以 验证 （ UCS ） 是 P 在 Shapley 值 意义 上 的 解 ， 同时 属于 P 的 核心 、 核 和 稳定 集中 　 　 寻求 得 等价 联盟 问题 的 解 ， 要 依赖于 联盟 值 函数 的 预先 求得 ， 而 这 是 困难 的 ， 但 可 将 联盟 值 与 任务 代价 联系 起来 讨论 　 　 任务 代价 函数 E 是从 Agent （ 或 联盟 ） 的 任务 集到 实数 集 R 的 映射 　 　 约定 的 联盟 值 是 Agnet 之间 通过 合作 所 带来 的 额外 效益 ， 也 就是 任务 代价 的 降低 对 CN ， 有 VC ∑ i ∈ CETiETC 　 　 这里 Ti 是 Ai 的 任务 集 ， TCUi ∈ CTi 是 联盟 C 的 任务 集 　 　 当 VCaVC 有 ∑ i ∈ CETiETCa （ ∑ i ∈ CETiETC ） a （ ∑ i ∈ CETi ） aETC 　 　 CN 　 　 这里 Ti 是 P 中 Ai 的 任务 集 　 　 定义 设有 联盟 问题 P 和 P ， 如果 存在 正数 a ， 使 ∑ i ∈ CETiETCa （ ∑ i ∈ CETiETC ） a （ ∑ i ∈ CETi ） aETC 　 　 CN 那么 称 P 和 P 在 代价 上 等价 　 　 命题 设 P 和 P 在 代价 上 等价 ， 那么 命题 的 结果 仍 成立 　 　 判断 联盟 问题 代价 等价 是 困难 的 ， 因为 要 对 N 的 所有 子集 进行 比较 ， 但 比 依 联盟 值来 判断 等价 进 了 一步 　 　 为了 方便 ， 我们 限定 ： 如果 对 i ∈ N ， 当 ETiaETi ， 对 CN 有 ETCaETC 成立 ， 这种 限定 称为 E 约束 　 　 命题 设有 联盟 问题 P 和 P ， 满足 E 约束 ， 如果 存在 正数 a ， 使 CTiaCTi 　 　 对 i ∈ N ， 那么 P 和 P 在 代价 上 等价 　 　 这时 ， 就 可以 根据 每个 Ai 的 任务 集 ， 来 判断 联盟 是否 等价 　 　 命题 P 和 P 在 联盟 值上 等价 当且 仅 当 P 和 P 在 代价 上 等价 　 　 如果 两个 联盟 问题 等价 ， 那么 在 已知 一个 联盟 问题 的 解 ， 就 可以 直接 计算 出 另 一个 联盟 问题 的 解 　 联盟 演化 　 　 联盟 演化 与 联盟 历史 有关 ， 令 联盟 历史 联盟 问题 ， 联盟 结果 中 ， 每个 联盟 问题 ， 联盟 结果 称为 联盟 的 一段 历史 ， 这里 联盟 问题 指 HE ε HE ε … HEn ε n ， 其中 HEi ε i 是 对 Ai 的 描述 ， HEi 是 历史 代价 ， 联盟 结果 是 UCS 　 　 ε iHEi ∑ Aj ∈ NHEj 是 等价 匹配 范围 根据 启发式 知识 ， 给 每 一个 Agent 指定 一个 适当 的 范围 提高 匹配 的 成功率 ， 其所失 要 比 通过 联盟 形成 来 求得 一个 结果 所 付出 的 计算 和 通信 的 开销 小 U 中 不 保存 具体 的 数值 ， 而是 一个 比例 ， 且 对 所有 的 C ∈ CS ， 有 ∑ i ∈ Cui ， 这样 只有 最后 合作 求解 完成 ， 才 根据 相应 的 比例 进行 联盟 值 的 分配 　 联盟 演化过程 　 　 步骤 每 一个 Agent 计算 任务 代价 ， 将 结果 通知 其他 的 Agent ； 　 　 步骤 与 保存 的 联盟 历史 进行 等价 匹配 ： ① 如果 匹配 成功 ， 那么 以 成功 匹配 的 历史 的 结果 ， 作为 此时 联盟 问题 的 结果 ； ② 如果 匹配 不 成功 ， 考虑 是否 可以 通过 调整 达到 匹配 ， 否则 调用 已有 的 联盟 形成 方法 ； 　 　 步骤 按 求得 的 UCS 组成 联盟 ， 对 给定 的 任务 进行 合作 求解 ， 并 进行 联盟 值 的 实际 分配 如果 是 通过 联盟 形成 求得 的 结果 ， 将 相应 的 结果 保存 到 联盟 历史 中 　 　 该 过程 可以 在 MAS 环境 下 实现 　 分布式 等价 匹配 　 　 定义 Ai 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 目前 的 任务 代价 Ei 在 ［ a ε iHEia ε iHEi ］ 范围 内 　 　 联盟 C 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 所有 的 联盟 成员 均 以 a 为 参考 与 该 历史 匹配 　 　 联盟 问题 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 CS 中 的 所有 联盟 均 以 a 为 参考 与 该 历史 匹配 　 　 分布式 等价 匹配 过程 ： 　 　 步骤 每 一个 Agent 以 自我 为 起点 ， 计算 目前 的 Ei 与 所有 历史 的 比 a ； 　 　 步骤 对于 每 一段 历史 ， 判断 其 所在 联盟 内 的 其他 成员 是否 以 相应 的 a 为 参考 与 该 历史 匹配 ； 　 　 步骤 将 联盟 内 所有 成员 均 匹配 的 历史 与 相应 的 a ， 通知 其他 的 Agent ； 　 　 步骤 如果 在 所有 的 Agent 之间 存在 一个 相同 的 历史 且 a 也 相同 ， 那么 匹配 成功 　 基于 代价 转移 的 调整 　 　 分布 等价 匹配 步骤 中 ， 虽然 达 不到 完全相同 的 历史 ， 但 如果 存在 这样 的 一段 历史 ， 可以 采用 代价 转移 的 方法 ， 使 趋于 相同 　 　 这样 一段 历史 应 满足 的 条件 是 ： CS 中 只有 一个 联盟 没有 匹配 ， 且 该 联盟 成员数 较 少 ， 且 满足 可 调整 条件 　 　 可 调整 条件 ： ∑ i ∈ CEi ∑ i ∈ Ca × HEi ， 指 虽然 个别 的 可能 不 匹配 ， 整体 是 匹配 的 　 　 每 一个 Agent 计算 相应 的 ai ， 比 a 大者 向 比 a 小者 进行 一定量 的 任务 代价 转移 ， 同时 要 对 相应 的 报酬 也 进行 转移 ， 对于 转移 的 量 在 转移 者 之间 通过 协商 机制 达到 同意 ， 一直 到 出现 匹配 为止 　 　 如果 大多数 Agent 对于 一个 历史 认为 匹配 ， 而 只有 极少数 认为 不 匹配 ， 而且 被 同意 的 Agent 认为 属于 同一 联盟 内 ， 那么 同意 者 可以 要求 不 同意 者 之间 进行 调整 ， 达到 全局 的 一致 ， 这是 启发式 知识 ， 并且 由于 可 调整 条件 保证 了 调整 的 成功 ； 在 调整 中 ， 代价 的 转移 同时 伴随 报酬 的 转移 　 联盟 形成 　 　 在 匹配 不 成功 ， 且 不能 进行 调整 时 ， 需要 调用 已有 的 联盟 形成 方法 来 进行 求解 在 联盟 演化 的 初级阶段 ， 会 经常 使用 联盟 形成 方法 ， 但 随着 联盟 历史 的 积累 ， 匹配 的 成功率 逐步提高 ， 到 一定 时候 可能 会 不 需要 联盟 形成 　 实例 分析 　 　 以 本文 的 例为例 ， 按照 本文 的 方法 ， 如果 已有 P 的 历史 ， 那么 当 遇到 P 时 ， 通过 匹配 可以 发现 P 与 P 等价 ， 此时 可以 直接 得到 P 的 结果 ， 而 不 需 进行 联盟 形成 算法 的 调用 　 结 　 　 语 　 　 联盟 演化 机制 的 主要 计算 是 等价 的 匹配 ， 复杂度 是 Om ， m 是 联盟 历史 的 个数 随着 联盟 历史 的 增多 ， 匹配 的 成功率 提高 ， 但 相应 的 复杂度 增大 ， 并且 要 大量 的 存储空间 来 支持 ， 这是 一对 矛盾 ， 可以 借鉴 CBR 的 有关 方法 　 　 本文 给出 的 演化 机制 适合 于 一般 情形 ， 不 局限于 V 满足 超加性 ， 而已 有 的 联盟 形成 方法 局限于 超加 情形 ； 所 提供 的 一种 不 通过 预先 计算 联盟 值 ， 求解 联盟 问题 解 的 方法 ； 在 匹配 成功 （ 可以 调整 ） 的 情况 下 ， 计算 复杂度 远 低于 现有 的 方法 ， 因为 现有 的 方法 不可避免 要 进行 联盟 值 计算 、 联盟 值 的 分配 ； 在 匹配 不 成功 的 情况 下 ， 仅 比 现有 的 方法 多 匹配 的 计算 　 　 对 每 一个 联盟 问题 ， 在 匹配 不 成功 的 情况 下 ， 如何 通过 合适 的 调整 方法 ， 构造 一个 等价 联盟 问题 ， 省去 调用 联盟 形成 方法 的 连续 演化 ， 是 有待 研究 的 工作 本 课题 得到 国家自然科学基金 项目编号 ， 和 清华大学 研究生院 博士学位 论文 基金 资助 作者简介 ： 徐晋晖 ， 男 ， 年月生 ， 博士 研究生 ， 研究 方向 为 多 Agent 系统 、 联盟 机制 石 纯一 ， 男 ， 年月生 ， 教授 ， 博士生 导师 ， 研究 方向 为 人工智能 应用 基础 作者 单位 ： 清华大学 计算机科学 系 　 北京 　 参考文献 　 　 ZlotkinGRosenscheinJSOnetwomanyCoalitionsinmultiagentsystemsInCastelfranchiCPmullerJEdsFromReactiontoCognitionLectureNotesinArtificialIntelligenceVolBerlinSpringer 　 　 ShehoryOKrausSCoalitionformationamongautonomousagentsStrategiesandcomplexityInCastelfranchiCPmullerJEdsFromReactiontoCognitionLectureNotesinArtificialIntelligenceVolBerlinSpringer ～ 　 　 KetchpelSCoalitionformationamongautonomousagentsInCastelfranchiCPmullerJEdsFromReactiontoCognitionLectureNotesinArtificialIntelligenceVolBerlinSpringer ～ 　 　 ZlotkinG ， RosenscheinJSCoalitioncryptographyandstabilityMechanismsforcoalitionformationintaskorientedInProcAAAISeattle ～ 　 　 罗翊石 纯一 Agent 协作 求解 中 形成 联盟 的 行为 策略 计算机 学报 ， ～ LuoYiShiChunyiThebehaviorstrategytoformcoalitioninagentcooperativeproblemsolvingChineseJournalofComputersinChinese ～ 　 　 ShehoryOKrausSTaskallocationviacoalitionformationamongautonomousagentsInProcIJCAIMontreal ～ 　 　 ShehoryOKrausSAkernelorientedmodelforcoalitionformationingeneralenvironmentsImplementationandresultsInProcAAAIPortland ～ 　 　 KetchpelSFormingcoalitionsinthefaceofuncertainrewardsInProcAAAISeattle ～ 　 　 SandholmTWLesserVRCoalitionformationamongboundedrationalagentsInProcIJCAIMontreal ～ 　 　 SandholmTWLesserVRCoalitionamongcomputationallyboundedagentsArtificialIntelligence ～ 　 　 原稿 收到 日期 ： 修改稿 收到 日期 ：