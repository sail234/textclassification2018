计算机 研究 与 发展 JOURNALOFCOMPUTERRESEARCHANDDEVELOPMENT 年 第卷 第期 VolNo 延迟 离散 Hopfield 型 神经网络 异步 收敛性 邱 深山 　 徐晓飞 　 刘 明珠 　 王亚东 摘 　 要 　 离散 Hopfield 型 神经网络 的 一个 重要 性质 是 异步 运行 方式 下 总能 收敛 到 稳定 态 ； 同步 运行 方式 下 总能 收敛 到 周期 不 超过 的 极限 环 ． 它 是 该 模型 可以 用于 联想 记忆 设计 、 组合 优化 计算 的 理论 基础 ． 文中 给出 了 延迟 离散 Hopfield 型 网络 的 收敛性 定理 ． 在 异步 运行 方式 下 ， 证明 了 对称 连接 权阵 的 收敛性 定理 ， 推广 了 已有 的 离散 Hopfield 型 网络 的 收敛性 结果 给出 了 能量 函数 极大值 点 与 延迟 离散 Hopfield 型 网络 的 稳定 态 的 关系 及 稳定 态 邻域 的 演化 特征 得到 了 能量 函数 收敛 与 异步 运行 时 网络 达到 稳定 的 协调 关系 关键词 　 离散 Hopfield 型 神经网络 ， 延迟 ， 收敛性 ， 稳定 态 中图法 分类号 　 TP ； TPCONVERGENCEOFDISCRETEHOPFIELDTYPENEURALNETWORKSWITHTIMEDELAYINASERIALMODEQIUShenShanXUXiaoFeiandWANGYaDongDepartmentofComputerScienceandEngineeringHarbinInstituteofTechnologyHarbin 　 LIUMingZhuDepartmentofMathematicsHarbinInstituteofTechnologyHarbin 　 Abstract 　 ItisknownthatanimportantpropertyofthediscreteHopfieldtypeneuralnetworkisthatitalwaysconvergestoastablestatewhenoperatinginaserialmodeandtoacycleoflengthatmostwhenoperatinginafullparallelmodelThesepropertiesarethebasisforthepotentialapplicationsofthismodelsuchasassociativememorydevicesandcombinatorialoptimizationConvergencetheoremsofdiscreteHopfieldtypeneuralnetworkswithdelayareobtainedinthepaperUnderaproperassumptionitisprovedthatanydiscreteHopfieldtypeneuralnetworkwithdelaywillconvergetoastablestatewhenoperatingintheserialmodeandoneoftheweightmatricesisasymmetriconeandcangeneralizeconvergencetheoreminearlierworksTheauthorsalsorelatemaximumofmodifiedenergyfunctiontostablestateofneuralnetworkwithdelayandobtainevolutionfeaturesinneighborhoodofstablestateInotherwordsthisnetworkcanconvergetoastablestateafteronetimeintervalAccordantrelationsbetweenconvergenceoftheenergyfunctionandstabilizationcorrespondentnetworkarepresentedintheserialmodeaswellKeywords 　 discreteHopfieldtypeneuralnetworkdelayconvergencestablestate 　 引 　 　 言 　 　 离散 Hopfield 型 网络 是 一种 能够 简单 模拟 人脑 局部 功能 的 大规模 并行处理 网络 ， 在 图像处理 、 模式识别 、 非线性 规划 、 TSP 问题 和 联想 记忆 等 领域 已 得到 了 成功 的 应用 正是 因为 它 的 广泛 应用性 ， 吸引 了 许多 学者 进行 理论 和 应用 的 研究 ， 获得 了 许多 研究成果 ［ ～ ］ ． 然而 ， 延迟 离散 Hopfield 型 网络 的 收敛性 尚属 空白 ． 　 　 在 人工神经网络 中 引入 延迟 ， 早 在 McCullohPitts 模型 提出 之后 就 有人 涉及 到 ， 即 带有 延迟 的 人工神经网络 的 雏形 ． Herz 等 人 在 Heb 学习 规则 中 引入 延迟 对 神经网络 的 性能 颇 有 影响 ［ ］ ． 事实上 ， 引入 延迟 使 网络 的 现在 状态 与 历史 状态 有机 联系 起来 ， 使 网络 的 演化 结果 不仅 与 当前 状态 有关 还 受 历史 状态 的 制约 ， 既 可以 学习 空间 时间 模式 ， 又 可以 引导 神经元 该 如何 进行 下 一步 演化 ． 所以 ， 研究 延迟 人工神经网络 的 系统 理论 不仅 具有 理论意义 ， 更 重要 的 是 它 的 应用 价值 　 　 熟知 离散 Hopfield 型 网络 之所以 能 用于 联想 记忆 、 组合 优化 计算 正是 因为 它 具有 收敛性 ， 即 在 异步 运行 方式 下 总能 收敛 到 稳定 态 ［ ～ ］ ； 同步 运行 方式 下 总 收敛 到 周期 不 超过 的 极限 环 ［ ］ ． 在 异步 运行 方式 下 ， 本文 证明 了 延迟 离散 Hopfield 型 网络 总能 收敛 到 稳定 态 给出 了 能量 函数 的 极大值 点 与 网络 稳定 态 的 关系 ， 得到 了 能量 函数 收敛 与 异步 运行 时 网络 N 达到 稳定 的 协调 关系 　 延迟 离散 Hopfield 型 网络 　 　 n 阶 延迟 离散 Hopfield 型 网络 是 由 n 个 完全 互联 的 神经元 构成 ， 每个 神经元 i 在 任意 时刻 t 拥有 两种 存储状态 ： xitxit ， 其中 xit 表示 对 历史 状态 的 记忆 ， 也就是说 网络 具有 时间 结构 ． 它 可 由 两个 n × n 阶 矩阵 ww 及 一个 n 维 阈值 向量 θ θ θ … ， θ nT 唯一 确定 ， 简记 Nww θ 用 wij 表示 在 当前 状态 神经元 j 与 神经元 i 的 连接 权值 ， 用 wij 表示 在 延迟 状态 神经元 j 与 i 的 连接 权值 ， θ i 为 第 i 个 神经元 的 阈值 神经元 按照 如下 规则 决定 下 一 时刻 的 状态值 ： 　 　 　 　 　 　 　 其中 ： 　 　 所谓 的 异步 运行 方式 （ 定义 ） ， 即 在 任意 时刻 t ≥ ， 网络 N 仅 有 一个 神经元 i 依式 规则 进行 演化 ， 其余 n 个 神经元 的 状态 保持 不变 当 延迟 离散 Hopfield 型 网络 Nww θ 的 延迟 权阵 wOn × n 即为 离散 Hopfield 型 网络 ［ ～ ］ ． 　 相关 概念 　 　 为 描述 方便 ， 首先 引入 如下 符号 ： 用 Bn 表示 每个 分量 仅取 ± 的 n 维 向量 全体 ， Bnvvvv … ， vnTvi ∈ 〈 uv 〉 表示 向量 uv ∈ Bn 的 内积 ， 即 表示 u 与 v 的 Hamming 距离 显然 有 〈 uv 〉 ndHuv ． 用 BHvr 表示 Bn 中 与 v 的 Hamming 距离 不 超过 r 的 向量 全体 ， 即 BHvrudHuv ≤ ruv ∈ Bn ． 　 　 定义 n 阶 延迟 离散 Hopfield 型 网络 Nww θ 的 一个 状态 v ∈ Bn 称为 稳定 状态 （ 或称 不动点 ） 任意 i ≤ i ≤ n 有 ： 　 　 　 　 　 　 　 　 　 　 成立 其中 vvv … ， vnT 　 　 定义 网络 Nww θ ， 任选 vv ∈ Bn 为 初值 ， 任意 时刻 t ≥ 首先 选择 两种 状态 vit 与 vit 不同 的 神经元 i 依式 运行 方式 进行 演化 若全 相同 ， 即 vtvt ， 则 随机 选 一个 神经元 依式 运行 方式 进行 演化 ， 称此 演化 方式 为 异步 运行 方式 ． 　 　 定义 称 Bn 上 二元 向量 函数 EuvuTwuuTwvuT θ 为 网络 Nww θ 的 能量 函数 ， 其中 uvt ， uvt 简记 Et ≡ Evtvt ． 　 　 定义 如果 对于 任意 uv ∈ BHvr ， 均 有 Euv ≥ Euv ， 称 向量 v 为 Euv 的 Hamming 距离 为 r 的 极大值 点若 rn ， 则 称 向量 v 为 Euv 的 最大值 点 类似 可以 定义 Hamming 距离 为 r 的 极小值 点 和 最小值 点 　 　 定义 让 Ω Er 表示 EtEvtvt 的 Hamming 距离 为 r 的 极大值 点 的 集合 Ω N 表示 网络 Nww θ 的 所有 稳定 态 的 集合 ． 如果 Ω Er Ω N 称 Et 为 r 距 正则 能量 函数 ； 若 Ω Er Ω N 称 Et 为 r 距 正规 能量 函数 ； 若 Ω Er Ω N 称 Et 为 r 距 完备 的 能量 函数 ． 特别 当 r 时 ， 分别 简称 为 正则 、 正规 、 完备 的 能量 函数 ［ ］ 　 延迟 离散 Hopfield 型 网络 收敛性 　 　 延迟 离散 Hopfield 型 网络 作为 联想 记忆 、 组合 优化 计算 ， 收敛性 是 决定 网络 联想 记忆 能力 和 优化 计算 可靠性 的 关键因素 ， 也 是 组合 优化 计算 的 理论 根据 ． 当然 ， 人们 颇为 关注 的 问题 是 延迟 网络 在 什么 条件 下 收敛 ， 延迟 项有何 作用 ． 如下 定理 将 回答 这些 问题 ． 　 　 定理 n 阶 延迟 离散 Hopfield 型 网络 Nww θ w 是 n × n 阶 对称 矩阵 ， w 是 n × n 阶 矩阵 且 对角 元素 满足 ： 　 　 　 　 　 　 　 　 　 　 　 　 　 　 则 网络 从 任意 的 初始状态 xx ∈ Bn 异步 方式 运行 ， 总能 收敛 到 一个 稳定 态 ． 　 　 证明 由 定义 引入 能量 函数 Euv ： 其中 uxtvxt θ 为 阈值 向量 θ θ θ … ， θ nT 显然 Et ≡ Extxt 有 上界 ， 即 Et ≤ ninjwijwijni θ i 令 Δ Et ≡ EtEt Δ xit ≡ xitxit 故 Δ EtxTtwxtxTtwxtxTt θ xTtwxtxTwxtxtT θ 　 　 对 任意 时刻 t ≥ ， 异步 运行 方式 下 进行 演化 有 ： Δ Et Δ xitHixtwii Δ xit Δ xitxitwii 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 依 定义 的 异步 运行 方式 首先 证明 不 存在 Δ xit Δ xit ≠ 的 情况 不失 一般性 ， 令 ： 　 　 Δ xi Δ xi 即 ： xxxixixixi 易知 ： Δ xi Δ xi 　 　 Δ xi Δ xi 即 ： xxxixixixi 易知 ： Δ xi Δ xi 由 情况 的 xi 有 ： 　 　 　 　 　 　 　 　 　 　 依 定义 知 ， 下 一步 仍然 演化 第 i 个 神经元 ， 由 xi 有 　 　 　 　 　 　 　 　 　 注意 当 j ≠ i 时 ， xjxjxj 将式 乘 与 式 相加 得 ： wii 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 易知式 与 式 矛盾 同理 可以 证明 情况 ， 当 Δ xi Δ xi 时 也 可 推出 与 式 矛盾 　 　 当 Δ xit Δ xit 时 ， 　 　 　 　 　 　 　 　 　 由 条件 式 ， 知 Δ Et ≥ 　 　 当 Δ xit Δ xjt 时 ， 　 　 　 　 　 　 　 　 　 易知 Δ Et ≥ 　 　 当 Δ xit ± Δ xit 时 ， Δ Et ≡ wii ± Hixt 　 　 　 　 　 　 　 　 　 　 由式 知 Δ Et ≥ 综上所述 易知 ： 当 Δ xit ≠ 或 Δ xit ≠ 时 ， 有 Δ EtEtEt ≥ 由 单调 有 界 原理 知 Et 是 收敛 的 　 　 如下 将 进一步 证明 Et 收敛 时 ， 网络 Nww θ 最终 将 收敛 到 某 一 稳定 态 　 　 由 Et 收敛 ， 即 存在 t 当 t ≥ t 时 ， 有 EtEt 　 　 　 　 　 　 　 　 　 　 　 　 　 若 xtxt 且 对 每 一个 神经元 演化 均 不变 ， 则 xxt 为 网络 N 的 稳定 态 ． 若 xt ≠ xt 即仅 有 一个 神经元 i 满足 xit ≠ xit ， 对 神经元 i 进行 演化 ， 仅 有 （ ） 及 （ ） 两种 可能 情况 使 Δ Et 下 一步 恰好 为 xtxt ， 将 任选 一个 神经元 进行 演化 ， 可能 改变 的 神经元 仅 有 i 且 有 xitxit 和 Δ Et ， 易知 wii ． 否则 ， 若 wii ， 该 神经元 i 不 可能 改变 状态 ， 因为 当 t ≥ t 时 ， Δ EtwiiHixt ≠ 与 （ ） 式 矛盾 为了 证明 方便 ， 不妨 假设 w 的 大于 零 的 主 对角 元素 个数 为 l ． 如下 将 说明 能量 函数 Et 与 N 的 收敛 不 同步 取决于 l 　 　 由 （ ） 式 知 ， 在 t ≥ t 进行 演化 可能 改变 的 神经元 或者 ① xit ≠ xit 或者 ② xitxit 且 wiiHixt ． 对于 ① 最多 需 演化 次 ， 对于 ② 最 多 演化 l ， 其后 重复 ② 的 演化 ll … ． 最多 需次 演化 达到 网络 N 的 某 一 稳定 态 ． 显然 ， 当 w 的 主 对角 元素 均 大于 零时 ， Et 收敛 时 与 N 收敛 到 某 一 稳定 态 最多差 一步 ， 或者 xitxitxit 达到 稳定 态 ， 或者 xitxitxit 达到 稳定 态 ． 　 　 推论 n 阶 延迟 离散 Hopfield 型 网络 Nww θ w 是 n × n 阶 对称 矩阵 ， w 是 n × n 阶 矩阵 且 对角 元素 满足 ： 则 网络 从 任意 的 初始状态 xx ∈ Bn 出发 异步 方式 运行 ， 其 能量 函数 Et 收敛 与 网络 N 的 收敛 的 演化 步 数最多 仅差 一步 　 　 从 定理 证明 的 最后 部分 可 得到 推论 ． 　 　 推论 当 定理 中 w 退化 为 零 矩阵 On × n 时 ， 收敛 条件 wij ≥ ， i … n 此时 的 推论 为 文献 中 的 主要 定理 ， 即 定理 推广 了 文献 中 的 主要 定理 ． 　 　 定理 n 阶 延迟 离散 Hopfield 型 网络 Nww θ ， w 是 n × n 阶 对称 矩阵 ， w 是 n × n 阶 矩阵 且 对角 元素 满足 ： 　 　 　 　 　 　 　 　 　 则 网络 从 任意 的 初始状态 xx ∈ Bn 异步 方式 运行 ， 网络 收敛 到 一个 稳定 态 的 充分 必要条件 是 相应 的 能量 函数 收敛 且 同时 达到 　 　 证明 如下 使用 的 符号 与 定理 的 证明 中 所 使用 的 符号 相同 ， 在 此 略去 说明 ． 对 任意 时刻 t ≥ ， 异步 运行 方式 下 进行 演化 有 ： Δ Et Δ xitHixt σ it 其中 ： 现将 Δ Et 随第 i 个 神经元 在 t ， t ， t 时刻 的 可能 状态 列表 如下 ： 表 　 序号 Δ xit Δ xitxitxitxit Δ Et Δ xitHixt σ itwiiHixtwiiHixt 令 　 　 且 xtxt ≠ xtxt 依式 异步 方式 演化 　 　 且 EtEtEt 依 xt 演化 路径 进行 　 　 如下 证明 ： TT ． 一方面 ， 由 T 的 定义 及表中 当 tt 时 ， xt ≠ xt 等价 于 网络 N 中 的 某 神经元 i 在 表中仅 有 序号 是 或 的 情况 出现 xit ≠ xit 相应 有 即 EtEt ． 由于 t ≥ T 时 ， 有 xtxt 所以 Δ Et Δ Et 故有 T ≥ T 另一方面 ， 由 T 的 定义 知 ： 当 ETET 时 ， 在 表中仅 能 出现 序号 或 两种 情况 否则 ， 若 出现 序号 或 两种 情况 ， 由 异步 运行 规则 知 ， 下 一步 将 出现 序号 或 两种 情况 ， 由式 知 ETET ， 此式 与 T 的 定义 Δ ETETET 矛盾 ． 故从表 序号 或 中知 xT ≠ xT ， 再 由 当 t ≥ T Δ Et 及式 知 ： 当 t ≥ T 时 ， Δ Et 当且 仅 当表中 序号 或 的 结果 出现 ， 所以 xitxiTt ≥ T 故知 T ≥ T 所以 TT ． 从 T 和 T 的 定义 知 T 是 网络 N 经 演化 规则 达到 稳定 态 的 最早 时刻 ， 而 T 恰是 能量 函数 依 网络 N 的 演化 路径 达到 收敛 状态 的 最早 时刻 ， 所以 由 TT 故 它们 同时 达到 ． 　 　 定理 ． n 阶 延迟 离散 Hopfield 型 网络 Nww θ w 是 n × n 阶 对称 矩阵 ， w 是 n × n 阶 矩阵 且 对角 元素 满足 ： 　 　 　 　 　 　 　 　 　 则 v 是 网络 N 的 稳定 态 的 充分 必要条件 是 v 为 其 能量 函数 Euv 的 Hamming 距离 为 的 极大值 点 ． 　 　 定理 的 证明 思想 与 文献 中 定理 iii 的 证明 类似 ， 从略 　 　 推论 ． 已知 定理 的 假设 条件 下则 网络 N 的 能量 函数 是 完备 的 能量 函数 ． 　 　 从 推论 引申 知 ， 延迟 神经网络 N 作为 优化 计算 的 模型 ， 自然 希望 是 r 完备 的 能量 函数 　 　 定理 n 阶 延迟 离散 Hopfield 型 网络 Nww θ ww 是 n × n 阶 矩阵 且 对角 元素 非负 ， 如果 异步 方式 运行 ， 对 任意 可能 的 uv ∈ BHv 依式 的 演化 规则 一步 演化 到 v ， 则 v 一定 是 网络 N 的 稳定 态 ． 　 　 注 ： 定理 中 任意 可能 的 uv ∈ BHv 意味着 u ≠ vv ≠ vu ≠ v 不能 出现 ， 因为 异步 方式 运行 时 vtvt 不同 的 分量 最多为 个 ． 　 　 证明 依式 的 演化 规则 和 定义 ， 对 任意 可能 的 uv ∈ BHv 可 写成 uv Δ uvv Δ v 其中 ： Δ u … ， vk α … ， T Δ v … ， vl β … ， T α β ∈ 　 　 仅 有 如下 种 情况 ： 　 　 ① α β ≤ kl ≤ n 　 　 ② α β ≤ l ≤ n 　 　 ③ α β ≤ k ≤ n 　 　 ④ α β 由 情况 ① 知 ： 由于 一步 演化 到 v ， 所以 有 skvksgnvkHkvkwkkwkk 等价 vkHkvkwkkwkk ≥ 　 　 　 　 　 　 　 　 　 　 　 情况 、 、 同理可知 ： vlHlvl ≥ wll 　 　 　 　 　 　 　 　 　 　 　 　 　 vkHkvk ≥ wkk 　 　 　 　 　 　 　 　 　 　 　 　 对于 任选 的 某 i ： 有 vkHkvk ≥ 　 　 　 　 　 　 　 　 　 　 　 　 由 uv 的 任意性 及 k 或 l 可取 遍到 n ， 所以 从 或式 的 任何 一个 式子 均 可 得到 v 是 N 的 稳定 态 ． 　 　 推论 n 阶 延迟 离散 Hopfield 型 网络 Nww θ w 是 n × n 阶 对称 矩阵 ， w 是 n × n 阶 矩阵 且 对角 元素 非负 ， 如果 异步 运行 方式 ， 满足 如下 条件 之一 ： 　 　 （ ） 对 任意 uv ≠ v ， uv ∈ BHv 一步 收敛 到 v 　 　 （ ） 对 任意 u ≠ vvvuv ∈ BHv 一步 收敛 到 v 　 　 （ ） 对 任意 uvv ≠ vuv ∈ BHv 一步 收敛 到 v 则 v 一定 是 网络 N 的 稳定 态 ． 　 　 其 证明 可 由 定理 证明 中 的 或式 直接 得到 ． 　 　 从 定理 及 推论 易知 ， 在 异步 运行 方式 下 v 是否 为 N 的 稳定 态由 BHv 中 的 点 一步 演化 情况 来 确定 ． 也 可 结合 定理 、 的 结论 来 认识 定理 和 推论 ， 即 演化 的 路径 方向 是 依照 能量 递增 的 趋势 ， BHv 中 可能 构成 的 能量 函数 Euv 值 ， 若 在 异步 运行 方式 下均 一步 演化 到 Evv ， 则 v 是 N 的 稳定 态 ， 当然 亦 是 能量 函数 的 局部 极大值 点 　 结 　 　 论 　 　 本文 给出 了 在 W 为 对称 的 条件 下 异步 运行 的 收敛性 定理 推广 了 Hopfield ［ ］ 的 结果 ． 　 　 本文 引入 与 延迟 离散 Hopfield 型 网络 对应 的 二元 能量 函数 ， 为 延迟 离散 Hopfield 型 网络 可 作为 联想 记忆 设计 、 优化 计算 奠定 了 理论 基础 ． 　 　 分析 了 能量 函数 的 极大值 点 与 网络 N 的 稳定 态 的 对应 关系 ， 给出 了 网络 N 在 稳定 态 邻域 的 演化 特征 ， 即均 可 一步 演化 到 稳定 态 ． 　 　 得到 了 网络 N 异步 运行 时 收敛 到 稳定 态 与 能量 函数 收敛 的 协调 关系 并 给出 了 它们 同步 到达 的 充分 必要条件 ． 本 课题 得到 国家自然科学基金 资助 项目编号 A 作者简介 ： 邱 深山 ， 男 ， 年月生 ， 博士 ， 讲师 ， 主要 研究 神经网络 及其 应用 、 机器 学习 和 小波 分析 徐晓飞 ， 男 ， 年月生 ， 教授 ， 博士生 导师 ， 研究 领域 包括 计算机 集成 制造 、 分布式 数据库 刘 明珠 ， 男 ， 年月生 ， 教授 ， 博士生 导师 ， 主要 从事 延迟 微分方程 数值 解 ， 神经计算 和 小波 分析 王亚东 ， 男 ， 年月生 ， 副教授 ， 主要 研究 领域 为 专家系统 、 机器 学习 、 知识 工程 作者 单位 ； 邱 深山 　 徐晓飞 　 王亚东 　 哈尔滨工业大学 计算机科学 与 工程系 　 哈尔滨 　 　 　 　 　 　 刘 明珠 　 哈尔滨工业大学 数学系 　 哈尔滨 　 参考文献 　 　 张铃 ， 张钹 ， 吴福朝 自 反馈 神经网络 的 椭球 学习 算法 计算机 学报 ～ ZhangLingZhangBoWuFuchaoEllipsoidlearningalgorithmofneuralnetworkswithselffeedbackconnectionsChineseJournalofComputersinChinese ～ 　 　 张军英 ， 许进 ， 保铮 Hopfield 网 的 关 分析 自动化 学报 ， ～ ZhangJunying ， XuJin ， BaoZhengConnectedanalysisforHopfieldnetworksActaAutomaticSinicainChinese ～ 　 　 ZhangXiangsunLiHongfengWangXiaodong ． AstraightforwardmathematicalanalysisfortheHopfieldneuralnetwork ． ActaElectronicaSinica ～ 　 　 BruckJGoodmanJW ． Ageneralizedconvergencetheoremforneuralnetworks ． IEEETransoninformationtheory ， ～ 　 　 HopfieldJJNeuralnetworksandphysicalsystemswithemergentcollectivecomputationalabilitiesProcNatAcadSciUSA ～ 　 　 ZongbinXuGuoqingHuChungpingKwongAsymmetricHopfieldtypenetworksTheoryandapplicationsNeuralNetworks ～ 　 　 HerzAVMLiZvanHemmenJL ． Statisticalmechanicsoftemporalassociationinneuralnetworkswithtransmissiondelays ． PhysRevLett ～ 　 　 GolesE ， FogelmanFPellegrinD ． Decreasingenergyfunctionasatoolforstudyingthresholdnetworks ． DiscreteApplMath ～ 原稿 收到 日期 ： 修改稿 收到 日期 ：