软件 学报 JOURNALOFSOFTWARE 年 第期 No 基于 复杂 特征 的 VN 结构 模板 获取 模型 赵 　 军 　 黄 昌宁 　 　 摘要 　 提出 了 基于 复杂 特征 的 VN 结构 模板 获取 模型 首先 用 统计 决策树 模型 生长 动词 分类 树 然后 用 最小 描述 长度 原则 对 动词 分类 树 剪枝 最后 由 动词 分类 树 推导 出 VN 结构 模板 实验 证明 在 利用 结构 模板 进行 VN 结构 的 识别 时 这种 模型 比 基于 义类 和 极大 似然 估计 原则 的 模型 具有 更 高 的 精确 率 和 召回 率 　 　 关键词 　 自然语言 处理 语料库 复杂 特征 集 统计 决策树 最小 描述 长度 原则 　 　 中图法 分类号 　 TPTheComplexfeaturebasedModelforAcquisitionofVNconstructionStructureTemplatesZHAOJun 　 HUANGChangning 　 　 Abstract 　 InthispaperacomplexfeatureandMDLbasedmodelforacquisitionofVNconstructionstructuretemplatesisputforwardFirstaverbclassificationtreeiscreatedusingstatisticaldecisiontreemodelThenthetreeisprunedbasedonMDLminimumdescriptionlengthprincipleFinallystructuretemplatesarederivedbasedontheverbclassificationtreeTheexperimentsshowthatusingthestructuretemplatesacquiredwiththemodeltorecognizingVNstructurethesystemhasitsadvantagesoverthemodelbasedonthesenseandtheMLEmaximumlikelihoodestimationprincipleinprecisionandrecall 　 　 Keywords 　 Naturallanguageprocessingcorpuscomplexfeaturestatisticaldecisiontreeminimumdescriptionlengthprinciple 　 　 在 汉语 中 动词 V 和 名词 N 的 同现 情况 有 以下 种 ： 偏正结构 VN （ 如 “ 射门 方法 ” ） 、 动宾 结构 VO （ 如 “ 改进 方法 ” ） 和 非法 组合 IC （ 如 “ 包括 ［ 方法 的 改进 ］ ” 中 的 “ 包括 方法 ” ） 本文 把 VO 结构 和 非法 组合 IC 统称 为 ～ VN 结构 正确 地 识别 VN 结构 对于 句法分析 、 信息检索 、 信息 抽取 等 都 是 至关重要 的 其中 一种 重要 的 方法 是 利用 词语 结构 模板 来 识别 VN 结构 例如 对于 “ 射门 方法 ” 、 “ 改进 方法 ” 和 “ 包括 方法 ” 如果 能够 利用 某种 方法 从 训练 语料 中 获得 如下 形式 的 结构 模板 ： Hh “ 方法 ” → VNIh “ 方法 ” → VOJd “ 方法 ” → IC （ 其中 Hh 、 Ih 和 Jd 是 《 同义词 词林 》 ［ ］ （ 以下 简称 《 词林 》 ） 的 义类 代码 ） 则 可以 正确 地 识别 它们 的 结构 　 　 基于 词 的 VN 结构 模板 获取 可以 形式化 地 表示 如下 ： 设有 动词 集合 V ｛ υ υ υ V ｝ 名词 集合 N ｛ nnnN ｝ 给定 观察 数据 Ｏ ｛ υ n υ ∈ Vn ∈ N ｝ 求解 概率模型 p υ n 使 它 能够 解释 观察 数据 O 因为 这种 概率模型 的 参数 数目 众多 （ NV ） 所以 在 参数估计 时 存在 数据 稀疏 问题 　 　 建立 基于 等价 类 的 概率模型 是 解决 数据 稀疏 问题 的 重要 方法 这种 方法 可以 描述 为 ： 在 N 的 划分 PN 和 V 的 划分 PV 之上 对于 c υ ∈ PV 和 cn ∈ PN 求解 概率模型 pc υ cn 进而 υ ∈ PVn ∈ PNp υ npcvcn 集合 的 等价 类 划分 有 两种 方法 ： ① 自动 聚类 ： 从 训练 语料 中 自动 学习 词语 的 等价 类 划分 这种 方法 得到 的 划分 能够 客观 地 反映 真实 文本 但是 聚类 中 同样 存在 数据 稀疏 问题 而且 聚类 算法 复杂 因此 实用性 较差 ［ ］ ； ② 基于 义类 词典 的 划分 方法 简单 适用性 好 但是 义类 词典 是 语义 分类 体系 而 VN 结构 模板 不仅 与 词语 的 语义 特征 有关 还 与 词语 的 句法 特征 有关 因此 基于 义类 词典 的 划分 对于 词语 结构 模板 获取 是 不 充分 的 ［ ］ 　 　 本文 提出 了 基于 动词 复杂 特征 的 VN 结构 模板 获取 模型 该 模型 在 对 集合 进行 划分 的 同时 考虑 了 动词 的 语法 特征 和 语义 特征 优于 单纯 基于 义类 词典 的 模型 ； 与 自动 聚类 方法 相 比较 该 模型 充分利用 复杂 特征 集 的 多种 信息 来 限制 模型 的 求解 空间 实用性 更强 　 基于 复杂 特征 的 VN 结构 模板 获取 模型 　 问题 定义 　 　 一个 动词 和 名词 同现 是 构成 VN 结构 还是 ～ VN 结构 既 与 动词 和 名词 本身 的 语法 和 语义 特征 有关 也 与 该 同现 对 的 上下文 环境 的 语法 和 语义 特征 有关 本文 将 其 本身 的 特征 称为 静态 特征 将 上下文 环境 的 特征 称为 动态 特征 本文 主要 研究 任意 动词 和 特定 名词 n 同 现时 的 结构 在 实验 中 只 考虑 动词 的 静态 特征 它们 有 ： 词 性子 类 SUBV （ 包括 及物动词 υ t 不 及物动词 υ i 等 ） 音节 数 SYL （ 包括 单音节 mon 双 音节 bi 等 ） 义类 词典 《 词林 》 的 大类 SENSEF ～ J 、 中类 SENSEa ～ n 和 SENSE 小类 ～ 以及 动词 的 词形 WORD 等 　 　 基于 复杂 特征 的 VN 结构 模板 获取 模型 可 描述 如下 ： 设有 特定 名词 n 动词 集合 Vn ｛ υ υ υ V ｝ 给定 观察 数据 SVN ～ VN 其中 VN ｛ υ n υ 和 n 构成 VN 结构 υ ∈ Vn ∈ N ｝ ～ VN ｛ υ nv 和 n 不 构成 VN 结构 υ ∈ Vn ∈ N ｝ 其中 动词 v 以 复杂 特征 集 的 形式 表示 如下 ： 其中 fi 为 特征 名 xi 为 特征值 　 　 基于 动词 复杂 特征 的 VN 结构 模板 获取 的 中心思想 是 ： ① 识别 与 结构 相关 的 特征 并 依据 这些 特征 对 动词 集合 Vn 进行 划分 ； ② 基于 动词 的 划分 估计 每个 等价 类中 的 动词 与 n 同现 构成 VN 和 ～ VN 的 概率 其中 的 关键问题 是 等价 类 的 划分 对于 Vn 的 一个 划分 P 应 满足 以下 条件 ： 　 　 ① PVn ； 　 　 　 　 ② c υ Vn ； 　 　 　 　 ③ c υ ic υ j ∈ Pc υ i ∩ c υ j φ ； 　 　 ④ c υ ∈ P 如果 ｜ c υ ｜ ＞ 则 υ ≠ φ 其中 ∪ 表示 复杂 特征 集 的 合一 运算 在 该 划分 上 建立 的 概率模型 既 可以 解释 例子 集 又 可以 对 未 观察 的 动词 和 名词 同现 的 结构 作出 精确 的 判断 本文 利用 统计 决策树 SDTstatisticaldecisiontree 模型 ［ ］ 进行 动词 等价 类 的 划分 一方面 SDT 的 表达能力 强于 N 元 模型 相当于 插值 N 元 模型 ； 另一方面 SDT 模型 的 最大 优势 在于 自动 抽取 相关 特征 的 能力 　 用 SDT 模型 生长 动词 分类 树 　 用 SDT 表示 动词 分类 树 　 　 SDT 是 一个 决策 机制 它 根据 一系列 特征 赋予 每 一种 可能 的 选择 一个 概率 值 pfh 其中 h 表示 一系列 特征 f 为 当前 作出 的 选择 概率 值 Pfh 由前 n 个 特征 提问 序列 qqqn 来 决定 其中 第 i 个 特征 提问 仅 与 前 i 个 特征 提问 有关 　 　 图是 用 SDT 表示 的 一棵 动词 分类 树 它 描述 了 一个 具有 某些 特征 的 动词 与 名词 “ 成绩 ” 同 现时 构成 VN 结构 或 ～ VN 结构 的 概率 其中 内部 结点 是 提问 结点 一个 提问 结点 表示 对 一个 特征 的 提问 从 该 结点 延伸 的 树枝 代表 该 特征 可能 的 取值 ； 叶 结点 是 选择 结点 表示 符合 从根 结点 到 该 结点 的 路径 上 所有 “ 特征 — 值 ” 的 动词 与 名词 “ 成绩 ” 同 现时 是 构成 VN 结构 还是 ～ VN 结构 所 提问 的 特征 有 ： 动词 的 子类 SUBV 、 动词 的 音节 数 SYL 、 动词 的 义类 SENSE 等 例如 结点 表示 SUBV υ tSYLbi 且 SENSEHg 的 动词 与 名词 “ 成绩 ” 同现 构成 VN 结构图 　 统计 决策树 例图 　 基于 极大 似然 估计 MLEmaximumlikelihoodestimation 原则 的 动词 分类 树 的 生长 算法 　 　 动词 分类 树 生长 算法 的 关键 是 每个 提问 结点 所 提问 的 特征 的 选择 问题 本文 利用 基于 信息 增益 的 特征 来 选择 方法 ［ ］ 生长 动词 分类 树设 X 是 由 任意 动词 与 特定 名词 n 的 同现 对 构成 的 训练 集 X υ ncm ｜ υ ∈ Vc ∈ C 其中 CVN ～ VN 是 分类 集 V 是 动词 集合 m 是 υ 和 n 的 同现 次数 ； 设 动词 特征 集为 AAAp 特征 Ak 的 取值 的 集合 Vk υ k υ kn 则 递归 地 生长 关于 特定 名词 n 的 动词 分类 树 T 的 算法 描述 如下 ： 　 　 ① 建立 动词 分类 树 T 的 根 结点 root 将 训练 集 X 与 root 相关联 ； 　 　 ② 设 当前 结点 为 nodei 与 nodei 关联 的 训练 集为 Xi 如果 对于 任意 υ ncm ∈ Xi 有 cVN 或 c ～ VN 则 确定 为叶 结点 返回 ； 　 　 ③ 对 Ai ∈ A 分别 计算 　 　 　 　 ． 熵 HXiPclogpc 　 　 　 　 ． 条件 熵 HXi ｜ AkPc ｜ Ak υ logpc ｜ Ak υ ； 　 　 ④ 计算 对 Ak 提问 的 信息 增益 ： IGAkXiHXi － HXi ｜ Ak 其中 IVAk 是 为了 避免 选择 具有 较 多 取值 的 特征 的 倾向 所加 的 系数 表示 为 IVAknjXijXilogXijXi 其中 Xi 是 与 nodei 相关联 的 训练 集 Xi 中 的 例子 数 Xij 是 训练 集 Xi 中 符合条件 Ak υ j 的 例子 数 ； 　 　 ⑤ 确定 具有 最大 信息 增益 的 特征 AmargmaxAkIGAkXi ； 　 　 ⑥ 依据 特征 Am 的 取值 的 集合 Vm υ mvmn 生长 结点 nodei 的 儿子 结点 nodeinodein 并 将 训练 集 Xi 划分 为 n 个 子集 XiXin 分别 将 XiXin 与 nodeinodein 相关联 ； 　 　 ⑦ 从 特征 集合 A 中 删除 特征 Am ； 　 　 ⑧ 对于 结点 nodeinodein 分别 执行 ② ～ ⑦ 进行 儿子 结点 的 生长 和 训练 集 的 划分 　 　 这样 一棵 基于 复杂 特征 的 动词 分类 树 就 生成 了 所有 的 叶 结点 构成 动词 集合 Vn 的 最优 划分 其中 每个 叶 结点 所 表示 的 复杂 特征 集由 从 树根 到 该 结点 的 所有 结点 的 复杂 特征 组成 　 用 最小 描述 长度 MDLminimumdescriptionlength 原则 搜索 动词 分类 树 的 最优 划分 　 基于 MLE 原则 的 语言 获取 模型 和 基于 MDL 原则 的 语言 获取 模型 　 　 以上 讨论 的 动词 分类 树 的 划分 和 基于 划分 的 概率模型 的 建造 是 语言 获取 的 问题 基于 MLE 原则 的 语言 获取 模型 为 MargmaxMpO ｜ M 其 挑选 模型 的 标准 是 模型 与 训练 数据 的 拟合 性即 模型 M 要 最大 可能 地 解释 训练 集 O 而 通常 情况 下 提供 给 学习者 的 数据 只是 目标语言 的 一小部分 于是 依据 MLE 原则 获取 的 语法 虽然 能够 很 好 地 解释 训练 集中 的 数据 但是 对 训练 集 以外 的 数据 的 解释 能力 很弱 这 就是 语言 获取 中 的 过度 适合 Overfitting 问题 即 对 训练 数据 的 不规则 性 和 特异性 过分 敏感 缺乏 归纳 能力 而 从 已知 的 观察 数据 归纳 出 既 可以 解释 已知 数据 又 可以 解释 未知 数据 的 语法 是 语言 获取 中 的 关键问题 例如 在 图 所示 的 基于 MLE 原则 的 生长 的 SDT 中其 最优 划分 是 所有 叶 结点 构成 的 划分 最优 的 概率模型 是 建立 在 最优 划分 上 的 模型 可以 看出 模型 的 概括 能力 很 弱 无法 判断 训练 集 以外 的 同现 “ 否定 Hc 成绩 ” 的 结构 这种 过度 适合 的 问题 使得 开放 测试 中 VN 结构 识别 的 召回 率不高 　 　 而 贝叶斯 ［ ］ 的 语言 获取 模型 为 MargmaxMpM ｜ OargmaxMpO ｜ M × pM 与 基于 MLE 原则 的 语言 获取 模型 相比 贝叶斯 语言 获取 模型 除了 考虑 模型 和 训练 数据 的 拟合 性 以外 还 考虑 了 模型 M 的 先验概率 pM 本文 依据 最小 描述 长度 MDL 原则 ［ ］ 来 定义 模型 的 评价 函数 即 对于 给定 的 观察 数据 的 最好 的 概率模型 是 具有 最短 描述 长度 的 模型 其中 描述 长度 由 以下 两 部分 组成 ： ① 模型 描述 长度 lG 即 模型 的 编码 长度 ； ② 数据 描述 长度 lOM 即将 模型 作为 数据 的 预测 时 数据 的 编码 长度 本文 将 在 节中 具体 定义 lM 和 lOM 这里 先 定义 pMlM 于是 PM 给 简单 的 语法 赋予 高 的 概率 这 与 OccamsRazor 的 直观 意义 相符 即 简单 的 语法 优于 复杂 的 语法 ［ ］ 另一方面 基于 MDL 原则 的 语言 获取 模型 又 超越 了 OccamsRazor 即 搜索 使 po ｜ m × pm 达到 最大 的 模型 M 其中 PM 倾向 于 简单 的 模型 而 POM 倾向 于 与 训练 数据 拟合 性好 的 模型 MDL 原则 就是 要 在 数据 拟合 程度 和 模型 复杂度 之间 找到 一个 鞍点 　 基于 MDL 原则 的 动词 分类 树 的 最优 划分算法 　 　 给定 一棵 动词 分类 树 可以 得到 动词 集合 V 的 若干个 划分 例如 对于 图 的 动词 分类 树 可以 得到 V 的 以下 划分 ： 　 　 　 全集 V 　 　 ． ［ SUBVVi ］ ［ SUBVVt ］ 　 　 图 　 动词 分类 树例 图 因为 建立 在 动词 分类 树 的 叶 结点 组成 的 划分 之上 的 模型 与 训练 数据 的 拟合 性 最好 因此 基于 MLE 的 模型 认为 这种 划分 是 最优 划分 ； 而 MDL 原则 认为 最优 划分 的 评判 目标 应该 是 在 模型 复杂度 和 数据 拟合 度 上 的 整体 评分 最好 　 　 对于 特定 名词 n 、 动词 集合 Vn 和 观察 数据 SVN ～ VN 设 Vn 的 候选 划分 集合 Ω PPPS 其中 每个 Pi ∈ Ω ≤ i ≤ s 都 对应 一个 基于 类 的 概率模型 Mi 目标 是 在 候选 概率模型 中 搜索 最优 的 模型 本文 用 MDL 原则 构造 模型 的 评价 函数 描述 如下 ： 　 　 ① 对于 每个 候选 划分 picccr 构造 相应 的 概率模型 Mip υ n ｜ υ ∈ Vn 其中 υ υ i υ j ∈ ckp υ inp υ jnpckn 而 pVNckn ∈ f υ nf υ n 其中 f υ n 表示 υ n 同现 的 频度 　 　 ② 计算 每个 概率模型 的 数据 描述 长度 ： 对于 任意 的 动词 和 名词 的 同现 υ n 它 的 结构 可 由 随机变量 X 表示 因此 X 服从 两点 分布 PXx 简化 上式 得 PXxpxpxx 设 xxxn 是 随机变量 X 的 容量 为 n 的 观察 样本 值 由于 样本 中 Xiin 相互 独立 所以 观察 值 xxxn 出现 的 概率 是 LPXxXxXnxnPXixipixipixi 定义 似然 函数 为 logLlogpixipixixilogpixilogpi 本文 将 logL 作为 数据 描述 长度 　 　 ③ 计算 每个 概率模型 的 模型 描述 长度 ： 在 本 问题 中 模型 描述 长度 由 两 部分 组成 即 划分 描述 长度 Lpar 和 概率 描述 长度 Lpro 设 动词 集合 Vn 的 候选 划分 集合 为 Ω 则 划分 描述 长度 为 LparVnlog ｜ Ω ｜ ； 概率 描述 长度 的 计算方法 如下 ： 因为 MLE 的 标准差 为 O 每个 标准差 的 编码 长度 为 O ｜ logO ｜ logOlog ｜ S ｜ 于是 每个 自由 参数 的 编码 长度 为 OClog ｜ S ｜ ／ Olog ｜ S ｜ ／ 本文 定义 概率 描述 长度 为 Lpar ｜ Ω ｜ ／ × log ｜ S ｜ 　 　 ④ 用 MDL 原则 挑选 最优 划分 和 最优 模型 ： MoptargminMLdatMLparMLproM 因为 Mi 和 MjLparMiLparMj 因此 MoptargminMLdatMLproM 　 　 给定 一棵 动词 分类 树 Tnodei 是 其中 的 一个 结点 与 结点 nodei 对应 的 训练 集 表示 为 Xi 将 与 结点 nodei 对应 的 复杂 特征 集 表示 为 ［ nodei ］ ［ nodei ］ 构成 Xi 的 一个 划分 建立 在 划分 ［ nodei ］ 上 的 概率模型 为 Mi 基于 MDL 原则 搜索 其 最优 划分 opt 的 递归 算法 如下 ： 　 　 ① 将 当前 结点 设为 根 结点 ； 　 　 ② 设 当前 结点 为 node 如果 node 是 叶 结点 则 返回 ［ node ］ ； 　 　 ③ 否则 对于 node 的 每个 子女 结点 childi 递归 地 搜索 与 它 相关联 的 动词 子集 Ci 的 最优 划分 Pi 令 PPi 构造 基于 划分 P 的 概率模型 为 M 如果 模型 Mi 的 描述 长度 小于 模型 M 的 描述 长度 即 LMiLM 则 返回 划分 ［ nodei ］ 否则 返回 划分 P 　 　 利用 以上 的 算法 可以 在 一棵 动词 分类 树上 搜索 到 一个 动词 集合 的 最优 划分 例 如图所示 动词 分类 树 的 最优 划分 为 结点 a ～ h 构成 的 划分 　 由 动词 分类 树 推导 VN 结构 模板 　 　 在 生长 动词 分类 树 并 搜索 它 的 最优 划分 以后 由 经过 剪枝 的 动词 分类 树 可以 容易 地 推导 出 VN 结构 模板 例如 在 图 中 与 最优 划分 对应 的 结构 模板 为 ： 　 基于 结构 模板 的 VN 型 短语 的 结构 识别 　 　 基于 结构 模板 的 VN 型 短语 的 结构 识别 可以 描述 为 这样 一个 问题 ： 给定 一个 同现 υ n 其中 υ 是 一个 特定 的 动词 n 是 一个 特定 的 名词 判断 它 是 VN 结构 还是 ～ VN 结构 可 利用 的 资源 有 ： 动词 词性 词典 、 动词 义类 词典 、 由 经过 剪枝 的 动词 分类 树 推导 的 结构 模板 VN 结构 识别 算法 描述 如下 ： 　 　 ① 对 动词 υ 标注 动词 的 分类 和 义类 并 建立 其 复杂 特征 集 的 向量 表示 QQm （ 因为 义类 歧义 没有 完全 排除 因此 可能 有 多个 向量 ） ； 　 　 ② 分别 计算 QQm 与 n 同 现时 构成 VN 结构 的 概率 pVNQinQin × 和 构成 ～ VN 结构 的 概率 p ～ VNQinQin × 其中 Qin 是 以 SDT 结构 模板 判断 的 Qi 和 n 同 现时 构成 VN 结构 的 概率 ； Qin 是 以 SDT 结构 模板 判断 的 Qi 和 n 同 现时 构成 ～ VN 结构 的 概率 ； 是 动词 υ 在 VN 结构 中 出现 的 概率 ； 是 名词 n 在 VN 结构 中 出现 的 概率 ； 是 动词 v 在 ～ VN 结构 中 出现 的 概率 ； 是 名词 n 在 ～ VN 结构 中 出现 的 概率 ； 　 　 ③ 计算 kargmaxipVNQin 和 largmaxip ～ VNQin 　 　 ④ 比较 pVNi 和 p ～ VNQln 　 　 　 　 ． 如果 pVNQknp ～ VNQln 则 同现 υ n 的 结构 为 VN 可信度 为 pVNQkn ； 　 　 　 　 ． 如果 pVNQknp ～ VNQln 则 同现 υ n 的 结构 为 ～ VN 可信度 为 p ～ VNQln 　 模型 分析 和 测试 结果 　 模型 分析 　 　 分别 从 训练 集 和 测试 集 （ 训练 集 和 测试 集 的 建造 见节 ） 中 抽出 动词 与 个 名词 “ 办法 ” 、 “ 标准 ” 、 “ 产品 ” 、 “ 成绩 ” 、 “ 贷款 ” 、 “ 单位 ” 、 “ 干部 ” 、 “ 公司 ” 、 “ 过程 ” 、 “ 合同 ” 同现 的 数据 作为 训练 集 和 测试 集 测试 各种 模型 的 性能 测试 指标 有 ： ① 收敛性 ： 比较 模型 在 不同 的 训练 数据 时 获得 的 结构 模板 的 变化 数 （ 增加 的 模板 数 和 减少 的 模板 数 之 和 ） 变化 数越 小 收敛性 越 好 ； ② 模板 数 ： 比较 模型 在 不同 的 训练 数据 时 获得 的 结构 模板 数 模板 数越 小 模型 越 简单 ； ③ 精确 率 ： p × ； ④ 召回 率 ： r × ； 其中 a 是 能 判断 VN ～ VN 且 判断 正确 的 同现 次数 b 是 能 判断 VN ～ VN 的 同现 次数 c 是 总 同现 次数 　 基于 MDL 的 模型 和 基于 MLE 的 模型 的 比较 　 　 通过 比较 基于 复杂 特征 和 MDL 的 模型 与 基于 复杂 特征 和 MLE 的 模型 的 各种 指标 比较 基于 MDL 的 模型 和 基于 MLE 的 模型 的 性能 结果 见图 ～ 　 　 图 　 MDL 和 MLE 收敛性 比较 　 　 　 　 　 　 　 　 　 　 图 　 MDL 和 MLE 模板 数 比较 　 　 　 图 　 MDL 和 MLE 精确 率 比较 　 　 　 　 　 　 　 　 　 　 　 图 　 MDL 和 MLE 召回 率 比较 　 　 通过 以上 实验 可以 得出 如下 结论 ： ① 基于 MDL 的 模型 比 基于 MLE 的 模型 收敛 速度 快 ； ② 基于 MDL 的 模型 比 基于 MLE 的 模型 简单 ； ③ 虽然 基于 MDL 的 模型 的 精确 率 比不上 基于 MLE 的 模型 但 随着 训练 数据 的 增加 基于 MDL 的 模型 的 精确 率 逐渐 逼近 基于 MLE 的 模型 ； ④ 基于 MDL 的 模型 的 召回 率 优于 基于 MLE 的 模型 主要 体现 在 ： 由于 基于 MDL 的 模型 的 概括 能力 优于 基于 MLE 的 模型 使得 该 模型 对于 未 观察 的 同现 的 处理 优于 基于 MLE 的 模型 对于 标不上 义类 的 同现 的 处理 优于 基于 MLE 的 模型 　 基于 复杂 特征 的 模型 和 基于 义类 的 模型 的 比较 　 　 通过 比较 基于 复杂 特征 和 MDL 的 模型 和 基于 义类 和 MDL 的 模型 的 各种 指标 比较 基于 复杂 特征 的 模型 和 基于 义类 的 模型 的 性能 结果 见图 ～ 　 　 　 　 图 　 复杂 特征 模型 和 义类 模型 收敛性 比较 　 　 图 　 复杂 特征 模型 和 义类 模型 模板 数 比较 　 图 　 复杂 特征 模型 和 义类 模型 精确 率 比较 　 　 图 　 复杂 特征 模型 和 义类 模型 召回 率 比较 　 　 通过 以上 实验 可以 得出 如下 结论 ： ① 基于 复杂 特征 的 模型 收敛 速度 比 基于 义类 的 模型 稍快 ； ② 基于 复杂 特征 的 模型 比 基于 义类 的 模型 简单 ； ③ 基于 复杂 特征 的 模型 比 基于 义类 模型 的 精确 率高 ； ④ 基于 复杂 特征 的 模型 的 召回 率 优于 基于 义类 的 模型 　 测试 结果 　 　 从 兆 字节 的 新华社 语料 中 抽取 vn 同现 对 （ 次 ） 涉及 个 动词 和 个 名词 其中 包括 VN 结构 对 （ 次 ） 涉及 个 动词 和 个 名词 对 所有 的 υ n 同现 标注 词性 标记 、 义类 标记 和 音节 数 标记 从而 构成 训练 集 　 　 从 训练 集中 随机 抽取 对 υ n 同现 构成 封闭 测试 集 涉及 个 动词 和 个 名词 从 训练 集外 的 万字 的 语料 中 抽取 υ n 同现 对 标注 词性 标记 、 义类 标记 和 音节 数 标记 构成 开放 测试 集 涉及 个 动词 和 个 名词 　 　 利用 VN 结构 模板 判断 封闭 测试 集 和 开放 测试 集中 υ n 同现 的 结构 测试 结果 如表 所示 　 　 表 　 　 　 　 精确 率 召回 率 封闭 测试 开放 测试 　 对 实验 中 几个 问题 的 说明 　 《 词林 》 收词 不足 的 问题 　 　 在 识别 阶段 存在 着 由于 《 词林 》 收词 不足 引起 的 某些 动词 没有 义类 代码 的 问题 在 缺少 义类 代码 的 情况 下 基于 复杂 特征 的 模型 可能 利用 词性 信息 和 音节 数 信息 例如 ： 动词 “ 造林 ” 的 词性 标记 为 υ i 音节 数为 但 在 《 词林 》 中 没有 义类 代码 在 识别 “ 造林 成绩 ” 的 结构 时由节 中 模板 ② 判断 它 为 VN 结构 实验 表明 开放 测试 中 对于 动词 没有 义类 的 υ n 同现 基于 复杂 特征 的 模型 的 识别 精确 率为 召回 率为 　 义类 兼类 问题 　 　 对 训练 集 和 测试 集中 υ n 同现 数据 中 的 义类 兼类 动词 虽然 利用 词性 标记 进行 了 排歧 但 仍然 存在 义类 兼类 问题 本文 采取 的 办法 是 保留 歧义 实验 表明 这些 义类 歧义 对于 训练 和 识别 的 影响 都 不大 原因 是 ： 基于 复杂 特征 和 MDL 原则 的 模型 得到 的 结构 模板 都 具有 共同 的 特征 例如 “ 研究 GbHg 成绩 ” 中义类 Hg 是 成组 出现 的 即 “ 教育 Hg 、 训练 Hg 、 学习 Hg 、 创作 Hg ” 而义类 Gb 是 个别 出现 的 在 开放 测试 中 对于 动词 义类 兼类 的 vn 同现 基于 复杂 特征 和 MDL 原则 的 模型 的 识别 精确 率为 召回 率为 ； 而 基于 义类 和 MLE 原则 的 模型 的 识别 精确 率为 召回 率为 　 结束语 　 　 本文 提出 了 基于 复杂 特征 和 MDL 原则 的 VN 结构 模板 获取 模型 实验 表明 在 利用 结构 模板 进行 VN 结构 的 识别 时 这种 模型 比 基于 义类 和 极大 似然 估计 原则 的 模型 具有 更 高 的 精确 率 和 召回 率 但 还有 以下 两 方面 的 不足 ： ① 对于 VN 结构 的 识别 除了 应该 考虑 其 组成 成分 的 句法 和 语义 特征 外 还 应该 考虑 它 出现 的 上下文 环境 例如 在 句子 “ 这个 分析 系统 性能 可靠 ” 中 vn 同现 “ 分析 系统 ” 构成 VN 结构 而 在 句子 “ 这个 实验 用于 分析 系统 的 性能 ” 中 “ 分析 系统 ” 构成 ～ VN 结构 虽然 本文 考虑 的 主要 是 它 的 内部 组成 成分 但是 基于 复杂 特征 和 MDL 原则 的 VN 结构 模板 获取 模型 是 通用 的 如果 将 上下文 环境 特征 加入 复杂 特征 集中 这种 模型 则 可以 同时 考虑 VN 结构 的 上下文 环境 ； ② 虽然 基于 复杂 特征 和 MDL 原则 的 模型 的 鲁棒性 优于 基于 义类 和 MLE 原则 的 模型 《 词林 》 收词 不足 的 问题 仍然 是 影响 VN 结构 的 识别 精确 率 和 召回 率 的 主要 因素 我们 正在 尝试 用 分布 相似 的 方法 解决 这个 问题 本文 研究 得到 国家自然科学基金 资助 作者 介绍 ： 赵军 年生 博士生 主要 研究 领域 为 自然语言 处理 信息检索 语料库 语言学 　 　 　 　 　 黄 昌宁 年生 教授 博士生 导师 主要 研究 领域 为 自然语言 处理 信息检索 语料库 语言学 本文 通讯联系 人 ： 赵军 北京 清华大学 计算机科学 与 技术 系 作者 单位 ： 赵 　 军 　 清华大学 计算机科学 与 技术 系 　 北京 　 　 　 　 　 　 黄 昌宁 　 清华大学 智能 技术 与 系统 国家 重点 实验室 　 北京 　 参考文献 　 ［ ］ 梅家驹 等 同义词 词林 上海 上海辞书出版社 MeiJiajuetalTongyiciCilinShanghaiShanghaiDictionaryPress 　 ［ ］ BrownPFetalClassbasedngramModelsofnaturallanguageComputationalLingustics ～ 　 ［ ］ DaganIetalContextualwordsimilarityandestimationfromsparsedataComputerSpeechandLanguage ～ 　 ［ ］ LiHangetalClusteringwordswiththeMDLprincipleInProceedingsofthethInternationalConferenceonComputationalLinguisticsCopenhagenDenmarktheAssociationforInternationalComputationalLinguistics 　 ［ ］ PereiraFetalDistributionalclusteringofEnglishwordsInProceedingsofthethAnnualMeetingoftheAssociationforComputationalLinguisticsOhioUSAAssociationforComputationalLinguistics ～ 　 ［ ］ MagermanSFNaturallanguageparsingasstatisticalpatternrecognition ［ PhDDissertation ］ StanfordStanfordUniversity 　 ［ ］ StanleyFChenBuildingprobabilisticmodelsfornaturallanguage ［ PhDDissertation ］ CambridgeMassachusettsHarvardUniversity 　 ［ ］ QuinlanJRInferringdecisiontreesusingtheminimumdescriptionlengthprincipleInformationandComputation ～ 本文 收到 原稿 收到 修改稿