信息 与 控制 InformationandControl 年 　 第卷 　 第期 　 Vol 　 No 　 在 KDD 和 DataMining 中 我们 的 部分 工作 和 看法 覃 振兴 　 袁曾 任 　 　 摘 　 要 ： 本文 介绍 了 什么 是 KDD 和 DataMining ， 目前 国外 在 DataMining 中 研究 的 一部分 重要 内容 的 概况 以及 几年 来 我们 在 KDD 和 DataMining 中 的 部分 工作 和 看法 ． 　 　 关键词 ： KDDDataMining 粗集 理论 神经元网络 遗传算法 　 　 中 图 分类号 ： TP 　 　 　 　 　 　 文献 标识码 ： AAPARTOFOURRESEARCHWORKANDVIEWSINTHEKDDANDDATAMININGQINZhenxingYUANZengrenDeptofMathmaticsandComputerScienceGuangxiTeachersTrainingUniversityGuangxiDeprofMathmaticsandComputerScienceandTechnologyTsinghuaUniversity 　 　 BeijingAbstractThepaperpresentsthedefinitionofKDDandDataMiningItalsopresentsbrieflyasurverofapartofimportantcontrntsintheintemationaldataminingresearchworkasasapartresearchworkandviewsintheKDDanddatamininginrecentyeatsKeywordsKDDdataminingroughsetsartifivialNeuralnetworkgeneticalgiruthm 　 　 当今世界 正 处于 一个 “ 信息 爆炸 ” 的 时代 ． 据估计 全世界 的 信息 总量 每个 月 翻一番 ， 以 目前 社会 的 信息化 和 自动化 发展趋势 来看 ， 这个 速度 还会 更 快 ． 随着 近年来 Internet 的 迅速 发展 ， 大量 的 数据 好象 一下子 涌到 我们 的 面前 ， 可以 说 我们 不是 缺少 信息 ， 而是 给 信息 淹没 了 ， 我们 反而 不 知道 如何 才能 从中 迅速 找到 我们 真正 需要 的 知识 ． 一般而言 ， 人们 通常 用 各种各样 的 数据库 来 保存 各种 信息 ． 长期 积累 下来 ， 有些 数据库 变得 非常 庞大 ， 目前 数百万 乃至 数千万 条 记录 的 数据库 已 比比皆是 ． 这些 数据 是 一种 宝贵 的 资源 ， 就象 一座 蕴藏 丰富 的 巨大 矿场 ． 但 不幸 的 是 ， 我们 从中 发掘 所 需 矿物 的 能力 却 非常 有限 ， 有时 我们 不得不 有所 取舍 ， 仅能 开发 其中 的 一小部分 而已 ． 目前 的 数据库系统 基本上 是 一个 检索 工具 ， 仅能 产生 一定 的 检索 、 汇总 或 统计 量 ， 还 谈不上 进行 理解 和 概括 ． 所以 传统 的 信息处理 方法 很大 程度 上 是 一种 手工 作业 ， 通过 统计 方法 把 数据库 的 大量 数据 简化 到 人类 能 处理 和 理解 的 范围 ， 然后 由 人类 专家 根据 经验 对 之 进行 分析 、 理解 ， 最后 给出 相应 的 结论 ． 但是 随着 海量 数据库 和 数据仓库 的 大量 出现 ， 用 这类 传统 的 方式 进行 处理 显得 非常 费时 、 费力 ， 而且 主观性 很大 ． 因此 ， 当前 迫切需要 更好 的 方式 和 工具 来 处理 和 发掘 这些 日益 庞大 的 数据库 ． 于是 一个 新 的 研究 领域 — 数据库 中 的 知识 发现 （ KnowledgeDiscoveryinDatabases 简称 KDD 也 就 应运而生 ， 而且 在 近几年 里 迅速 发展 起来 ． 这个 领域 实质 上 是 智能 技术 与 数据库 相结合 ， 不但 为 决策者 提供 知识 和 策略 ， 而且 为 投资者 带来 经济效益 　 什么 是 KDD 　 　 KDD （ Knowledgediscoveryindatabases 这一 术语 最早 出现 在 年 AAAI 的 KDD 专题 研讨会 上 ， 而后 Fayyad 给出 了 一个 较 详尽 的 定义 ． 他 认为 KDD 包括 九个 步骤 ： 确定 研究 领域 和 用户 需求 创建 目标 数据 集 ： 选择 一个 数据 集 或者 集中 在 变量 或者 数据 样本 的 子集 上 ， 使之能 反映 待 发现 的 对象 数据 的 净化 和 预处理 ， 如 排除 噪声 或者 分离 物等 数据 的 减少 和 映射 ： 寻找 有用 的 特征 以 表示 确定 作业 目标 的 数据 ． 用 降级 或者 变换 方法 以 减少 变量 数 或者 找到 对 数据 的 恒定 的 表示 选取 适当 的 数据 采掘 任务 决定 KDD 处理 的 目标 是否是 分类 、 回归 、 聚类 等 选择 数据 采掘 的 算法 ： 选择 用于 寻找 数据 中 模式 的 方法 进行 数据 采掘 ， 发掘 数据 所 包含 的 模式 解释 所 发现 的 模式 并 形式化 整理 已 发现 的 知识 ： 检验所 发掘 的 知识 然后 予以 应用 ． 　 　 我们 比较 倾向 于 上述 定义 ， 不过 我们 认为 对 DataMining 的 定义 可 略为 扩充 ， 从 至步 有时 在 广义 上 都 可 看作 是 DataMining 的 范畴 ． 于是 我们 不妨 把 至步 称为 DataMining 的 前 处理 ， 而 ， 则 称作 其后 处理 ． KDD 可 看作 一个 有效 的 迭代 和 在 上述 任何 两步 之间 可能 包含 环路 的 循环 过程 ， KDD 是 一个 经过 用户 评估 的 大 闭环 过程 DataMining 是 其中 的 一个 内环 在 后处理 的 检验 和 应用 中 ， 若 发现 不 一致 或 不 合适 则 可 回头 对 前面 步骤 进行 修改 ， 直至 得到 较 满意 的 结果 ． 从 这 一 意义 上 来讲 ， 我们 觉得 DataMining 可以 认为 是 在 一个 比较 确定 的 数据库 上 ， 采用 特定 的 数据 采掘 方法 提取 出 隐含 的 、 未知 的 、 有 潜在 应用 价值 的 信息 的 过程 ． 　 国外 部分 研究 情况 　 　 年 AAAI 组织 了 一个 KDD 专题 研讨会 ， 其 论文集 于 年 出版 ， 标志 着 KDD 的 正式 诞生 ． 之后 逐渐 升温 ， 越来越 多 的 研究者 投身 其中 ． 而 近几年 为了 处理 数据仓库 和 Internet 上 浩如烟海 的 信息 数据 ， 象 IBM ， NASA ， GM ， MICROSOFT 等 大 公司 竞相 投入 资金 推动 KDD 的 研究 及其 实用化 ， 因此 近两年来 形成 一股 KDD 研究 热潮 ． 从 年 开始 举行 每年 一届 的 KDD 国际 会议 ， AAAI 和 IJCAI 这 两大 AI 系列 会议 均 开设 了 KDD 专题 ， 各种 有关 KDD 的 专辑 和 杂志 层出不穷 ． 下面 ， 我们 就 DataMining 当前 所 研究 的 主要 热点 中 我们 比较 感兴趣 而且 作 了 一些 工作 的 几个 主题 分别 讨论 其 当前 的 研究 状况 ， 对于 想 比较 详细 了解 KDD 和 DataMining 各个方面 的 读者 可以 参见 文献 ． 相关性 建模 　 　 即 是 通过 对 选定 的 数据表 进行 分析 ， 找到 一个 模型 来 描述 变量 间 有 意义 的 依赖 关系 ． 其中 关联 规则 的 发掘 是 近期 研究 得 比较 多 的 一个 重要 问题 ～ ， 主要 是因为 其 用于 实际 的 大型 事务 数据库 （ 如 大型商场 或 超级市场 的 事务 数据库 ） 中 ， 应用 效果 和 前景 都 非常 好 ． 关联 规则 的 数学模型 最先 由文 提出 ． 设 Γ ＝ i ， i ， … im 是 一组 文字 （ 或 称项 ） ， 事务 是 上 的 一个 子集 ． 每个 事务 均 有 一个 唯一 标识符 Tid ． 不同 的 事务 一起 构成 了 一个 事务 数据库 ， 记为 D ． D 就是 发掘 关联 规则 的 数据源 ． 一个 关联 规则 简记 为 XY 的 形式 ， 这里 X ∈ Γ ， 且 X ∩ Y φ ． 规则 X 关联 规则 的 数学模型 最先 由文 提出 ． 设 Γ ＝ i ， i ， … im 是 一组 文字 （ 或 称项 ） ， 事务 是 上 的 一个 子集 ． 每个 事务 均 有 一个 唯一 标识符 Tid ． 不同 的 事务 一起 构成 了 一个 事务 数据库 ， 记为 D ． D 就是 发掘 关联 规则 的 数据源 ． 一个 关联 规则 简记 为 XY 的 置信度 c 表示 在 D 中有 c ％ 的 事务 包含 X ∩ Y ， 而 规则 X 关联 规则 的 数学模型 最先 由文 提出 ． 设 Γ ＝ i ， i ， … im 是 一组 文字 （ 或 称项 ） ， 事务 是 上 的 一个 子集 ． 每个 事务 均 有 一个 唯一 标识符 Tid ． 不同 的 事务 一起 构成 了 一个 事务 数据库 ， 记为 D ． D 就是 发掘 关联 规则 的 数据源 ． 一个 关联 规则 简记 为 XY 的 支持 度 s 表示 在 D 中有 s ％ 的 事务 包含 X ∪ Y ， 人 可以 根据 需要 定出 不同 的 阈值 s ′ ， 称为 最小 支持 度 ， 只有 其 支持 度 s 大于 s ′ 时才 予以考虑 ． 　 　 例如 ： 在 某 商场 中 发现 购买 商品 A 和 B 的 客户 有 ， 购买 商品 C 和 D 的 客户 有 ， 而且 购买 A 和 B 的 客户 有会 购买 C 和 D ， 于是 这一 信息 可用 关联 规则 R ： A ∧ BC ∧ Dc ， s 来 表示 ． 这 类 规则 对 商场 的 布局 ， 商品 摆放 及 市场 分析 等 都 非常 有用 ． 　 　 根据 文 ， 关联 规则 问题 可以 分解成 以下 两步 ： 　 　 找出 所有 满足 最小 支持 度 的 所有 项集 ． 　 　 从 上面 的 项 集中 提取 满足 最小 置信度 的 规则 ． 其中 第步 是 问题 的 核心 ， 在 事务 数据库 D 非常 大且 项集 的 项数 也 很多 时 ， 如何 能 快速 准确 地 找出 这些 项集 是 非常 关键 的 ． 比较 经典 的 算法 是 IBM 公司 的 Quest 系统 中 的 Apriori 及 文中 DHP 算法 ． 文 ［ ］ 则 引入 并行算法 以 提高效率 ． 这 两个 算法 适用 于 事务 数据库 ， 即 各 属性 只取 发生 和 不 发生 两值 ， 但 通过 分段 和 影射 可 推广 至 其它 类型 的 数据库 或 得到 定量 性 的 相关 规则 ． 　 　 另外 的 一个 推广 就是 引入 背景 知识 ， 如 面向 属性 的 概念 层次 树即 是 其中 一种 ， 它 使得 关联 规则 可以 扩展 到 多级 概念 层次 ． 数据 综合 和 概括 　 　 数据 概括 即 是 把 一个 大 的 相关 数据 集从 较 低 概念 层次 抽象 到 更 高 概念 层次 的 过程 ． 我们 知道 数据库 中 的 数据 常常 是 比较 具体 和 细致 的 ， 所以 其 概念 层次 往往 较 低 ， 而 用户 有时 需要 在 更 高 的 抽象 级 上 进行 分析 ， 这 就要 进行 一定 的 抽象化 ． 　 　 目前 ， 主要 有 两类 方法 ： “ 数据 立方 ” 方法 ～ ， 也 被称作 “ 多维 数据库 ” ， “ 数据 可视化 ” 或 “ OLAP （ OnLineAnalyticalProcessing ） ” 面向 属性 的 归约 attributeoriented 以下 简称 AO 方法 ． 本文 主要 讨论 AO 方法 ． 　 　 AO 方法 主要 特点 是 它 利用 一种 特殊 的 背景 知识 即 概念 层次 或 概念 树 把 数据库 中 的 原始数据 按 背景 知识 转换 为 更 高级 的 概念 可以 大大 缩小 数据 规模 ． 数据 分类 　 　 数据 分类 即 根据 分类 模型 ， 把 数据库 中 数据项 影射 或 划分 到 预先 定义 好 的 若干 类别 中 的 某 一个 ． 数据 分类 在 概率 统计 ， 机器 学习 ， 神经网络 和 专家系统 中均 被 研究 过 ， 是 一个 重要 的 DataMining 专题 ． 　 　 基于 决策树 的 分类 方法 来源于 机器 学习 ， 从 一组 样本 中用 带 监督 的 学习 方法 构造 出 决策树 ， 它 同时 要 考虑 分类 准确性 和 树 的 大小 两个 方面 ． 　 　 具体 是 先 采样 进行 学习 得到 一个 决策树 ， 然后 对 它 进行 检验 ， 如果 有些 对象 不 满足 于 它 ， 则 把 这些 例外 的 对象 加入 样本 中 重新学习 ， 直至 得到 一个 准确 的 决策 集 ． 最终 结果 是 一棵树 ， 它 每 一片 叶子 都 是 一个 类 ， 而 内 结点 则 代表 一个 属性 ， 该 属性 所有 取值 都 在 其 分枝 中 ． 决策树 有 比较简单 的 表示 形式 ， 比较 容易 理解 和 推导 ． 　 　 较 经典 的 决策树 学习 系统 是 ID 及 C ， C 是 把 ID 从 分类 属性 领域 扩展 到 能 对 数字化 属性 进行 分类 ， 文用 ID 算法 来 作 面向 属性 的 归约 可以 改善 高 抽象 级 的 分类 能力 ， 中 的 DBMiner 即 是 一个 可调 的 多级 分类 系统 ， 它 使用 级别 调节 和 显现 技术 来 提高 大型 数据库 的 分类 准确性 ， 同时 应用 了 面向 属性 的 归约 和 分类 方法 ． 　 　 但是 ， 机器 学习 方法 及其 它 部分 的 分类 算法 往往 需要 把 训练 数据 放入 内存 ， 这 只 适用 于 较 小规模 的 数据 ， 在 大型 数据库 中 往往 性能 不 隹 ． 因此 提出 了 一种 快速 分类 算子 ， 叫 SLIQSupervisedLearninginQuest ， 它 也 是 一种 基于 决策树 的 算子 ， 它 能 训练 数据 对 内存 的 需求 减少 到 一个 较 小 的 比例 ， 同时 处理 分类 和 数值 型 属性 ． 其 改进 算法 SPRINT 可以 使 训练 数据 不 受 内存 的 限制 ． 　 　 还有 就是 以前 的 决策树 都 是 针对 单个 属性 作为 分支 决策依据 ， 有时 需要 用 多个 综合 来 划分 类别 ． 文 认为 可 分成 两个 阶段 ， 先是 特征 抽取 ， 找出 一组 好 的 分类 属性 ， 然后 根据 这些 属性 综合 起来 进行 分类 ， 可以 得到 更好 的 分类 效果 ． 　 　 其它 还有 象 基于 概率 的 方法 ， 及 基于 Roughsets 的 方法 等 ． 文 提出 了 应用 于 大型 数据库 的 分类 方法 ， 用 区间 算子 来 减少 生成 决策树 时 的 开销 ， 而 中用 神经网络 来 进行 和 提取 规则 ， 是 一种 较 新 的 方法 ． 还有 也 提出 了 一个 叫 metalearning 的 方法 ， 可以 综合 几种 基本 的 分类 算子 ， 可能 是 一个 比较 好 的 尝试 ． 数据 聚类 也 叫 非 监督 学习 　 　 数据 聚类 即 是 把 给定 的 若干 抽象 或 具体 的 对象 划分 成 有限 个数 的 类别 ． 它 在 统计学 和 机器 学习 中均 被 研究 过 ． 但 这些 方法 在 处理 极 大量 的 数据 时 开销 太 大 ， 必须 采用 一定 的 方法 进行 简化 ． 　 　 文 的 CLARANS 采用 先 抽样 再 聚类 的 方法 ， 综合 了 PAM 和 CLARA 算法 的 优点 ． 但是 要 把 所 聚类 对象 放入 内存 ， 而且 计算 类间 的 距离 开销 也 很大 ， 因此 文 采用 Rtree 来 “ 聚焦 ” 出类 的 代表 ， 可以 大大 节省 空间 和 减少 计算 复杂度 ． 由于 Rtree 不 一定 存在 ， BIRCH 算法 可以 根据 内存大小 进行 调整 ． 　 我们 的 部分 研究 工作 　 　 有些 研究者 认为 KDD 是 机器 学习 或 统计学 等 方法 的 另 一 说法 ， 我们 说 的 KDD 及其 DataMining 方法 并 不是 说 要 完全 抛弃 以前 的 方法 ， 而是 要 互相 结合 ， 再 引入 一些 新 的 智能 技术 予以 扩展 ， 使之能 适应 数据量 剧增 带来 的 新 变化 ． 本 实验室 很 早就 注意 到 了 KDD 这一 研究 领域 一直 注视 国外 的 最新进展 目前 已 在 国内 国际 杂志 和 会议 发表 有关 文章 三十余篇 ． 我们 曾 从 以下 几个 方面 进行 了 一些 研究 ． 现 简要 介绍 如下 ． 与 逻辑学 结合 并 引入 背景 知识 ～ ． 　 　 周生炳 博士后 提出 不 完全 决策表 概念 及其 化简 方法 和 基于 规则 的 面向 属性 归纳 方法 rulebasedattributeoriented 简称 为 RBAO 方法 的 无 回溯 方法 并 应用 于 知识 发现 ． 其 主要 思想 是 把 不 完全 决策表 与 AO 方法 相结合 ， 进一步 改善 AO 方法 与 粗糙集 方法 的 结果 ． 但 总的来说 当前 的 各种 KDD 方法 都 是从 数据库 本身 的 信息 出发 挖掘出 有 意义 的 模式 用户 的 经验 、 常识 等 无法 利用 其 原因 之一 是 缺乏 有效 的 表示 和 处理 的 手段 ． AO 方法 和 RBAO 方法 算是 走出 了 第一步 但 只能 表示 和 利用 分类学 的 知识 而且 所 涉及 的 事物 性质 都 是 数据库 中 的 属性 ． 可是 ， 有时 数据库 之外 的 某些 性质 可能 与 数据库 属性 有关 反之亦然 ． 而且 某些 性质 只 对 部分 对象 有 意义 ． 为此 在 数据库 归纳 中 我们 引入 了 一般 的 背景 知识 称为 基于 知识 knowledgebased 的 KDD 方法 ． 该 方法 用 不 循环 一元 谓词 知识库 表示 背景 知识 把 非 单调推理 与 归纳 学习 纳入 一个 统一 框架 大大提高 了 背景 知识 的 表达能力 ． 应用 神经元网络 （ 基于 BP 算法 ） 实现 DataMining ． 由 神经元网络 提取 规则 ～ ． 　 　 在 过去 的 几年 里 ， 用 ANN 技术 提取 规则 包括 “ crisp ” 和 模糊 两类 的 若干 方法 已经 提出 来 了 ， 从 已 训练 好 的 多层 神经网络 提取 “ crisp ” 乾脆 的 规则 的 技术 ， 例如 BRINNE 技术 和 KT 算法 以及 由 YoonByungjao 等 人 提出 通过 “ destructivelearning ” 毁坏 性 学习 提取 规则 和 IshikawaM 提出 结构 的 学习 及其 应用 于 规则 的 提取 　 　 作者 等 人 提出 一种 由 预处理 和 规则 提取 两 阶段 组成 的 方法 ， 预处理 阶段 中 包含 有 动态 修正 、 聚类 和 删枝 三 部分 ． 动态 修正 是 自动 生成 或者 由 初始 规则 集 构造 出全 联接 或者 非全 联接 网络 的 初步 拓扑 结构 ； 聚类 和 删技 分别 删 截掉 不 重要 或者 多余 的 隐含 节点 和 联接 ， 从而 可以 得到 最 简洁 和 规模 小 的 拓扑 结构 ， 成为 提取 规则 的 基础 ． 作者 等 人 还 提出 了 规则 提取 算法 并 用于 已 删截 好 的 网络 提取 规则 ． 作者 将 这种 方法 应用 于 美国 AD 报告 中 气象 云图 的 数据 ， 提取 出 规则 集 ， 经过 测试数据 集 的 测试表明 是 正确 的 和 有效 的 ， 这是 一种 简单 和 可行 的 方法 ． 由 神经元网络 采掘 分类 规则 ． 　 　 文章 中 所用 采掘 算法 是 由 训练 、 删枝 、 提取 和 后处理 四个 模块 组成 ． 训练 模块 主要 是 采用 惩罚 函数 将 学习 的 知识 集中 到 尽可能少 的 隐含 单元 上 ． 开始 选用 比 必要 还 大 的 网络结构 ， 然后 消去 不 需要 的 部分 ， 这种 做法 允许 网络 相当 快 而且 对 起始 条件 不太 敏感 地去 学习 知识 ， 同时 减少 修整 好 系统 的 复杂性 ， 有助于 改进 泛化 能力 ． 由于 网络 规模 较大 将会 增加 删除 隐含 节点 的 困难 ， 所以 惩罚 项 应该 加 到 误差 函数 中以 把 知识 汇集 在 最少 隐含 单元 上 ， 在 文献 中 采用 由 Chaulin 建议 的 惩罚 函数 ． 删除 模块 主要 采用 异常 的 比例 去 选择 对于 分类 最 相关 的 隐含 单元 ． 建议 的 算法 是 基于 在 其他 文献 中 已 采用 的 由 模糊 分类器 产生 的 类区 分析 ， 在 类区 中 重叠 的 程度 或者 由 模糊 分类器 产生 在 模糊 规则 内部 存在 异常 的 程度 ， 把 它 定义 为 异常 的 比例 并用 它 来 作为 隐含 单元 评估 的 一个 量度 ． 给定 一组 留下 的 隐含 单元 ， 建议 的 算法 消 去 邻接 的 隐含 单元 ， 它 的 消去 使 比例 之 和 最小 ． 当 单个 隐含 单元 的 更 多 消去 导致 异常 比例 之 和 显著 地 增加 时 ， 意味着 显著 地 依靠 属于 分类器 在 使用 时 的 未知 数据 的 识别 误差率 ， 建议 的 算法 终断 ． 其他 内容 因 篇幅 关系 不再 介绍 ， 请 见 ． 将 这种 方法 应用 于 IrisCancerSplicePlomotes 和 Agrawal 建议 的 几种 函数 上 ， 实验 结果表明 在 提取 规则 准确率 、 规则 数 和 条件 数都 比较 好 ． 混合法 　 　 在 文献 中 采用 遗传算法 删剪 已经 训练 好 的 神经元 网络拓扑 结构 ， 然后 把 删剪 好 的 网络 转化 为 M 树 ， 而 M 是 输出 单元 的 数目 并 等于 问题 的 类数 ， 最后 ， 通过 分析 每棵 树 提取 出 适合 每类 的 规则 集 ． 将 这种 方法 应用 于 IrisBreastCaneerDatasets 和 HandnittenNumeralDataset 中 取得 了 和 年 由 Setiono 等 人 得到 的 NN 和 DT 规则 相当 ． 但是 这种 方法 表现 出 解释 能力 而 同时 保持 网络 的 精度 ， 此外 ， 这种 方法 可以 清晰 地 说明 决策 过程 ． 感谢 周生炳 博士后 、 张 朝晖 博士 、 周远辉 博士 提供 他们 的 文章 以及 多次 的 讨论 ． 作者简介 ： 覃 振兴 ， 男 ， 岁 ， 硕士 ． 研究 领域 为 人工智能 和 KDD 及 DataMining 领域 ． 　 　 　 　 　 袁曾 任 ， 男 ， 岁 ， 教授 研究 领域 为 智能 控制 和 计算 智能 人工神经网络 ， 模糊 逻辑 、 遗传算法 及其 应用 作者 单位 ： 覃 振兴 广西师范大学 数学 与 计算机科学 系 清华大学 计算机系 智能 技术 与 系统 国家 重点 实验室 客座 ； 　 　 　 　 　 　 袁曾 任 清华大学 计算机系 　 北京 　 参考文献 　 UMFayyadGPiatetskyShapiroPSmythFromDataMiningtoKnowledgeDiscoveryAnOverviewInUMFayyadGPiatetskyShapiroPSmythRUUthurusamyeditorsAdvancesinKnowledgeDiscoveryandDataMiningAAAIMITPress ～ GPiateskyShapiroWJFrawleyKnowkledgeDiscoveryinDatabasesAAAIMITPressUMFayyadGPiatetskyShapiroPSmythRUUthurusamyeditorsAdvancesinKnowledgeDiscoveryandDataMiningAAAIMITPress ～ RAgrawalTImielinskiASwamiMiningAssociationRulesBetweenSetsofItemsinLargeDatabasesProceedingsofACMSIGMODMay ～ RAgrawalRSrikantFastAlgorithmsforMiningAssociationRulesinLargeDatabasesProceedingsofthethInternationalConferenceonVeryLageDataBasesSeptember ～ JHanYFuDiscoveryofMultipleLevelAssociationRulesfromLargeDatabasesProceedingsofthethInternationalConferenceonVerylageDataBasesSeptember ～ HMannilaHToivonenAInkeriVerkamoEfficientAlgorithmsforDiscoveringAssociationRulesProceedingsofAAAIWorkshoponKnowledgeDiscoveryinDatabasesJuly ～ JSParkMSChenPSYuAnEffectiveHashBashedAlgorithmforMiningAssociationRulesProceedingsofACMSIGMODMay ～ ASavasereEOmiecinskiSNavatheAnEfficientAlgorithmforMiningAssociationRulesinLargeDatabasesProceedingsofthethInternationalConferenceonVerylageDataBasesSeptember ～ RSrikantRAgrawalMiningGeneralizedAssociationRulesProceedingsofthethInternationalConferenceonVerylageDataBasesSeptember ～ SrikantRAgrawalRaMiningQuantitativeAssociationRulesinLargeRelationalTablesInProcoftheACMSIGMODConferenceonManagementofDataRandyKerberChimegeDiscretizationofNumericAttributesInProceedingsoftheAAAIworkshoponKDD ～ HTsukimotoTheDiscoveryofLogicalPropositionsinNumericalDataAAAIWorkshoponKnowledgeDiscoveryinDatabases ～ RAgrawalJCShaferParallelMiningofAssociationRulesIEEETransationonKnowledgeandDataEngineeringDec ～ MChenJHanPSYuDataMiningAnOverviewfromDatabasePerspectiveIEEETransKjnowledgeandDataEngineering ～ AFuptaVHarinarayanDQuassAggregatequeryProcessinginDataWarehousingEnvironmentInProcstIntConfVeryLargeDataBasesPagesZurichSwitzerlandSept ～ VHarinarayanJDUllmanARajaramanImplementingDataCubesEfficientlyInProcoftheACMSIGMODConferenceonManagementofDataJWidomReserchProblemsinDataWarehousinInProcthIntConfonInformationandKnowledgeManagementBaltimoreMarylandNov ～ WPYanPLarsonEagerAggregationandLazyAggregationInProcstIntConfVeryLargeDataBasesZurichSwitzerlandSept ～ JHanYCaiNCerconeDatadrivenDiscoveryofQuantitativeRulesinRelationalDatabasesIEEETransKnowledgeandDataEngineering ～ JHanYFuExplorationofthePowerofAttributeorientedInductioninDataMiningInUMFayyadGPiatetskyShapiroPSmythRUUthurusamyeditorsAdvancesinKnowledgeDiscoveryandDataMiningAAAIMITPress ～ JRQuinlanInductionofDecisionTreesMachineLearning ～ JRQuinlanCProgramsforMachineLearningMorganKaufmannRAgrawalMMehtaJShaferRSrikantAArningTBollingerTheQuestDataMiningSystemInProcIntlConfonDataMiningandKnowledgeDiscoveryKDDPortlandOregonAugustMMehtaRAgrawalJRissanenSLIQAFastScalableClassifierforDataMiningInProcIntConferenceonExtendingDatabaseTechnologyEDBTAvignonFranceMarchJShaferRAgrawalMMehtaFastSerialandParallelClassificationofVeryLargeDatabasesInVLDBMSChenPSYuUsingMultiAttributePredicatesforMiningClassificationRulesIBMResearchReportJHanYFuWWangetcDBMinerASystemforMiningKnowledgeinLargeRelationalDatabasesInKDDPortlandOregonAugestPCheesemanJStutzBayesianClassificatonAutoClassTheoryandResultsInUMFayyadGPiatetskyshapiroPSmythRUUthurusamyEditorsAdvancesinKnowledgeDiscoveryandDataMiningAAAIMITPress ～ JElderIVDPregibonAStatisticalPerspectiveonKnowledgeDiscoveryinDatabasesInUMFayyadGPiatetskyshapiroPSmythRUUthurusamyEditorsAdvancesinKnowledgeDiscoveryandDataMiningAAAIMITPress ～ GPiatetskyshapiroDiscoveryAnalysisandPresentationofStrongRulesInGPiatetskyshapiroWJFrawleyEditorsKnowledgeDiscoveryandDatabasesAAAIMITPress ～ WZiarkoRoughSetsFuzzySetsandKnowledgeDiscoverySpringerverlagRAgrawalSGhoshTImielinskiBIyerASwamiAnIntervalClassifierforDatabaseMiningApplicationsProceedingsofthethInternationalConferenceonVerylageDataBasesAugust ～ HLuRSetionoHLiuNeuroruleAConnectionistApproachtoDataMiningProceedingsofthethInternationalConferenceonVeryLageDataBasesSeptember ～ AKJRCDubesAlgorithmsforClusteringDataPrinticeHallDFisherImprovingInferenceThroughConceptualClusteringInProcAAAICconfSeattleWashingtonJuly ～ DFisherOptimizationandSimplificationofHierarchicalClusteringsInProcstIntConfonKnowledgeDiscoveryandDataMingingKDDMontrealCanadaAug ～ NBeckmannHPKriegelRSchneiderBSeegerTheRtreeAnEfficientandRobustAccessMethodforPointsandRectanglesInProcACMSIGMODIntConfManagementofDataAtlanticCityNJJune ～ MEsterHPKriegelXXuKnowledgeDiscoveryinLargeSpatialDatabasesFocusingTechniquesforEfficientClassIdentificationInProcthIntSymponLargeSpatialDatabasesSSDPortlandMaineAugust ～ RNgJHanEfficientandEffectiveClusteringMethodforSpatialDataMiningInProcIntConfVeryLargeDataBasesSantiagoChileSeptember ～ WPYanPLarsonEagerAggregationandLazyLazyAggregationInProcthIntConfVeryLargeDataBasesZurichSwitzerlandSept ～ HJLuRSetionoHLiuEffectiveDataMiningusingNeuralNetworksIEEETransactionsonKnowledgeandDataEngiYoonByungjooLacherRCExtractionRulesneeringDECPage ～ PKChanSJStolfoLearningArbiterandCombinerTreesfromPartitionedDataforScalingMachineLearningInKDDAugust ～ 周生炳 ， 张钹 不 完全 决策表 及其 化简 软件 学报 （ 将 发表 周生炳 ， 张钹 RBAO 方法 的 无回 嗍 算法 计算机 学报 （ 将 发表 周生炳 ， 张钹 基于 知识 的 KDD 方法 中国 科学 （ E 辑 ） （ 将 发表 ） 周生炳 基于 知识 的 KDD 方法 清华大学 博士后 出站 报告 北京 BinaghiEEmpiricalLearningforFuzzyKnowledgeAcquisitionProcndIntConfFuzzyLogicNeuralNetworksIIZUKAFuLiMinRuleGenerationfromNeuralNetworksIEEETransactionsonSystemsManandCybernetics ～ byDestructiveLearningIEEE ～ IshikawaMStructuralLearninganditsApplicationstoRuleExtractionIEEE ～ 袁曾 任 ， 卢振中 由 神经网络 提取 规则 的 一种 方法 及其 在 气象 云图 中 的 应用 年 中国 智能 自动化 学术会议 论文集 上册 ） ～ 袁曾 任 ， 卢振中 由 神经网络 提取 规则 的 一种 方法 信息 与 控制 ～ ZhouyuanluiLuYuchangShiChunyiUsingNeualNeworktoDiscoverKnowledgefromDatabasetobepublishedZhaohuiZhangYuanhuiZhouYuchangLuBoZhangExtractingRulesfromaGAPrunedNeualNetwork 收稿 日期 ：