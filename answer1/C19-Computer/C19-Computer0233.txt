软件 学报 JOURNALOFSOFTWARE 年 第期 No 一种 适用 于 机群系统 的 任务 动态 调度 方法 傅 　 强 　 郑纬民 　 　 摘要 　 任务调度 是 机群系统 上 实现 并行计算 需要 解决 的 重要 问题 之一 对于 在 运行 中 动态 产生 任务 的 并行 应用程序 由于 很难 作出 准确 的 任务分配 决策 可能 导致 各个 计算 结点 的 任务 负载 失衡 最终 引起 整个 系统 的 性能 显著 下降 因此 需要 通过 任务 再 分配 来 维持 负载平衡 该文 提出 一种 任务分配 与 再 分配 方法 它 通过 尽量 延迟 任务 的 执行 开始 时刻 在 任务 再 分配 时 避免 了 进程 迁移 使得 引入 的 调度 开销 很小 分析 和 实验 结果表明 该 方法 在 许多 情况 下 能够 有效 地 提高 并行程序 的 运行 性能 　 　 关键词 　 调度 机群系统 并行计算 任务分配 负载平衡 　 　 中图法 分类号 　 TPADynamicTaskSchedulingMethodinClusterofWorkstationsFUQiang 　 ZHENGWeimin 　 　 Abstract 　 TaskschedulingisanimportantissueintheresearchofparallelcomputinginclusterofworkstationsBecauseitisdifficulttomakeprecisedecisionoftaskallocationwhenrunningparallelapplicationsthatdynamicallyspawntasksloadimbalancemaybeoccurandtheperformanceofwholesystemwilldecreasedramaticallySotaskreallocationisnecessaryforloadbalancingAmethodfortaskallocationandreallocationispresentedinthispaperBydeferringthetasksrealstarttimeitavoidsprocessmigrationintaskreallocationThereforetheoverheadisgreatlydecreasedAnalysisandexperimentsshowthatthismethodcaneffectivelyimprovetheperformanceofparallelapplicationsinmanycases 　 　 Keywords 　 Schedulingclusterofworkstationsparallelcomputingtaskallocationloadbalancing 　 　 近年来 随着 工作站 性能 价格比 的 迅速 提高 和 快速 局域网 的 出现 工作站 机群系统 ClusterofWorkstations 已 成为 并行计算 的 一个 重要 发展 方向 在 机群系统 上 进行 并行计算 需要 软件 环境 的 支持 目前 已经 开发 并 广泛应用 的 并行 软件 环境 有 PVMparallelvirtualmachine ［ ］ MPICHmessagepassinginterface 等 　 　 在 基于 消息传递 模式 的 机群系统 并行计算 中 并行任务 的 调度 方案 极大 地 影响 了 应用程序 的 运行 性能 在 实际 应用领域 中 由于 机群系统 结构 和 程序 本身 的 不确定性 往往 需要 在 运行 时 进行 动态 调度 但 动态 调度 无法 获得 任务 的 负载 粒度 和 相互间 的 同步 与 通信 关系 的 准确 信息 因此 作出 的 任务分配 往往 不够 准确 还 需要 在 适当 的 时候 进行 任务 再 分配 来 维持 各个 结点 上 的 负载平衡 在 一些 并行 系统 如 PVM 中 任务 一经 分配 就 立即 执行 要 实现 任务 再 分配 只能 采取 进程 迁移 的 方式 但 进程 迁移 不仅 难于 在 异构 结点 间 实现 而且 其 开销 也 十分 庞大 甚至 抵消 负载平衡 所 带来 的 性能 提高 　 　 本文 提出 了 一种 基于 消息传递 并行 环境 的 “ 惰性 ” 任务调度 方法 它 可以 不 借助 进程 迁移 而 实现 低 开销 的 任务 再 分配 其 特点 有 ： 采用 非 阻塞 式 任务 派生 方式 缩短 响应 时间 采用 惰性 任务 执行 机制 只 对 未 开始 执行 的 任务 进行 再 分配 开销 很小 任务分配 及 再 分配 时 采取 本地化 算法 不仅 进一步 减小 调度 开销 而且 在 一定 情况 下 还 减小 了 通信 开销 任何 任务 至多 执行 一次 再 分配 不会 产生 “ 颠簸 ” 现象 　 　 下面 首先 给出 算法 描述 然后 介绍 该 算法 的 实现 方案 最后 给出 性能 分析 和 模拟实验 的 结果 　 算法 描述 　 　 “ 惰性 ” 任务调度 方法 由 任务分配 算法 和 任务 执行 与 再 分配机制 两 部分 组成 如图所示 其中 任务分配 算法 响应 应用程序 发出 的 任务 派生 申请 作出 首次 任务分配 决定 ； 任务 执行 机制 决定 在 何时 运行 何 任务 并 在 一定 条件 下 对 已 分配 的 任务 进行 调整 即 任务 再 分配 图 　 任务分配 算法 　 　 实现 任务 的 低 开销 再 分配 实际上 是 通过 “ 迁移 ” 尚未 执行 的 任务 来 实现 的 这 就 要求 任务 在 分配 后 不 立即 执行 而是 进入 本地 的 就绪 队列 系统 按 LIFOlastinfirstout 顺序 从队 头取 任务 执行 只有 当该 任务 结束 或 因 等待 未 执行 任务 传送数据 而 阻塞 时才 取下 一个 任务 执行 由于 单 CPU 的 UNIX 系统 采用 时间 片 轮换 法 调度 用户 进程 故 这种 多个 任务 串行 执行 的 总 时间 与 并发 执行 相同 　 　 本文 采用 的 任务分配 算法 流程 如下 ： 　 　 IfReceiveSPAWNtaskname 　 ∥ 接到 派生 任务 taskname 的 请求 　 　 　 　 IDGetIDtaskname ； 　 　 　 　 ∥ 创建 对应 taskname 的 唯一 标识号 　 　 　 　 InsertQIDHEAD 　 　 　 　 　 ∥ 将 ID 插入 本地 就绪 任务 队列 Q 的 队头 　 　 　 　 AckID 　 　 　 　 　 　 　 　 　 ∥ 应答 派生 任务 的 请求 并 返回 ID 　 　 　 　 首先 将 任务分配 在 本地 目的 是 减少 调度 开销 并且 使 通信 尽量 本地化 任务分配 后 不 立即 执行 但 马上 响应 派生 任务 的 请求 使 发出请求 的 进程 能够 继续执行 　 任务 执行 与 再 分配机制 　 　 任务 执行 机制 只有 在 当前 运行 的 任务 进程 结束 或 因 等待 未 执行 任务 传输数据 而 阻塞 时才 被 激活 它 首先 查看 本地 就绪 任务 队列 Q 若 Q 非空则 取队 头 任务 执行 ； 若 Q 为 空则 进行 任务 再 分配 ： 向 其他 结点 申请 任务 被 申请 结点 若 Q 非空 则 返回 队尾 任务 　 　 IfEndtaskcurrentTaskorBlockcurrentTask 　 ∥ 没有 任务 进程 在 运行 　 　 　 IfnotemptyQ 　 　 　 　 currentTaskGetQHEAD 　 　 　 　 　 　 　 　 　 ∥ 取队 头 任务 ID 作为 当前 运行 任务 号 　 　 　 else 　 　 　 　 currentTaskRequestTaskotherNode 　 　 　 　 　 ∥ 向 其他 结点 申请 任务 　 　 　 RuncurrentTask 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 ∥ 执行 该 任务 　 　 　 　 IfReceiveREQUESTTASK 　 　 　 　 　 　 　 　 　 　 　 　 ∥ 其他 结点 申请 任务 　 　 　 IfnotemptyQ 　 　 　 　 　 AckGetQTAIL 　 　 　 　 　 　 　 　 　 　 　 　 ∥ 返回 队尾 任务 　 　 这里 执行 机制 在 运行 本地 任务 和 申请 其他 结点 任务 时 分别 采用 的 是 LIFO 策略 和 FIFOfirstinfirstout 策略 任务 派生 关系 可以 看成 一棵 任务 树 由于 本地 执行 任务 采用 LIFO 方式 可以 维持 较 小 的 就绪 任务 集而 “ 迁移 ” 任务 采用 FIFO 方式 则 迁移 走 的 任务 在 任务 树上 更 靠近 根 结点 也就是说 它 会派 生出 更 多 的 任务 从而 保护 通信 的 本地化 Blumofe 的 分析 ［ ］ 表明 对于 大规模 动态 并行计算 此种 方式 能够 获得 接近 线性 的 加速 比 　 　 当 结点 的 本地 就绪 任务 队 列为 空 结点 轻载 时该 结点 向 其他 结点 申请 任务 这种 方式 也 就是 ReceiverInitiated 方式 RI 调度 由于 轻载 结点 承担 了 发起 任务 再 分配 的 开销 因此 RI 方法 在 系统 平均 负载 较重 的 情况 下 能够 有效 地 减少 调度 开销 ［ ］ 　 　 申请 其他 结点 任务 的 过程 就是 任务 再 分配 的 过程 由于 申请 后 立即 执行 该 任务 就 保证 了 一个 任务 最多 被 再 分配 一次 　 实现 方案 　 　 通过考察 PVM 的 API 可以 看出 本文 所述 算法 可以 在 PVM 系统 上 加以 实现 概略 地说 就是 接管 PVM 的 组 原语 PVM － SPAWNPVM － SEND 和 PVM － RECEIVE 如图所示 图 　 　 系统 引入 新 的 数据结构 ： 本地 派生 任务 队列 Q 和 发送 消息 缓冲 队列 Qs 　 　 对于 接管 后 的 组 原语 描述 如下 ： 　 　 PVM － SPAWN 　 　 系统 向 应用程序 返回 一个 任务 标识号 ID 并 将 其 插入 队列 Q 　 　 PVM － SEND 　 　 查看 队列 Q 　 　 if 目标 任务 已 激活 　 　 　 调用 PVM 的 消息 发送 原语 进行 发送 ； 　 　 elseifQs 已满 　 　 　 　 挂 起 ； 　 　 　 　 执行 本地 调度 ； 　 　 　 　 else 　 　 　 　 插入 队列 Qs 　 　 PVM － RECEIVE 　 　 查看 相关 结点 上 的 队列 Q 　 　 if 目标 任务 已 激活 　 　 　 调用 PVM 的 消息 接收 原语 进行 接收 ； 　 　 else 　 　 　 　 　 挂 起 ； 　 　 　 　 　 执行 本地 调度 ； 　 　 　 性能 分析 　 　 任务调度 的 目的 是 要 达到 负载平衡 从而 缩短 并行程序 的 运行 时间 进而 获得 更 高 的 加速 比 下面 我们 通过 对比 PVM 系统 来 讨论 本文 任务 再 分配 方法 的 性能 　 　 当 不 考虑 任务 间 的 通信 时设 应用程序 包含 n 个 独立 任务 其 粒度 分别 为 gii ∈ n 并行 系统 包括 m 个单 CPU 工作站 结点 其 计算能力 分别 为 cjj ∈ m 　 　 结点 j 单独 执行 任务 i 的 响应 时间 为 tjgigi ／ cj 　 　 PVM 采用 RoundRobin 转轮 法 一次性 分配任务 根据 抽屉 原理 分配 到 每个 结点 上 的 任务 数 Njj ∈ m 在 ］ 之间 由于 任意 两个 结点 分配 到 的 任务 集合 的 总 粒度 可能 相差 很大 导致 运行 时间 相差 很多 不能 保证 负载平衡 设 结点 j 运行 分配 到 的 Nj 个 任务 的 总 时间 为 Tj 则 并行 加速 比 S 就是 在 最快 的 结点 上 运行 整个 应用程序 所 需 时间 与 并行执行 时 最晚 结束 的 结点 运行 时间 的 比值 ： 其中 分子 部分 是 一个 常数 设为 C 在 最坏 的 情况 下即 并行计算 中 分配 在 最慢 结点 上 的 任务 粒度 远远 大于 其他 任务 时可得 其中 cfast 和 cslow 分别 为 最快 和 最慢 结点 的 计算能力 l 为 分配 在 最慢 结点 上 的 任务 粒度 与 应用程序 总 粒度 之 比 可以 看出 当 机群系统 各 结点 计算能力 相差 较大 且 任务 粒度 不均 时 PVM 可能 获得 远远 小于 的 最差 加速 比 也就是说 并行 时 的 性能 不如 在 最快 的 一个 结点 上 运行 的 性能 　 　 下面 看 一下 采用 本文 中 算法 时 的 情况 首先 可以 证明 最早 结束 的 结点 a 的 运行 时间 Ta 与 最晚 结束 的 结点 b 的 运行 时间 Tb 之差 Δ ≤ tslowgmax 其中 gmax 是 应用程序 中 最大 的 任务 的 粒度 tslowgmax 是 最慢 的 结点 运行 gmax 的 时间 　 　 证明 ： 用 反证法 假设 Δ ＞ tslowgmax 则 当 结点 a 运行 结束 时 结点 b 正在 运行 的 不 可能 是 最后 一个 任务 也就是说 队列 Q 中 还有 未 开始运行 的 任务 这 是因为 任何 任务 x 的 执行 时间 tbgx 小于 等于 tslowgmax 根据 算法 这时 结点 a 将 向 结点 b 申请 运行 任务 这 就 意味着 结点 a 并未 运行 结束 与 前提 矛盾 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 □ 　 　 上面 的 结论 保证 了 各 结点 的 运行 时间 不会 相差太大 从而 实现 了 负载平衡 　 　 另外 从 加速 比 来看 由于 最快 的 结点 上 运行 的 任务 集是 总任务 集 的 子集 故 运行 时间 不会 超过 常数 C 结合 上面 结论 可 得 ： 也就是说 在 最坏 的 情况 下 并行 运算 的 时间 与 在 最快 的 一个 结点 上 串行 运行 相当 　 　 在 模拟实验 中 我们 将 本文 中 提出 的 调度 方法 与 PVM 的 任务分配 策略 进行 了 性能 上 的 比较 实验 中 模拟 了 以下 环境 ： 　 　 个 结点 的 机群系统 各 结点 的 计算能力 的 比值 为 ； 　 　 任务 序列 为 随机 产生 的 树形 序列 参数 k 调整 任务 派生 的 时间 间隔 k 越大 表示 任务 派生 的 间隔 越长 k 表示 任务 派生 的 平均 时间 间隔 与 任务 的 平均 计算 粒度 相等 ； 　 　 任意 两个 任务 间 有 可能 存在 通信 或 同步 关系 参数 c 用来 调整 任务 间 的 通信 依赖 关系 c 越大 任务 间 的 通信 依赖性 越强 c 表示 任意 两个 任务 间 都 存在 通信 关系 c 反之 　 　 图为 模拟实验 的 测试 结果 图中 每 一个 数据 点 代表 一次 对比 模拟 ： 纵坐标 表示 使用 PVM 调度 策略 的 总 运行 时间 与 采用 本文 调度 方法 的 总 运行 时间 之比为 简单 起 见 实验 忽略 了 网络通信 的 时延 及 调度 系统 的 开销 图 　 　 从图 中 可以 看到 使用 本文 的 调度 方法 可以 提高 程序 的 并行 性能 另外 还 可以 看到 该 方法 对 任务 间通信 关系 较 简单 、 任务分配 频度 较 高 的 应用程序 效果 较为 显著 　 小 　 结 　 　 针对 机群系统 并行计算 中 如何 实现 负载平衡 的 问题 本文 提出 了 一个 低 开销 的 任务调度 方法 该 方法 采用 “ 惰性 ” 任务 执行 机制 在 不 影响 并行性 的 前提 下 尽量 延迟 就绪 任务 的 实际 执行 以便 在 并行计算 过程 中 对 未 执行 的 任务 进行 重新分配 分析 和 实验 结果表明 该 方法 在 一定 的 条件 下 可以 达到 较 好 的 性能 此外 该 方法 可 利用 PVM 系统 加以 实现 本文 研究 得到 国防科技 预研 基金 资助 。 作者 介绍 ： 傅强 年生 博士生 主要 研究 领域 为 并行处理 负载平衡 。 　 　 　 　 　 郑纬民年生 教授 博士生 导师 主要 研究 领域 为 并行 分布 处理 本文 通讯联系 人 ： 傅强 北京 清华大学 计算机科学 与 技术 系 应用 教研组 作者 单位 傅 　 强 　 郑纬民 　 清华大学 计算机科学 与 技术 系 　 北京 　 参考文献 　 ［ ］ GeistABeguelinADongarraetalPVMParallelVirtualMachineCambridgeTheMITPress ～ 　 ［ ］ BlumofeRDParkDSSchedulinglargescaleparallelcomputationsonnetworksofworkstationsTechnicalReportMassachusettsInstituteofTechnology ～ 　 ［ ］ WillebeekLemairHReevesAPStrategiesfordynamicloadbalancingonhighlyparallelcomputersIEEETransactionsonParallelandDistributedSystems ～ 本文 收到 原稿 收到 修改稿