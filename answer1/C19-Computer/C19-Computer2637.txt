软件 学报 JOURNALOFSOFTWARE 年 第卷 第期 VolNo 分布式 虚拟环境 中 基于 神经网络 的 实时 预测 寿黎 但 史烈 石教英 摘要 　 在 分布式 虚拟环境 中 性能 的 瓶颈 是 为 维护 主机 间 实体 行为 的 一致性 而 进行 的 通信 该文 针对 虚拟 场景 中 的 难 预测 对象 建立 其 状态 向量 的 神经网络 模型 使用 了 基于 函数 型 连接 的 神经网络 对 其 行为 进行 实时 预测 首先 介绍 了 函数 型 连接 的 原理 和 特点 其次 在 对 传统 的 DR 算法 进行 描述 后 提出 了 基于 神经网络 预测 的 自 适应 DR 算法 然后 给出 了 基于 该 算法 的 网络软件 结构 最后 对 一个 特例 进行 了 实验 实验 结果表明 该 算法 可以 很 好 地 工作 关键词 　 分布式 虚拟环境 计算机网络 DeadReckoningDR 算法 神经网络 函数 型 连接 中图法 分类号 　 TPRealtimePredictionBasedonNeuralnetworksinDistributedVirtualEnvironmentSHOULidanSHILieSHIJiaoyingStateKeyLaboratoryofCADCGZhejiangUniversityHangzhouDepartmentofComputerScienceandEngineeringZhejiangUniversityHangzhouAbstract 　 InadistributedvirtualenvironmentDVEthebottleneckofperformanceisthecommunicationamonghostswhichkeepstheconsistencyofvirtualentitiesTheneuralnetworkmodelsofstatevectorsforunpredictableentitiesinavirtualscenearebuildinthispaperandthefunctionallinknettorealtimepredictionoftheirbehaviorisappliedFirstlytheprinciplesandcharactersoffunctionallinknetareintroducedinthispapersecondlyafterdescriptionofthetraditionaldeadreckoningDRalgorithmanadaptiveversionofthealgorithmbasedonfunctionallinknetispresentedthenetworksoftwarearchitecturebasedonthealgorithmisalsogivenfinallyanexampleofthealgorithmisgivenwithexperimentaldatawhichshowsthegoodperformanceofitKeywords 　 Distributedvirtualenvironmentcomputernetworksdeadreckoningneuralnetworkfunctionallinknet 　 　 分布式 虚拟环境 distributedvirtualenvironment 是 指 在 一组 以 网络 互联 的 计算机 上 同时 运行 虚拟环境 VE 系统 的 技术 它 是 虚拟环境 与 网络 技术 学科 交叉 的 产物 可以 使 人们 自由 地 在 虚拟环境 中 实现 交互 而 不 受 其 实际 地理位置 的 制约 从而 可 在 许多 科研 和 应用领域 中 使用 如 远程 学习 、 计算机 支持 下 的 协同工作 CSCW 、 分布式 模拟 distributedsimulation 等 各种 应用 分布式 虚拟环境 的 理论 和 概念 还 派 生出 了 许多 新 的 领域 如 远程 机器人 telerobotics 、 远程 诊治 telemedicine 等 分布式 虚拟环境 是 目前 最 热门 的 研究 领域 之一 在 科学研究 、 模拟训练 、 战场 仿真 等 许多 方面 有 广阔 的 应用 前景 　 　 在 分布式 虚拟环境 中 最 根本 的 要求 是 每时每刻 都 要 保持 分布式系统 各 主机 间 场景 和 场景 中 各 虚拟 实体 行为 的 一致性 以 维护 整个 系统 的 统一 因此 这 就 需要 各 主机 之间 实时 地 交换 大量 的 状态 信息 由此 而 引起 的 通信量 往往 占 分布式 虚拟环境 实体 间 总 通信量 的 大部分 这 一类 通信 我们 称为 一致性 通信 一致性 通信 数据 的 发送者 称为 参考 系统 （ 或 标准 系统 ） 接收者 称为 从属 系统 在 场景 复杂度 较 高 （ 如 数万 ～ 数十万 实体 ） 或 系统 规模 较大 （ 数百 ～ 数千台 主机 ） 的 情况 下 ［ ］ 一致性 通信 往往 会 导致 网络 环境 的 拥塞 乃至 崩溃 因此 降低 一致性 通信量 是 分布式 虚拟环境 中 的 一个 重要 研究课题 　 　 近年来 已有 许多 研究 工作 在 该 方向 上 展开 ［ ］ ［ ］ 其中 常用 的 方法 是 采用 自动控制 理论 中 的 DR 算法 对 虚拟 场景 中 的 实体 行为 进行 预测 减少 一致性 通信 的 次数 从而 达到 降低 网络带宽 的 目的 它们 的 基本 思想 是 在 参考 系统 和 从属 系统 上 采用 完全一致 的 预测 算法 根据 虚拟 实体 的 状态 历史 对 下 一 时刻 的 状态 进行 预测 如果 预测 结果 与 实际 状态 相差不远 则 在 参考 系统 端 不 发送 下 一 时刻 的 一致性 数据 从属 系统 中下 一 时刻 的 状态 就 用 预测 所得 结果 代替 反之 若 与 实际 相差 较远 则 发送 实际 状态 的 数据 即 进行 一致性 通信 这 类 预测 所 工作 的 对象 一般 有 一个 共同 的 特征 即 其 状态 向量 可用 一个 简单 的 时间 函数 表示 但是 实际 的 虚拟 场景 中 往往 存在 许多 实体 其 状态 向量 无法 用 一个 简单 的 函数 来 表示 这 类 对象 一般 较 智能化 直接 受到 人 的 控制 因此 随意性 很大 对于 这 类 实体 传统 的 DR 算法 无能为力 这 就 需要 另辟 途径 来 对 其 进行 研究 在 本文 中 我们 使用 基于 函数 型 连接 的 神经网络 来 对 虚拟 实体 进行 实时 的 预测 得到 了 较 好 的 效果 大大降低 了 一致性 通信量 （ 在 本文 中 为了 避免 混淆 我们 用 网络 一词 表示 多台 主机 之间 的 计算机网络 而用 神经网络 一词 表示 抽象 的 人工神经网络 ） 函数 型 连接 简介 　 　 在 函数 型 连接 模型 中 一旦 一个 节点 例如 节点 k 被 激励 就 会 有 许多 附加 函数 功能 也 被 激励 即 不仅 能 得到 节点 k 的 输出 ok 而且 还 能 得到 fokfokfnok ［ ］ 对 函数 型 连接 的 不同 具体 要求 会 产生 不同 的 效果 在 本文 中 我们 考虑 函数 展开 模型 和 张量 （ 或称 外积 ） 模型 　 　 在 函数 展开 模型 中 函数 型 连接 单独 作用 在 每个 节点 上 对于 输入 模式 中 的 每个 节点 它 产生 相同 的 附加 函数 在 这种 情况 下 输入 x 可以 简单 地 展开 成 它 的 幂函数 或者 是 展开 成 n 维空间 的 正交 基 函数 的 一个 子集 例如 sin π xcos π xsin π xcos π x 等等 该 神经网络 的 作用 是 将 输入 模式 映射 到 一个 更大 的 模式 空间 我们 将 输入 分量 与其 展开 的 量 联系 起来 并用 它们 来 表达 输入 这样 做 没有 引入 本质性 的 新 信息 但 模式 表达 可以 得到 增强 　 　 在 张量 或 外积 模型 中 输入 模式 的 每个 分量 都 被 乘 上 整个 输入 模式 矢量 在 这种 情况 下 原来 由 分量 集合 xi 所 描述 的 模式 变成 xixixj 其中 j ≥ i 或 xixixjxixjxk 其中 j ≥ ik ≥ j ≥ i 等等 这样 做 没有 引入 新 的 信息 但是 它 可 使 神经网络 得到 联合 激励 　 　 在 这 两种 模型 中使 表达 增强 的 运算 可以 适当 地 混用 通过 函数 变换 后 的 神经网络 由于 其 输入 得到 了 增强 仅 使用 规则 和 单层 神经网络 就 可 使 学习 过程 迅速 收敛 ［ ］ 对 输入 节点 个数 不 超过 样本 个数 较 少 （ 个 以内 ） 的 小规模 学习 问题 只 需 不到 次 即可 使 系统误差 小于 例如 考虑 一个 输入 （ xxx 单 输出 y 的 学习 问题 组 学习 样本 见 表表 三 输入 单 输出 学习 样本 集 样本 序号 xxxy 　 　 可以 采用 混合型 函数 展开 项 xxxxxxxxxcos π xcos π xcos π xxcos π xxcos π xxcos π xxcos π xxcos π xx 等 项 采用 单层 拓扑 结构 即可 使 神经网络 迅速 收敛 如图所示 图 　 三 因素 函数 型 网络 的 学习 速度 　 　 从图 中 可以 看出 在 多 因素 情况 下 采用 扩展 的 输入 项可 使得 学习 的 收敛 速度 大大提高 同时 该 神经网络 采用 了 单层 的 结构设计 简单 编程 方便 学习 时间 极短 （ 在 PentiumMHz 机器 上 不到 ms ） 因此 可以 满足 实时 预测 的 需求 基于 函数 型 连接 的 预测 算法 　 　 在 分布式 虚拟环境 中 已经 有 许多 有关 虚拟 实体 状态 向量 的 预测 算法 的 研究 这 类 算法 统称 为 DR 算法 一个 典型 的 DR 预测 算法 是 在 参考 系统 和 从属 系统 两端 都 使用 Kalman 预测器 ［ ］ 根据 其 运动 的 状态方程 在 每 一次 时钟 周期 时 检查 其 预测 结果 与 实际 状态 的 误差 如该 误差 超过 一个 约定 的 阈值 则 进行 一致性 通信 否则 省去 该次 时钟 周期 内 的 一致性 通信 　 　 在 动态 的 虚拟 场景 中 许多 运动 实体 常常 遵循 一定 的 规律 运动 但是 也 有 一些 实体 的 运动 没有 明显 的 规律 可循 即 无法 用 状态方程 表示 其 运动 举 一些 简单 的 例子 如 鼠标 的 移动 、 数据 手套 的 动作 等 这些 对象 的 运动 往往 受到 智能型 用户 的 直接 控制 因而 其 状态 改变 的 随意性 较大 换句话说 这 类 对象 的 状态 较难 预测 如果 将 这类 对象 中 的 某 一个 看做 一个 系统 则 往往 不 可能 找到 一个 确定 的 状态方程 来 描述 它 此时 我们 可以 求助于 神经网络 　 　 在 第节 中 我们 已 简单 地 介绍 了 基于 函数 型 连接 的 神经网络 这种 神经网络 的 优越性 使得 它 可 胜任 实时 的 预测 算法 的 基本原理 是 对于 难 预测 对象 而言 在 长时间 内其 运动 状态 往往 显得 较 混乱 而 无规律 但是 我们 有 理由 认为 （ 算法 的 实验 也 确实 表明 了 这 一点 ） 在 一段 短时间 内 对象 的 运动 遵循 某种 难以确定 的 规律 这种 规律 是 随着 时间 而 改变 的 但是 状态 对于 时间 的 变化 总是 连续函数 因此 在 有限 的 自变量 范围 内 根据 有限 个 样本 总 可以 用 若干个 确定 的 正交 基 函数 的 线性 表示 来 逼近 ［ ］ 这 也 是 函数 型 连接 的 理论 基础 这些 正交 基 函数 正是 函数 型 连接 中 的 函数 展开 项 例如 提供 k 组 样本 集合 XmXmXmrymrXmXmXmrymrXmkXmkXmkrymkr 其中 ymi 恰好 就是 Xmiirkr 则 可以 选取 适当 的 神经网络 经过 学习 后 使得 神经网络 输出 向量 y ′ mi 与 样本 集合 中 的 ymi 一致 因此 可以 看出 这里 的 每组 样本 实际上 是 根据 前 r 个 状态 预测 第 r 个 状态 由 该组 样本 训练 而成 的 神经网络 可以 用来 预测 ymkr 的 值 　 　 由于 对象 状态 不停 地 改变 这 就 需要 实时 地 对 预测器 进行 调整 包括 修改 学习 样本 集 并 进行 再 学习 这样 我们 可以 在 传统 的 DR 算法 基础 上 得到 另 一种 算法 这种 算法 可以 称为 基于 学习 的 自 适应 DR 算法 由于 自 适应 DR 算法 能 对 运动 方程 不 确定 的 对象 进行 预测 因此 特别 适用 于 难 预测 对象 在 给出 算法 描述 之前 我们 先对 符号 表示 作 一些 约定 我们 用 k 维 向量 XxxxkT 表示 被 考察 对象 的 状态 向量 用 Xn 表示 tn 时刻 对象 的 状态 向量 第 i 组 学习 样本 用 含有 r 个 状态 向量 的 矩阵 SiXmiXmiXmirYi 表示 其 含义 是 前 r 个 状态 向量 预测 产生 函数 型 连接 的 输出 状态 向量 yi 学习 样本 集 η 如下 SiiN 　 　 整个 系统 分为 参考 端 （ 标准 端 ） 和 从属 端 参考 端的 预测 算法 如下 　 　 算法 参考 端的 预测 算法 　 　 Step 用伪 随机数 构造 样本 集 η SiiN 　 　 Step 用 该组 样本 集合 对 神经网络 进行 训练 学习 Step 将 过去 的 r 个 时间 点 的 状态 历史 序列 XnrXnrXn 作为 函数 型 神经网络 的 r 个 输入 计算 输出 向量 即 预测 结果 ） n 　 　 Step 接收 到 下 一个 时间 同步 信号 （ tn 时刻 ） 如果 ‖ Xnn ‖ ＞ ε 则 将 新 状态 向量 Xn 的 数据 通过 计算机网络 环境 发送到 预测 端 并 将 状态 Xn 加入 历史 序列 同时 用 新 样本 SXnrXnrXnXn 代替 η 中 最 老 的 样本 否则 不 发送数据 而 将 预测 向量 n 当作 tn 时刻 的 状态 加入 状态 历史 序列 同时 用 SXnrXnrXn 更新 样本 集 η 　 　 Step 无条件 跳转 至 Step 依次 无限 循环 执行 Step ～ 各步 操作 　 　 由 算法 的 描述 可知 每 收到 一个 时钟 信号 算法 就 循环 一次 上述 算法 的 Step 中 需要 忽略 最初 的 r 次 循环 因为 最初 r 次 循环 时 不 存在 长度 为 r 的 历史 序列 另外 每次 循环 都 要 改变 相应 序列 的 下标 这些 说明 同样 也 适用 于 从属 端的 算法 从属 端的 算法 可以 表示 如下 　 　 算法 从属 端的 预测 算法 　 　 Step 用 与 算法 相同 的 伪 随机数 构造 样本 集 η SiiN 　 　 Step 用 该组 样本 集合 对 神经网络 进行 训练 学习 　 　 Step 将 过去 的 r 个 时间 点 的 状态 历史 序列 XnrXnrXn 作为 函数 型 神经网络 的 r 个 输入 计算 输出 向量 即 预测 结果 ） n 　 　 Step 接收 到 下 一个 时间 同步 信号 （ tn 时刻 ） 如果 在此之前 收到 参考 端的 数据包 则 将 收到 的 新 状态 Xn 加入 历史 序列 同时 用 新 样本 SXnrXnrXnXn 代替 η 中 最 老 的 样本 否则 即 未 收到 数据包 则 将 预测 向量 n 当做 tn 时刻 的 状态 加入 状态 历史 序列 同时 用 SXnrXnrXn 更新 样本 集 η 　 　 Step 无条件 跳转 至 Step 依次 无限 循环 执行 Step ～ 各步 操作系统 的 软件结构 　 　 根据 上节 中 所 给出 的 算法 我们 可以 设计 出 相应 的 网络软件 结构 如图所示 图 　 基于 神经网络 　 　 对应 于 一个 实体 i 参考 端 主机 上 有 一个 神经网络 预测器 其 内部 运行 算法 与 它 相对 应 从属 端 主机 上 必然 存在 一个 相应 的 从属 实体 i ′ 和 神经网络 预测器 该 预测器 执行 算法 图中 FLNN 是 基于 函数 型 连接 的 神经网络 的 缩写 由于 分布式 虚拟环境 中 主要 的 性能 限制 来自 网络带宽 瓶颈 从 该软件 结构图 可以 看出 采用 神经网络 预测器 的 实质 是 用 消耗 计算资源 的 方法 来 降低 对 网络资源 的 需求 基于 函数 型 连接 的 神经网络 具有 极高 的 收敛 速度 （ 多数 情况 ＜ ms ） 因此 当 实体 个数 较大 时 预测 过程 所 消耗 的 单机 计算资源 仍然 不 多 可见 该 预测 算法 提供 了 良好 的 可扩展性 对于 目前 计算机领域 内 很 热门 的 大规模 分布式 虚拟环境 ［ ］ （ LargeScaleDistributedVirtualEnvironment ） 具有 参考价值 实验 结果 　 　 由于 我们 所 关心 的 实体 行为 是 “ 难以预测 ” 的 实体 行为 的 宏观 表现 较 混乱 所以 往往 不 需要 保留 很长 的 状态 历史 序列 一般 只 需 不到 个 另外 我们 所 考察 的 虚拟 实体 在 虚拟空间 中 函数 型 连接 的 学习 过程 非常 迅速 在 样本 个数 不 超过 个 只 需要 ～ 次 循环 学习 即可 使 神经网络 收敛 当 输入 的 状态 向量 个数 不 超过 个 时 这样 的 计算 量 在 目前 的 高档 PC机 上 只 需 不到 ms 的 时间 因此 该 算法 完全 可以 用于 实时 的 预测 　 　 我们 对 空间 自由度 为 的 鼠标 进行 了 实验 硬件平台 是 用 Mbps 的 以太网 互连 的 台 PentiumMhz 的 PC机 软件平台 采用 MSWindows 实验 对象 是 名 熟练 用户 另外 我们 对 同样 的 数据 使用 二次 多项式 插值 来 预测 作为 对照 在 该 实验 的 神经网络 预测 算法 中 r 值取 为 样本 集所含 的 样本 个数 N 为 因此 我们 可以 建立 含有 二个 输入 向量 一个 输出 向量 的 函数 型 神经网络 设 两个 输入 向量 分别 为 xnyn 和 xnyn 则 对 该 两个 向量 作 如下 维 的 混合型 函数 展开 xnynxnynxnynxnxnynxnxnynxnynxnynxnyncos π xncos π yncos π xncos π yncos π xnyncos π xnyncos π xnyncos π xnyn 并 实时 预测 新 的 状态 向量 xnyn 结果 如图所示 图 　 预测 算法 对个 用户 的 鼠标 使用 的 结果 　 　 实验 结果表明 该 算法 对 所有 用户 所 操纵 的 鼠标 都 能 很 好 地 进行 预测 而且 该 算法 的 预测 精度 优于 多项式 插值 的 预测 算法 产生 这种 结果 的 原因 是 由于 神经网络 预测器 能够 实时 地 修改 其权值 使 之 在 不同 的 时刻 进行 自 适应 在 模拟 实体 数目 较大 的 情况 下 （ 例如 个 ） 算法 可以 节省 ～ 的 一致性 通信量 对 所有 实体 进行 一次 预测 消耗 CPU 时间 ～ s 但是 对于 大规模 系统 实体 数 ＞ 模拟 测试表明 消耗 在 预测 算法 上 的 计算 量 特别 巨大 这 就 需要 强大 的 单机 计算能力 的 支持 另外 对于 传统 DR 算法 的 预测 对象 即 状态 可 表示 为 显式 时间 函数 的 实体 该 神经网络 算法 也 可 很 好 地 进行 预测 本文 不再 赘述 结论 　 　 （ ） 函数 型 连接 是 一种 采用 函数 并行 激励机制 的 神经网络 这种 神经网络 的 特点 是 采用 单层 拓扑 结构 和 δ 学习 规则 因而 收敛 速度 非常 高 本文 给出 了 一个 基于 函数 型 连接 的 神经网络 预测 算法 用于 对 分布式 虚拟环境 中 的 实体 状态 进行 实时 的 预测 克服 了 传统 的 DR 算法 对难 预测 对象 无法 建立 其 控制论 模型 的 缺点 实验 结果表明 对 自由度 为 二 的 鼠标 该 算法 可以 很 好 地 工作 　 　 （ ） 在 分布式 虚拟环境 中 主要 的 性能 瓶颈 是 网络带宽 文中 所述 的 基于 函数 型 连接 的 神经网络 预测 算法 降低 了 网络带宽 的 消耗 有助于 提高 整个 系统 的 性能 和 可扩展性 本文 通讯联系 人寿 黎 但 杭州 浙江大学 CADCG 国家 重点 实验室 作者简介 ： 寿黎 但 年生 硕士生 主要 研究 领域 为 CSCW 多媒体 大规模 分布式 虚拟环境 史烈 年生 讲师 主要 研究 领域 为 多媒体 虚拟现实 石教 英年生 教授 博士生 导师 主要 研究 领域 为 计算机 图形学 计算机 体系结构 虚拟现实 作者 单位 ： 寿黎 但 　 浙江大学 CADCG 国家 重点 实验室 杭州 史烈 石教英 　 浙江大学 计算机科学 与 工程学系 杭州 参考文献 PentlandAPComputationalcomplexityversussimulatedenvironmentsComputerGraphics ～ PrattDRAsoftwarearchitecturefortheconstructionandmanagementofrealtimevirtualenvironments ［ PhDThesis ］ MontereyCaliforniaNavalPostgraduateSchoolMacedoniaMRAnetworksoftwarearchitectureforlargescalevirtualenvironments ［ PhDThesis ］ MontereyCaliforniaNavalPostgraduateSchool 美包 约翰 自 适应 模式识别 与 神经网络 北京 科学出版社 PaoYohhanAdaptivePatternRecognitionandNeuralnetworksMassachusettsMenloParkAddisonWesleyPublishingCompanyInc ～ PaoYohhanYoshiyasuTakefujiFunctionallinknetcomputingtheorysystemarchitectureandfunctionalitiesComputer ～ BaumgartnerEricTSkaarStevenBAnautonomousvisionbasedmobilerobotIEEETransactionsonAutomaticControl ～ 本文 收到 原稿 收到 修改稿