信息 与 控制 InformationandControl 年 　 第卷 　 第期 　 Vol 　 No 　 神经网络 理论 的 发展 与 前沿 问题 刘永红 　 　 摘 　 要 　 系统地 论述 了 神经网络 理论 发展 的 历史 和 现状 ， 在 此基础 上 ， 对 其 主要 发展趋向 和 所 涉及 的 前沿 问题 进行 了 阐述 ． 文中 还作 了 一定 的 评论 ， 并 提出 了 新 的 观点 ． 　 　 关键词 　 神经网络 理论 ， 神经计算 ， 进化 计算 ， 基于 神经科学 和 数学 的 研究 THEDEVELOPMENTANDFORWORDPROBLEMSOFNEURALNETWORKTHEORYLIUYonghongDeptofAutomationWuhanUniversityofTechnologyWuhanAbstract 　 ThisisasurveypaperofthedevelopmentandforwordproblemsofneuralnetworktheoryItisdividedintofourpartsIntroductiontoneuralnetworkThehistoryandpresentconditionThedevelopmenttrendandforwordproblemsConclusionsInthepaperanewcommentandviewforneuralnetworktheoryispresentedKeywords 　 neuralnetworktheoryneuralcomputingevolutionarycomputingstudybasedonneurosciencesandmathematics 　 引言 　 　 神经网络 是 一门 活跃 的 边缘性 交叉学科 研究 它 的 发展 过程 和 前沿 问题 ， 具有 重要 的 理论意义 　 　 神经网络 理论 是 巨量 信息 并行处理 和 大规模 平行 计算 的 基础 ， 神经网络 既 是 高度 非线性 动力学 系统 ， 又 是 自 适应 组织系统 ， 可用 来 描述 认知 、 决策 及 控制 的 智能 行为 ． 它 的 中心 问题 是 智能 的 认知 和 模拟 ． 从 解剖学 和 生理学 来看 ， 人脑 是 一个 复杂 的 并行 系统 ， 它 不同于 传统 的 Neumann 式 计算机 ， 更 重要 的 是 它 具有 “ 认知 ” “ 意识 ” 和 “ 感情 ” 等 高级 脑 功能 ． 我们 以 人工 方法 摸拟 这些 功能 ， 毫无疑问 ， 有助于 加深 对 思维 及 智能 的 认识 ． 年代 初 ， 神经网络 的 崛起 ， 已 对 认知 和 智力 的 本质 的 基础 研究 乃至 计算机 产业 都 产生 了 空前 的 刺激 和 极大 的 推动 作用 ． 　 　 近十年 来 ， 神经网络 理论 与 实践 有 了 引人注目 的 进展 ， 它 再 一次 拓展 了 计算 概念 的 内涵 ， 使 神经计算 、 进化 计算 成为 新 的 学科 ， 神经网络 的 软件 模拟 得到 了 广泛 的 应用 ． 近几年来 科技 发达国家 的 主要 公司 对 神经网络 芯片 、 生物芯片 独有情钟 ． 例如 Intel 公司 、 IBM 公司 、 ATT 公司 和 HNC 公司 等 已 取得 了 多项 专利 ， 已有 产品 进入 市场 ， 被 国防 、 企业 和 科研部门 选用 ， 公众 手中 也 拥有 神经网络 实用化 的 工具 ， 其 商业化 令人鼓舞 ． 尽管 神经 计算机 、 光学 神经 计算机 和 生物 计算机 等 研制 工作 的 艰巨性 和 长期性 ， 但 有 一点 可以 使人 欣慰 ： 它 现在 还 只是 初露锋芒 ， 有 巨大 的 潜力 与 机会 ， 前景 是 美好 的 ． 　 　 事实上 ， 探究 大脑 — 思维 — 计算 之间 的 关系 还 刚刚开始 ， 道路 还 十分 漫长 ， 关于 脑 的 计算 原理 及其 复杂性 ； 关于 学习 、 联想 和 记忆 过程 的 机理 及其 模拟 等 方面 的 研究 已 受到 人们 的 关注 ， 它 未来 的 发展 必将 是 激动人心 的 ． 神经网络 理论 的 前沿 问题 将 渗透 在 世纪 科学 的 挑战性 问题 中 ， 可能 取得 重大 的 突破 ． 　 发展 历史 及 现状 　 　 神经网络 诞生 半个 多 世纪 以来 ， 经历 了 个 阶段 ： 　 　 奠基 阶段 早 在 年代 初 ， 神经 解剖学 、 神经 生理学 、 心理学 以及 人脑 神经元 的 电 生理 的 研究 等 都 富有成果 ． 其中 ， 神经 生物学家 McCulloch 提倡 数字化 具有 特别 意义 ． 他 与 青年 数学家 Pitts 合作 ［ ］ ， 从 人脑 信息处理 观点 出发 ， 采用 数理 模型 的 方法 研究 了 脑细胞 的 动作 和 结构 及其 生物 神经元 的 一些 基本 生理 特性 ， 他们 提出 了 第一个 神经计算 模型 ， 即 神经元 的 阈值 元件 模型 ， 简称 MP 模型 ， 他们 认识 到 了 模拟 大脑 可 用于 逻辑 运行 的 网络 ， 有 一些 结点 ， 及 结点 与 结点 之间 相互 联系 ， 构成 一个 简单 神经网络 模型 ． 其 主要 贡献 在于 ， 结点 的 并行计算 能力 很强 ， 为 计算 神经 行为 的 某此 方面 提供 了 可能性 ， 从而 开创 了 神经网络 的 研究 ． 这一 革命性 的 思想 ， 产生 了 很大 影响 ． 　 　 举例 说 ， 数学家 Kleene 在 此基础 上 抽象 成 一种 有限 自动机 理论 ． Wiener 是 控制论 的 创始人 之一 ， 年 他 出版 了 著名 专著 Cybernetics ［ ］ 探讨 了 动物 和 机器 的 控制 和 通讯 问题 ， 他 在 年 增补 了 两章 内容 ， 主要 是 讨论 学习 和 自 生殖 问题 ， 他 选择 机器 学习 下棋 问题 作为 研究 对象 ， 对 脑电波 与 自 组织系统 进行 了 探索 ． 尤其 是 ， MP 模型 是 最终 导致 Neumann 电子计算机 诞生 的 重要 因素 之一 ， 数学家 Neumann ［ ］ 是 现代 计算机科学 的 创始人 之一 ， 又 是 最初 的 神经网络 设想 者 之一 ． 他 研究 了 自我 繁衍 自动机 ， 而且 证明 了 至少 存在 一种 确实 能够 自我 繁衍 的 分子 自动机 模型 ， 年 他 提出 了 元胞 自动机 ， 可用 来 模拟 生命 系统 所 具有 的 自 复制 功能 ， 还 可用 来 模拟 其他 的 自然 现象 ． 但 有 很多 元胞 自动机 也 并不一定 对 某个 连续 系统 的 离散 化 描述 得 好 ． 于是 ， Neumann 又 设想 一种 新 的 计算机 ： 基于 自动机 理论 、 自然 和 人工智能 知识 的 计算机 ． 　 　 此外 ， 数学家 Turing 建立 了 通用 计算机 的 抽象 模型 ［ ， ］ ， 他 和 Post ［ ］ 都 证明 了 一个 重要 定理 ： 原则上 存在 着 一种 “ 万能 自动机 ” ， 它 能 识别 任何 别的 自动机 能够 识别 的 符号串 ． Turing 机 理论 ， 为 带有 存贮 程序 的 计算机 的 形式 程序语言 的 发明 提供 了 理论 框架 ． 重要 的 是 ， 他 研究 了 算法 而 不是 公理 系统 的 效率 ． 并行处理 和 串行 处理 在 原则上 尽管 相同 ， 但 区别 在于 ， 整个 计算 的 效率 或 速度 不同 ． 值得注意 的 是 ， Turing 机和 逻辑 神经网络 之间 或多或少 的 等 价值 得到 了 证明 ， 使 人们 对于 大脑 和 计算机 之间 的 类似性 的 信念 进一步 加强 了 ． 可惜 当时 人们 认为 这种 类似 都 是 基于 逻辑 单元 的 相似性 ， 而 作为 信息处理 工具 的 神经系统 ， 人们 还 缺乏 认识 ． 　 　 年 神经 生物学家 Hebb ［ ］ 的 论著 TheOrganizationofBehavior ， 对 大脑 神经细胞 、 学习 与 条件反射 作 了 大胆 地 假设 ， 称为 Hebb 学习 规则 ． 他 的 基本 思想 是 ， 假设 大脑 经常 在 突触 上 做 微妙 的 变化 ， 突触 联系 强度 可变 是 学习 和 记忆 的 基础 ， 其 强化 过程 导致 了 大脑 自 组织 形成 细胞 集合 几千个 神经元 的 子 结合 ， 其中 循环 神经 冲动 会 自我 强化 ， 并 继续 循环 ， 任何 一个 神经元 同 属于 多个 细胞 集合 ， 可以 说 ， 细胞 集合 是 大脑 思维 信息 的 基本 量子 ． 他 给出 了 突触 调节 模型 ， 描述 了 分布 记忆 ， 它 后来 被 称为 关联 论 connectionist ． 由于 这种 模型 是 被动 学习 过程 ， 并 只 适用 于 正交 矢量 的 情况 ， 后来 研究者 把 突触 的 变化 与 突触 前后 电位 相关联 ， 在 他 的 基础 上作 了 变形 和 扩充 ． 说明 Hebb 对 神经网络 的 发展 起到 了 重大 的 推动 作用 ， 至今 仍然 被 人们 引证 ． 　 　 年代 初 ， 神经网络 理论 具备 了 初步 模拟实验 的 条件 ． Rochester ， Holland 与 IBM 公司 的 研究 人员 合作 ， 他们 通过 网络 吸取经验 来 调节 强度 ， 以 这种 方式 模拟 Hebb 的 学习 规则 ， 在 IBM 计算机 上 运行 ， 取得 了 成功 ， 终于 出现 了 许多 突现 现象 ， 几乎 有 大脑 的 处理 风格 ． 但 ， 最 大规模 的 模拟 神经网络 也 只有 个 神经元 ， 而 每个 神经元 又 只有 个 结合点 ． 再往 下 做 试验 ， 便 受到 计算机 的 限制 ． Hebb 的 学习 规则 理论 还 影响 了 正在 IBM 实习 的 研究生 McCarthy ， 他 参入 IBM 的 一个 小组 ， 探讨 有关 游戏 的 智能 程序 ， 后来 他 成为 人工智能 的 主要 创始人 之一 ． 人工智能 的 另 一个 主要 创始人 Minsky 于 年 对 神经系统 如何 能够 学习 进行 了 研究 ， 并 把 这种 想法 写入 他 的 博士论文 中 ， 后来 他 对 Rosenblatt 建立 的 感知器 Perceptron 的 学习 模型 作 了 深入分析 ． 　 　 年 英国 生物学家 Hodgkin 和 Huxley 建立 了 长 枪乌贼 巨大 轴索 非线性 动力学 微分方程 ， 简称 HH 方程 ， 形 如 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 解释 略 ． 由于 Hodgkin 和 Huxley 研究 的 成果 有 重大 理论 及 应用 价值 ， 他们 荣获 了 诺贝尔 生理 医学奖 ． 他们 的 著名 方程 引起 了 许多 学者 的 关注 ， 方程 中 包含 了 丰富 的 内容 ， 对 理论 和 实践 产生 了 极大 的 作用 ， 有些 学者 对 HH 方程 研究 得到 了 很多 有 意义 的 结果 ． 如 ， 发现 了 神经 膜 中 所 发生 的 非线性 现象 ： 自激振荡 、 混沌 及 多重 稳定性 等 ， 几乎 都 可用 这个 方程 来 描述 ． 　 　 年 生理学家 Eccles 提出 了 真实 突触 的 分流 模型 ［ ］ ， 并 通过 突触 的 电 生理 实验 得到 证实 ． 其 重要 意义 是 ， 为 神经网络 模拟 突触 的 功能 提供 了 原型 和 生理学 的 证据 ． 年 Uttley 发明 了 一种 由 处理单元 组成 的 推理机 ， 他称 这种 处理单元 为 信息 子 informon ， 用 推理机 模拟 行为 及 条件反射 现象 ． 它 是 一种 线性 分离器 ， 利用 Shannon 的 熵 值 与 输入输出 概率 之 比 的 自然对数 来 调节 其 输入 参数 ． 他 在 年代 中期 把 它 应用 于 自 适应 模式识别 ， 他 认为 这种 模型 是 实际 神经系统 的 工作 原理 ， 并 出版 了 专著 InformationTransmissionintheNervousSystem ． 　 　 第一次 高潮 阶段 ． 　 年 计算机 科学家 Rosenblatt ［ ］ 基于 MP 模型 ， 增加 了 学习 机制 ， 推广 了 MP 模型 ． 他 证明 了 两层 感知器 能够 将 输入 分为 两类 ， 假如 这 两种 类型 是 线性 并 可分 ， 也 就是 一个 超平面 能 将 输入 空间 分割 ， 其 感知器 收敛 定理 ： 输入 和 输出 层 之间 的 权重 的 调节 正比 于 计算 输出 值 与 期望 输出 之差 ． 他 提出 的 感知器 模型 ， 首次 把 神经网络 理论 付诸 工程 实现 ． 例如 ， 年 到 年间 在 他 的 帅 领下 完成 了 第一台 真正 的 神经 计算机 ， 即 ： Mark Ⅰ 的 感知器 ． 他 还 指出 了 带 隐层 处理 元件 的 层 感知器 这一 重要 的 研究 方向 ， 并 尝试 将 两层 感知器 推广 到层 ． 但 他 未能 找到 比较 严格 的 数学方法 来 训练 隐层 处理单元 ． 这种 感知器 是 一种 学习 和 自 组织 的 心理学 模型 ， 其 结构 体现 了 神经 生理学 的 知识 ． 当 模型 的 学习 环境 有 噪音 时 ， 内部结构 有 相应 的 随机 联系 ， 这种 感知器 的 学习 规则 是 突触 强化 律 ， 它 可能 应用 在 模式识别 和 联想 记忆 等 方面 ． 可以 说 ， 他 的 模型 包含 了 一些 现代 神经 计算机 的 基本原理 ， 而且 是 神经网络 方法 和 技术 上 的 重大突破 ， 他 是 现代 神经网络 的 主要 建构 者 之一 ． Rosenblatt 之举 激发 了 许多 学者 对 神经网络 研究 的 极大 兴趣 ． 美国 上 百家 有 影响 的 实验室 纷纷 投入 这个 领域 ， 军方 给予 巨额 资金 资助 ， 如 ， 对 声纳 波 识别 ， 迅速 确定 敌方 的 潜水艇 位置 ， 经过 一段时间 的 研究 终于 获得 了 一定 的 成果 ． 这些 事实 说明 ， 神经网络 形成 了 首次 高潮 ． 　 　 年 Widrow 和 Hoff 提出 了 自 适应 线性元件 ADACINE 网络 模型 ［ ］ ， 是 一种 连续 取值 的 线性网络 ， 主要 用于 自 适应 系统 ． 他们 研究 了 一定 条件 下 输入 为 线性 可 分 问题 ， 期望 响应 与 计算 响应 的 误差 可能 搜索 到 全局 最小值 ， 网络 经过训练 抵消 通信 中 的 回波 和 噪声 ， 它 还 可 应用 在 天气预报 方面 ． 这是 第一个 对 实际 问题 起 作用 的 神经网络 ． 他们 还 对层 网络 进行 过 尝试 ， 但 仍 给 不出 数学 解 ． 可以 说 ， 他们 对 分段 线性网络 的 训练 有 一定 作用 ， 是 自 适应控制 的 理论 基础 ． Widrow 等 人 在 年代 ， 以此 为 基础 扩充 了 ADALINE 的 学习 能力 ， 年代 他们 得到 了 一种 多层 学习 算法 ． 　 　 在 神经网络 中 ， 出现 一种 持续 不 衰减 的 周期性 兴奋 波 ， 称为 回响 reverberation 现象 ． 人们 关心 的 问题 是 产生 回响 的 条件 ， 网络 的 参数 对 回响 的 周期 、 幅度 等 性质 的 影响 ， 以及 如何 通过 外部 来 控制 回响 波 ． 从而 利用 神经网络 的 节律 性 ， 并 解释 脑电波 中 的 α 节律 ． 年 意大利 科学家 Caianiello 基于 神经元 模型 ， 引入 了 不应期 特性 ， 提出 一个 神经 方程 　 　 式 中 ［ ］ 是 单位 阶跃 函数 ， Si 是 第 i 个 神经元 所 受到 的 外界 刺激 ， θ i 是 第 i 个 神经元 的 阈值 ， tr 是 过去 的 某 一 时刻 ， H 是 影响 网络 所 持续 的 最长 时间 ， Wijr 是 影响 权重 ， 它 有 兴奋性 和 抑制性 两种 输入 ． 该 方程 同时 考虑 神经元 的 空间 和 时间 性质 ， 而且 取 离散 值 ， 用 网络 内部结构 不变 的 方式 来 描述 神经网络 中 的 回响 现象 ． 它 的 局限性 在于 ， 不能 反映 学习 和 记忆 过程 ． 由于 该 方程 中 出现 一个 非线性 函数 ， 所以 用 它 研究 回响 现象 时 ， 就 会 遇到 一个 在 非线性 系统 中求 周期 解 的 问题 ， 而 这 是 一个 相当 复杂 的 问题 ． 随后 ， Caianiello 根据 Hebb 假说 ， 发展 了 他 自己 的 模型 ， 描述 了 学习 和 记忆 过程 中 重复 强化 因素 ， 以及 遗忘 过程 为 饱和 性质 ， 给出 了 一种 记忆 方程 　 　 有趣 的 是 ， Cainaniello 对脑 的 某 一 状态 所 对应 不同 的 参数 作 了 举例说明 ． 比如 ， 对应 于 理解 、 联想 、 忘记 、 睡眠 和 梦 等 出现 的 情况 ． 但 他 给出 的 方程组 很 难求 出 定量 解 ， 并且 还 未 与 神经系统 的 结构 相结合 ， 仅仅 对 神经系统 的 功能 作 一些 定性分析 ． 当然 ， 他 的 非线性 时变 方程组 ， 在 一些 简化 的 特殊 条件 下 可以 得到 解析 解 ． 所以 许多 学者 在 计算机 上用 模拟 方法 研究 这个 相当 复杂 的 问题 ． 　 　 年 Rosenblatt 对 他 的 感知器 作 了 总结 ［ ］ ． 还 有些 科学家 采用 其它 数学模型 ， 如 ， 用 代数 、 矩阵 等 方法 来 研究 神经网络 ． 值得一提的是 ， 我国 中科院 生物物理 所在 年 提出 用 矩阵 法 描述 一些 神经网络 模型 ． 他们 重点 研究 视觉 系统 信息 传递 过程 和 加工 的 机理 以及 建立 有关 数学模型 ． 此外 ， Fogel 、 Owens 和 Walsh 在 年 出版 了 一本 关于 进化 规划 的 专著 ArtificialIntelligienceThroughSimulatedEvolution ． 由于 该书 所 提倡 的 思想 方法 根本 不合 当时 人工智能 的 主流 ， 受到 学术界 的 怀疑 ， 一直 到 年代 初才 被 人们 重视 ． 　 　 年代 中 、 后期 ， Grossberg ［ ， ］ 从 信息处理 的 角度 ， 研究 了 思维 和 大脑 结合 的 理论 问题 ， 运用 数学方法 研究 自 组织性 、 自 稳定性 和 自 调节性 ， 以及 直接存取 信息 的 有关 模型 ． 他 建立 了 一种 神 网络结构 ， 即 ： 他 给出 的 内星 instar 、 外星 outstar 和 雪崩 avalanche 为 最小 的 结构 ． 他 提出 的 雪崩 网可 用于 空间 模式 的 学习 和 回忆 以及 时间 模式 的 处理 方面 ， 如 ， 执行 连续 语音 识别 和 控制 机器人 手臂 的 运动 ． 他 的 这些 成果 ， 对 当时 影响 很大 ， 有些 学者 与 Grossberg 合作 ， 他 组建 的 自 适应 系统 中心 取得 了 丰硕 的 成果 ， 几乎 涉及 到 神经网络 的 各个领域 ． 日本 神经网络 理论家 Amari 注重 生物 神经网络 的 行为 与 严格 的 数学 描述 相结合 ， 尤其 是 对 信任 分配 问题 的 研究 ， 得到 许多 重要 结果 ． Willshaw 等 人 ［ ］ 提出 了 一种 模型 ： 存贮 输入 信号 和 只 给出 部分 输入 ， 恢复 较完整 的 信号 ， 即 全息 音 holophone 模型 ． 这为 利用 光学 原理 实现 神经网络 奠定 了 理论 基础 ， 为 全息图 与 联想 记忆 关系 的 本质 问题 的 研究 开辟 了 一条 新途径 ． Nilsson 对 多层 机 ， 即 具有 隐层 的 广义 认知 机作 了 精辟 论述 ［ ］ ， 他 认为 网络 计算 过程 实质 上 是 一种 坐标 变换 或是 一种 映射 ． 他 已 对 这类 系统 的 结构 和 功能 有 比较清楚 的 认识 ． 但 他 没有 给出 一种 实用 的 学习 算法 ． 那时 ， 尚无 人 知道 训练 由 多层 阈值 逻辑 单元 TLUs 组成 的 多层 机 的 实用 方法 ． 年代 ， 美国 在 视感 控制 方面 曾 热过 一阵子 ， 由于 识别 视觉 特征 的 功能 一直 得不到 增强 ， 于是 受到 冷落 ， 主要 是 缺乏 理论 的 正确 指导 ． 不言而喻 ， 要 解决 这样 复杂 的 问题 就 应该 建立 它 的 基本 理论 ． 直到 年代 初 ， Ullman 指出 了 似 运动 机制 的 计算 理论 、 Marr 的 视觉 理论 ， 他们 为 这 一 领域 的 发展 奠定 了 坚实 的 理论 基础 ． 　 　 坚持 阶段 ． 　 神经网络 理论 那 遥远 但 并非 遥不可及 的 目标 着实 吸引 了 很多 人 的 目光 ， 美国 军方 认为 神经网络 工程 应当 比 “ 原子弹 工程 ” 更 重要 ， 并 对 它 的 投资 兴趣 非常 大 ， 而 对 其 实践 的 效果 也 比较满意 ． 这时 ， Minsky 警觉 的 是 ， 人工智能 的 发展 与 前途 问题 ． 以 顺序 离 符号 推导 为 其 基本特征 与 神经网络 大相径庭 ． 他 引发 学术界 的 争议 ， 导致 对 人工智能 投资 的 增加 ． 他 从 感知器 的 功能 及 局限性 入手 ， 在 数学 上 进行 了 分析 ， 证明 了 感知器 不能 实现 XOR 逻辑 函数 问题 ， 也 不能 实现 其它 的 谓词 函数 ． 他 认识 到 感知器 式 的 简单 神经网络 对 认知 群 不变性 无能为力 ． 年 Minsky 和 Papert 在 MIT 出版 了 一本 论著 Percertrons ， 对 当时 与 感知器 有关 的 研究 及其 发展 产生 了 恶劣 的 影响 ， 有些 学者 把 研究 兴趣 转移 到 人工智能 或 数字 计算机 有关 的 理论 和 应用 方面 ． 这样 ， 推动 了 人工智能 的 发展 ， 使 它 占 了 主导地位 ． 美国 在 此后 年里 从未 资助 神经网络 研究课题 ， 前 苏联 有关 研究 机构 也 受到感染 ， 终止 了 已经 资助 的 神经网络 研究 的 课题 ． 　 　 Minsky 对 感知器 的 评论 有 一定 启发性 ． 然而 更 多 的 是 他 的 偏爱 和 误导 ． 美国 科学家 Simon 甚至 在 年 出版 的 一本 论著 PatternsandOperators ： TheFoundationofDataRepresentation 中 还 在 判 感知器 死刑 ． 说明 他 对 神经网络 理论 在 年代 至 年代 初 有关 感知器 方面 的 成果 缺乏 了解 ． 更 遗憾 的 是 ， Minsky 和 Papert 没有 看到 日本 科学家 Amari 在 年 对 信任 分配 问题 的 数学 求解 这一 重要 成果 ． 如果 他们 知道 ， 写 那本书 就 会 谨慎 ， 也 就 绝对 不会 产生 当时 那种 影响 ． 后来 ， Minsky 出席 了 首届 国际 神经网络 会议 年 ， 他 发表演说 ： 过去 他 对 Rosenblatt 提出 的 感知器 下 的 结论 太早 又 太 死 ， 在 客观 上 ， 阻碍 了 神经网络 的 发展 ． 　 　 最有 意义 的 是 ， 仍然 有 少数 天才 的 具有 远见卓识 的 科学家 在 坚持 不断 的 研究 神经网络 理论 ， 有 的 科学家 在此期间 投入 到 这个 领域 ， 带来 了 新 的 活力 ． 他们 取得 了 理论 上 的 一系列 重要 成果 ． 举例 如下 ： 　 　 Holland 于 年 卷入 基因 遗传算法 及 选择 问题 的 数学方法 分析 和 基本 理论 的 研究 中 ， 经过 长期 探索 与 实践 ， 建立 了 遗传算法 理论 ［ ， ］ ． 遗传算法 是 一种 借鉴 生物界 自然选择 和 自然 遗传 机制 的 高度 并行 、 随机 、 自 适应 搜索算法 ， 从而 开拓 了 神经网络 理论 的 一个 新 的 研究 方向 ． 然而 ， 当时 产生共鸣 的 只有 他 指导 的 博士 和 人工智能 中 少数 的 学者 ， 在 计算机科学 世界 里 没有 把 他 的 “ 古怪 ” 的 理论 真的 当一回事 ． 与此同时 ， Holland 也 没有 把 自己 的 理论 应用 到 会 引起 广泛 注意 的 那些 实用 问题 并 可 争取 到 不少 的 投资 ． 他 从不 对 自己 的 理论 外廓 喧染 ， 而是 只顾 那种 兴趣 以及 他 的 研究进展 ． 当然 ， Holland 的 研究 与 人工智能 的 主流 研究 方向 正相反 ． 他 认为 学习 问题 和 来自 环境 的 反馈 问题 是 生物进化 的 根本 问题 ， 竞争 比 连贯 一致 更为 本质 ． 他 设计 的 分类器 系统 的 规则 会 随 时间 而 改变 和 进化 ， 这 很 重要 ， 并 在 计算机 上 模拟 了 突现 模型 ， 系统 具有 开采 — 探险 式 学习 能力 ． 后来 ， 他 的 一名 学生 Goldberg 博士 在 年 将 这个 理论 成功 的 应用 到 煤气管道 的 模拟系统 上 在 一些 心理学 实验 中 他 的 理论 也 得到 了 验证 ． 　 　 年 SteinLenngMangeron 和 Oguztoreli 提出 了 一种 连续 的 神经元 模型 ［ ］ ， 采用 泛函 微分方程 来 描述 各种 普通 类型 的 神经元 的 基本特征 ， 方程 形如式 中 把 t 时刻 规范化 的 轴突 冲动 频 xt ≤ xt ≤ 和 神经细胞 的 输入 ft 联系 起来 ． 常数 a ＞ ＜ p ＜ q 和 b 是 个别 神经元 的 特性 或 某 特殊 类 神经元 的 特性 ． 若 b 值取 负 通常 情况 ， 则 积分 项 表示 抑制 新 冲动 的 产生 ． 年 Heiden 研究 这个 方程 的 性质 ， 他 引入 变量 ， 即 把 他们 的 方程 化为 维 动力系统 ， 形 如 　 　 Heiden 得到 了 一些 重要 的 结论 ［ ］ ． 如 ， 该 系统 可 化为 竞争 系统 ， 方程 至少 有 一 周期 轨道 ， 其 Floquet 特征 乘数 的 模 不 大于 和 系统 存在 唯一 的 渐近 稳定 的 周期 轨道 等 ， 表明 神经元 中 存在 振荡 行为 ， 并且 还是 循环 的 ． 　 　 年 Grossberg ［ ］ 提出 自 适应 共振 理论 ART ， 这是 感知器 较 完善 的 模型 ， 即 superrised 学习 方式 ． 本质 上 说 ， 仍 是 一种 unsuperrised 学习 方式 ． 随后 ， 他 与 Carpenter 一起 研究 ART 网络 ， 它 有 两种 结构 ART 和 ART ， 能够 识别 或 分类 任意 多个 复杂 的 二元 输入 图像 ， 其 学习 过程 有 自 组织 和 自 稳定 的 特征 ， 一般 认为 它 是 一种 先进 的 学习 模型 ． 　 　 类似 的 情形 ： Werbos ［ ］ 提出 的 BP 理论 以及 提出 的 反向 传播 原理 ； Fukushima ［ ］ 提出 了 视觉 图象识别 的 Neocognitron 模型 ， 后来 他 重新 定义 了 NeocognitronAmari ［ ］ 对 神经网络 的 数学 理论 研究 受到 一些 学者 的 关注 ； Feldmann ， Ballard ， Rumelhart 和 McClelland 等 学者 致力于 连续 机制 ， 并行 分布 处理 PDP 的 计算 原则 和 算法 研究 ， 他们 提出 了 许多 重要 的 概念 和 模型 ； Rechenber 提出 了 进化 随机 策略 ， 并 成功 的 应用 到 物体 风洞试验 中 ； Kohonen 出版 了 一本 专著 AssociativeMemoryASystemTheoreticApproach 年 ， 他 阐述 了 全息 存储器 与 联想 存储器 的 关系 ， 详细 讨论 了 矩阵 联想 存储器 ， 这 两种 存储 都 是 线性 的 ， 并 以 互联 想 的 方式 工作 ， 实现 起来 比较 容易 ． 　 　 上述 研究成果 的 影响 在 扩大 ， 坚定 的 神经网络 理论家 仍 在 继续 研究 ， 为 掀起 第二次 高潮 作好 了 准备 ． 可以 肯定 ， 神经网络 理论 在 坚持 阶段 不仅 有 活力 ， 它 的 独立性 非常 强 ， 许多 论文 和 专著 将 逐步 融入 科学知识 中 ． 　 　 第二次 高潮 阶段 ． 　 Kohonen 提出 了 自 组织 映射 网络 模型 ［ ］ ， 映射 具有 拓扑 性质 ， 对 一维 、 二维 是 正确 的 ， 并 在 计算机 上 进行 了 模拟 ， 通过 实例 所 展示 的 自 适应 学习 效果显著 ． 他 认为 有 可能 推广 到 更 高维 的 情况 ． 当时 ， 他 的 自 组织 网络 的 局部 与 全局 稳定性 问题 还 没有 得到 解决 ． 值得一提的是 ， Hinton 和 Anderson 的 著作 ParallelModelsofAssociativeMemory 产生 了 一定 的 影响 ． 由于 理想 的 神经元 连接 组成 的 理论 模型 也 具有 联想 存储 功能 ， 因此 特别 有 意义 ． 这 类 神经网络 从 年代 初 就 有 学者 在 研究 ． 当然 ， 不同 时期 总有 新 的 认识 ． 年 生物 物理学家 Hopfield ［ ］ 详细 阐述 了 它 的 特性 ， 他 对 网络 存储器 描述 得 更加 精细 ， 他 认识 到 这种 算法 是 将 联想 存储器 问题 归结为 求 某个 评价 函数 极小值 的 问题 ， 适合 于 递归 过程 求解 ， 并 引入 Lyapunov 函数 进行 分析 ． 在 网络 中 ， 节点 间 以 一种 随机 异步 处理 方式 相互 访问 ， 并 修正 自身 输出 值 ， 可用 神经网络 来 实现 ， 从而 这 类 网络 的 稳定性 有 了 判据 ， 其 模式 具有 联想 记忆 和 优化 计算 的 功能 ． 并 给出 系统 运动 方程 ， 即 Hopfield 神经网络 的 神经元 模型 是 一组 非线性 微分方程 其中 ui 是 第 i 个 神经元 的 膜电位 ， Ci 、 Ri 分别 是 输入 电容 和 电阻 ， Ii 是 电路 外 的 输入 电流 ， Tij 是 第 J 个 神经元 对 第 i 神经元 的 联系 强度 ， fu 是 u 的 非线性 函数 ， 一般 取 S 型 曲线 或 阶跃 函数 ． 他 构造 出 Lyapunov 函数 ， 并 证明 了 在 TijTji 情况 下 ， 网络 在 平衡点 附近 的 稳定性 ， 并 对 这种 模型 以 电子电路 来 实现 ． 这样 ， 研究 取得 了 重大 的 突破 ， 对 神经网络 理论 的 发展 产生 了 深远 的 影响 ． 年 Hopfield 向 美国科学院 提交 了 关于 神经网络 的 报告 ， 其 主要 内容 是 ， 建议 收集 和 重视 以前 对 神经网络 所 做 的 许多 研究 工作 ， 他 指出 了 各种 模型 的 实用性 ． 从此 ， 第二次 高潮 的 序幕 拉开 了 ． 　 　 Marr 开辟 了 视觉 和 神经科学 研究 的 新篇章 ， 他 的 视觉 计算 理论 对 视觉 信息加工 的 过程 进行 了 全面 、 系统 和 深刻 的 描述 ， 对 计算 理论 、 算法 、 神经 实现 机制 及其 硬件 所 组成 的 个 层次 作 了 阐述 ． 年 Marr ［ ］ 的 著作 Vision 使 许多 学者 受益 ， 被 认为 是 最具 权威性 和 经典性 的 著作 ． 在 Marr 的 理论 框架 的 启示 下 ， Hopfield 于 年 至 年 提出 了 神经网络 集体 运算 功能 的 理论 框架 ［ ］ ， 随后 ， 引起 许多 学者 研究 Hopfield 网络 的 热潮 ， 对 它 作 改进 、 提高 、 补充 、 变形 等 ， 至今 仍 在 进行 ， 推动 了 神经网络 的 发展 ． 例如 ： 年 Lee ［ ］ 引入 高阶 突触 连接 ， 使 这 一 网络 的 存储 有 相当 大 的 提高 ， 并且 收敛 快 ， 但 随着 阶数 的 增加 ， 连接 键 的 数目 急剧 增加 ， 实现 起来 就 越 困难 ， 得不到 技术 的 支持 ． Lapedes ［ ］ 提出 的 主 — 从 网络 是 对 它 的 发展 ， 并 充分利用 了 联想 记忆 及 制约 优化 双重 功能 ， 还 可 推广 到 环境 随 时间 变化 的 动态 情况 ， 但 对于 大 N ， 主 网络 的 维数 很 高 ， 也 成为 一个 实际困难 ； 一些 研究者 发现 Hopfield 网络 中 的 平衡点 位置 未知 ， 即使 给出 一 具体 平衡位置 ， 用 他 的 方法 也 不能 确定 其 稳定性 ， 只 得到 极小值 点 满足 的 必要条件 ， 而 非 充分条件 ． Hopfield 网络 在 求解 TSP 问题 上 也 存在 一些 问题 ， 需要 改进 ． 另外 ， 有些 学者 试图 建立 实用 稳定性 ， 有 一定 理由 ， 它 可以 体现 容错 能力 ． 　 　 年 Kirkpatrick 等 人 ［ ］ 首先 认识 到 模拟退火 算法 可 应用 于 NP 完全 组合 优化 问题 的 求解 ． 这种 思想 最早 是 由 Metropolis 等 人 在 年 提出 的 ， 即 固体 热平衡 问题 ， 通过 模拟 高温 物体 退火 过程 的 方法 ， 来 找 全局 最优 或 近似 全局 最优 ， 并 给出 了 算法 的 接受 准则 ． 这是 一种 很 有效 的 近似算法 ． 实际上 ， 它 是 基于 MonteCarlo 迭代法 的 一种 启发式 随机 搜索算法 ． 年 Hinton 等 人 ［ ， ］ 提出 了 Boltzmann 机 模型 ， 借用 统计 物理学 中 的 概念 和 方法 ， 引入 了 模拟退火 方法 ， 可 用于 设计 分类 和 学习 算法 方面 ， 并 首次 表明 多层 网络 是 可 训练 的 ． 它 是 一种 神经网络 连接 模型 ， 即 由 有限 个 被 称之为 单元 的 神经元 经 一定 强度 的 连接 构成 ， 又 是 一种 神经 计算机 模型 ． Sejnowski ［ ］ 于 年 对 它 进行 了 改进 ， 提出 了 高阶 Boltzmann 机和 快速 退火 等 ． 这些 成为 随机 神经网络 的 基本 理论 ． 　 　 Poggio 等 人 ［ ， ］ 以 Marr 视觉 理论 为 基础 ， 对 视觉 算法 进行 了 研究 ， 在 年 和 年 他 提出 了 初级 视觉 的 正则 化 方法 ， 使 视觉 计算 的 研究 有 了 突破性 进展 ． 我国 生物 物理学家 汪云九 提出 了 视觉 神经元 的 广义 Gabor 函数 EG 模型 ， 以及 有关 立体 视觉 、 纹理 检测 、 运动 方向 检测 、 超 视觉 度 现象 的 计算 模型 ． 汪云 九 等 人 还 建立 了 初级 视觉神经 动力学 框架 ， 他们 开辟 了 一条 新 的 途径 ． 　 　 HechtNielsen 是 一位 地道 的 学者 式 企业家 ， 他 是 神经 计算机 最早 的 设计者 之一 ， 对 神经网络 理论 、 应用 及 商业化 作出 了 重要 贡献 ． 早 在 年 ， 他 开始 制定 Motorola 神经计算 的 研究 与 发展 计划 ， 在 此基础 上 ， 于 年 又 进一步 制定 了 TRW 的 计划 ， 构造 了 一种 对传 网络 的 多层模式 识别 神经网络 ， 主要 适用 图象 压缩 和 统计分析 ， 他 还 成功 设计 了 一种 神经 计算机 称为 TRWMark Ⅲ ， 年 将 它 投入 商业 应用 ， 并且 设计 了 Grossberg 式 时空 匹配 滤波器 ． 他 在 年 证明 了 反向 传播 算法 对于 多种 映射 的 收敛性 ［ ］ ． 　 　 年 Rumelhart 和 McClelland 合著 的 ParallelDistributedProcessingExplorationintheMicrostructuresofCognition 两卷 书 出版 ， 对 神经网络 的 进展 起 了 极大 的 推动 作用 ． 它 展示 了 PDP 研究 集团 的 最高 水平 ， 包括 了 物理学 、 数学 、 分子生物学 、 神经科学 、 心理学 和 计算机科学 等 许多 相关 学科 的 著名 学者 从 不同 研究 方向 或 领域 取得 的 成果 ． 他们 建立 了 并行 分布 处理 理论 ， 主要 致力于 认知 的 微观 研究 ． 尤其 是 ， Rumelhart 提出 了 多层 网络 BackPropagation 法 或 称 ErrorPropagation 法 ， 这 就是 后来 著名 的 BP 算法 ， 受到 许多 学者 的 重视 ． 　 　 此外 ， 我国 系统 科学家 钱学森 在 年代 初 倡导 研究 “ 思维科学 ” ． 年 他 主编 的 论文集 《 关于 思维科学 》 出版 ［ ］ ， 书中 有关 神经网络 方面 的 论文 ： 刘觐龙 对 “ 思维 神经 基础 ” 的 探讨 ； 洪加威 对 “ 思维 的 一个 确定 型 离散数学 模型 ” 的 研究 ； 陈霖 的 长篇 文章 “ 拓扑 性质 检测 ” ． 这 本书 引起 了 国内 学术界 有关 人士 的 极大 反响 ． 　 　 年 在 圣地 雅哥 召开 了 首届 国际 神经网络 大会 ， 国际 神经网络 联合会 INNS 宣告成立 ． 嗣后 ， INSS 创办 的 刊物 JournalNeuralNetworks 问世 ， 还 诞生 十几种 国际 著名 的 神经网络 学术刊物 ． 神经网络 理论 经过 半个 多 世纪 的 发展 ， 人们 看到 它 已经 硕果累累 ． 于是 ， 美国国防部 高级 预研 计划局 DARPA 组织 了 一批 专家 、 教授 进行 调研 ， 走访 了 三千多 位 有关 研究者 和 著名 学者 ， 于 年 月 完成 了 一份 长 达 三百多 页 的 神经网络 研究 计划 论证 报告 ． 并 从 月 开始 执行 一项 发展 神经网络 及其 应用 的 八年 计划 ， 投资 亿美元 ． 美国 国家 科学 基金会 NSF 于 年 拨款 万美元 ， 年 NSF 、 ONRAFOSR 投资 达 千万美元 ． DARPA 的 看法 是 ， 神经网络 是 解决 机器 智能 的 唯一 希望 ． 世界 上 一些 著名 大学 纷纷 成立 神经网络 研究所 、 制订 有关 教育 计划 ． 许多 国家 相应 成立 了 神经网络 学会 ， 定期 召开 国际性 、 区域性 会议 ， 如 ： 年 欧洲 召开 首届 国际 会议 ParallelProblemSolvingfromNaturePPS N年 IEEE 神经网络 学会 主持 召开 了 第一届 进化 计算 国际 会议 ． 　 　 我国 学术界 大约 在 年代 中期 关注 神经网络 领域 ， 有 一些 科学家 起到 先导 的 作用 ， 如 中科院 生物物理 所 科学家 汪云九 ， 姚国 正 和 齐翔林 等 ［ ］ ； 北京大学 非线性 研究 中心 在 年 月 发起 举办 了 BeijingInternationalWorkshoponNeuralNetworksLearningandRecognitionaModernApproach ． INNS 秘书长 Szu 博士 在 会议 期间 作 了 神经网络 一系列 讲座 ， 后来 这些 内容 出版 了 ［ ］ ． 从这时起 ， 我国 有些 数学家 和 计算机 科学家 开始 对 这 一 领域 产生 兴趣 ， 开展 了 一定 的 研究 工作 ． 　 　 年 召开 了 全国 一个 非正式 的 神经网络 会议 ， 年 我国 的 八个 学会 联合 在 北京 召开 了 神经网络 首届 学术 大会 ， 国内 新闻媒体 纷纷 报道 这一 重大 盛会 ， 这是 我国 神经网络 发展 以及 走向世界 的 良好开端 ． 年 在 南京 召开 了 中国 神经网络 学术 大会 第二届 ， 会上 成立 了 中国 神经网络 学会 ． 我国 “ ” 高技术 研究 计划 和 “ 攀登 ” 计划 于 年 批准 了 人工神经网络 的 项 课题 ， 自然科学 基金 和 国防科技 预研 基地 也 都 把 神经网络 的 研究 列入 选题 指南 ． 许多 全国性 学术年会 和 一些 学术刊物 把 神经网络 理论 及 应用 方面 的 论文 列为 重点 ． 这些 毫无疑问 ， 为 神经网络 在 我国 发展 创造 了 良好 的 条件 ， 促使 我们 加快步伐 缩短 我国 在 这个 领域 的 差距 ． INNS 开始 重视 我国 ， 把 年 国际 神经网络 学会 、 IEEE 神经网络 委员 主办 的 国际性 学术会议 IJCNN 定 在 北京 召开 ． 　 　 年 Chua 和 Yang 提出 了 细胞 神经网络 CNN 模型 ［ ， ］ ， 它 是 一个 大规模 非线性 计算机 仿真 系统 ， 具有 细胞 自动机 的 动力学 特征 ． 它 的 出现 对 神经网络 理论 的 发展 产生 了 很大 的 影响 ． 另外 ， Kosko 建立 了 双向 联想 存储 模型 BAM ［ ～ ］ ， 它 具有 非 监督 学习 能力 ， 是 一种 实时 学习 和 回忆 模式 ， 并 建立 了 它 的 全局 稳定性 的 动力学 系统 ． 　 　 Mead 是 VLSI 系统 的 创建者 ， 他 和 Conway 、 Mahowald 等 人 合作 ， 研制 一种 动物 神经系统 的 电子电路 模拟 ， 即称 硅 神经系统 ． 如 ， 在 一 方阵 中含 几千个 光敏 单元 的 VLSI 芯片 ， 它 是 以 人 的 视网膜 中 锥体细胞 的 方式 来 连接 一块 VLSI 芯片 ． 对此 ， 他 在 年 出版 了 专著 AnalogVLSIandNeuralSystemMead ． Muhlenbein ［ ， ］ 提出 了 一种 进化 系统 理论 的 形式 模型 ， 是 一种 遗传 神经网络 模型 ． 其 基本 思想 是 来源于 Waddington 在 年 发表 的 论文 ， 对 基因型 与 表型 关系 进行 了 描述 ． Aleksander ［ ］ 提出 了 概率 逻辑 基于 Markovchain 理论 ， 对 其 收敛性 、 结构 以及 记忆 容量 等 研究 ， 为 概率 逻辑 神经元网络 的 发展 提供 了 新 的 方法 和 途径 ． 　 　 上述 例证 说明 ， 这次 高潮 吸引 了 许多 科学家 来 研究 神经网络 理论 ， 优秀 论著 ， 重大成果 如 雨后春笋 ， 新 生长 的 应用领域 受到 工程 技术人员 的 极大 赞赏 ． 　 　 新 发展 阶段 ． 　 从 神经网络 理论 的 发展史 看 ， 它 的 高潮 阶段 是 很 容易 度过 的 ． IJCNN 大会 主席 Rumelhart 意识 到 这 一点 ， 在 他 的 开幕词 中有 一个 观点 ， 神经网络 的 发展 已到 了 一个 转折 的 时期 ， 它 的 范围 正在 不断扩大 ， 其 应用领域 几乎 包括 各个方面 ． 半个世纪 以来 ， 这门 学科 的 理论 和 技术 基础 已 达到 了 一定 规模 ， 笔者 认为 ， 神经网络 到 了 新 发展 阶段 ， 需要 不断完善 和 突破 ， 使 其 技术 和 应用 得到 有力 的 支持 ． 　 　 年代 初 ， 对 神经网络 的 发展 产生 了 很大 的 影响 是 诺贝尔奖 获得者 Edelman 提出 了 Darwinism 模型 ， 其 主要 种 形式 是 Darwinism Ⅰ 、 Ⅱ 、 Ⅲ ． 他 建立 了 一种 神经 网络系统 理论 ， 例如 ， Darwinism Ⅲ 的 结构 ， 其 组成 包括 输入 阵列 、 Darwin 网络 和 Nallance 网络 ， 并且 这 两个 网络 是 并行 的 ， 而 它们 又 包含 了 不同 功能 的 一些 子 网络 ． 他 采用 了 Hebb 权值 修正 规则 ， 当 一定 的 运动 刺激 模式 作用 后 ， 系统 通过 进化 ， 学会 扫描 和 跟踪目标 ． 该 系统 中 关于 群 group 的 作用 ， 他 早 在 年 就 阐述 了 ， 即 神经 模式 的 选择 阶段 是 群 限制 、 群 选择 和 群 竞争 ． 　 　 年 廖晓昕 ［ ］ 对 细胞 神经网络 建立 了 新 的 数学 理论 与 基础 ， 得出 了 一系列 结果 ． 如 ， 耗散 性 、 平衡位置 的 数目 及 表示 ， 平衡态 的 全局 稳定性 、 区域 稳定性 、 周期 解 的 存在 性 和 吸引 性 等 ． 使 这个 领域 取得 了 新 的 进展 ， 他 认为 该 理论 有 巨大 的 潜在 应用 前景 ， 它 还有 待 以此 为 基础 来 发展 系统 ． 　 　 神经网络 的 光学 方法 ， 能 充分发挥 光学 强大 的 互连 能力 和 并行处理 能力 ， 提高 神经网络 实现 的 规模 ， 从而 加强 网络 的 自 适应 功能 和 学习 功能 ， 因此 近来 引起 不少 学者 重视 ． Wunsch 在 OSA 年会 提出 一种 AnnualMeeting ， 用 光电 执行 ART ， 它 的 主要 计算 强度 由 光学 硬件 完成 ， 光电 ART 单元 的 基本 构件 为 双 透镜 组 光学 相关器 ， 并 采用 光 空间 调节器 完成 二值 纯 相位 滤波 和 输入 图象 的 二维 Fourier 变换 ， 它 的 学习 过程 有 自 适应 滤波 和 推理 功能 ， 可以 把 光学 有机 组合 在 其中 ， 具有 快速 和 稳定 的 学习 的 特点 ， 网络 所 需 神经元 数目 大量 减少 ， 而且 人为 调节 参数 也 减少 很多 ． 年 Jenkins 等 人 ［ ］ 研究 了 光学 神经网络 PNN ， 建立 了 光学 二维 并行 互连 与 电子学 混合 的 光学 神经 网络系统 ， 实现 了 光学 神经元 ， 它 是 解决 光学 实现 相减 和 取 阈 问题 的 新动向 ． 值得 重视 的 是 ， 年代 初 ， McAulay ， Jewel 等 许多 学者 致力于 电子 俘获 材料 应用 于 光学 神经网络 的 研究 ［ ， ］ ， 在 光存储 等 方面 取得 一定 成果 ， 受到 人们 的 关注 ． 最近 ， 阮昊 等 人 采用 他们 研制 的 CasEuSm 电子 浮获 材料 实现 IPAInterpatternAssociation 和 Hopfield 等 那些 互联 权重 不变 的 神经网络 模型 ［ ］ ， 他们 认为 ， 采用 这种 方式 还 可 实现 如 感知器 等 那些 通过 学习 来 改变 互联 权重 的 网络 模型 ． 这些 ， 对 光学 神经网络 的 发展 起到 很大 的 推动 作用 ． 　 　 对于 不变性 模式识别 机制 的 理解 ， 是 对 理论家 的 一大 挑战 ， 尤其 是 对于 多 目标 的 旋转 不变 分类 识别 问题 的 研究 ， 具有 广泛 的 应用 前景 ． 最近 ， 申金媛 、 母国 光 等 人 ［ ］ 提出 一种 新 方法 ， 即 基于 联想 存储 级联 WTA 模型 的 旋转 不变 识别 ． 当 识别 多个 模式 时 就 可 联想 出 一个 模式 ， 针对 该 问题 ， 他们 采用 了 全 单极 形式 ， 对 互连 权重 进行 二值化 截取 ， 并 把 联想 存储 模型 与 WTA 模型 级联 起来 ， 从而 提高 了 存储容量 和 容错性 ， 实现 了 多 目标 旋转 不变 分类 识别 ． 他们 选择 四大 类型 飞行器 作为 仿真 模拟 ， 其 方法 可行 和 有效 ． 　 　 此外 ， Haken 在 年 出版 了 一本 论著 SynergeticandCognition ： ATopDownApproachtoNeuralNets ． 他 把 协同学 引入 神经网络 ． 正如 他 认为 的 ， 这是 研究 和 设计 神经网络 的 一种 新颖 方法 ． 在 他 的 理论 框架 中 ， 强调 整体性 ， 认知 过程 是 自发 模式 形成 的 ， 并 断言 ： 模式识别 就是 模式 形成 ． 他 提出 了 一个 猜测 ： 感知 发动机 模式 的 形成 问题 可以 绕开 模式识别 ． 他 仍 在 摸索 着 如何 才能 使 这种 方法 识别 情节性 景象 和 处理 多意 模式 ． 　 　 值得 重视 的 是 ， 吴佑寿 等 人 ［ ］ 提出 了 一种 激励函数 可调 的 神经网络 模型 ， 对 神经网络 理论 的 发展 有 重要 意义 ． 可以 认为 ， 先验 知识 不 充分利用 岂 不 可惜 ， 但 问题 是 先验 知识 有时 不 一定 抓住 了 实质 ， 存在 一定 局限性 ． 因此 ， 在 设计 激励函数 可调 网络 TAF 时要 谨慎 ． 他们 针对 一个 典型 的 模式 分类 难题 ， 即 双 螺线 问题 来 讨论 TAF 网络 的 设计 、 激励函数 的 推导 及其 网络 训练 等 ， 其 实验 结果表明 这种 网络 方法 的 有效性 和 正确性 ， 尤其 对 一些 可用 数学 描述 的 问题 ． 另外 ， 对 模式识别 中 的 手写 汉字 识别 问题 研究 ， 有 重要 的 理论 和 应用 价值 ． 郝红卫 和 戴汝为 ［ ］ 把 统计 识别方法 与 多层 感知器 网络综合 起来 ， 他们 提出 了 一种 网络 集成 法 ， 对个 不同 手写 汉字 分类器 进行 集成 ． 这个 方法 有 一定 的 推广性 ， 对 其它 类似 问题 提供 了 一个 范例 ． 年代 ， 国内 许多 学者 对 Hopfield 神经网络 的 进一步 研究 很感兴趣 ， 使 它 得到 了 一定 的 完善 和 发展 ． 　 　 年代 以来 ， 人们 较 多 地 关注 非线性 系统 的 控制 问题 ， 通过 神经网络 方法 来 解决 这 类 问题 ， 已 取得 了 突出 的 成果 ， 它 是 一个 重要 的 研究 领域 ． 年 Narendra 和 Parthasarathy 提出 了 一种 推广 的 动态 神经 网络系统 及其 连接 权 的 学习 算法 ［ ］ ， 它 可 表示 非线性 特性 ， 增强 了 鲁棒性 ． 他们 给出 了 一种 新 的 辨识 与 控制 方案 ， 以 multilayer 网络 与 recarrent 网络 统一 的 模型 描述 非线性 动态 系统 ， 并 提出 了 动态 BP 参数 在线 调节 方法 ． 他们 研究 的 是 ， 假定 对象 为 线性 或 非线性 离散 时间 系统 ． 有些 学者 对 它 的 学习 算法 计算 量 大 和 收敛 速度慢 进行 了 一定 改进 ． 值得 重视 的 是 ， 连续 时间 非线性 动态 系统 ， 如 ， 仿射 非线性 系统 可 直接 应用 于 广泛 而 真实 的 物理 系统 ． 值得一提的是 ， 戴先 中等 人 ［ ］ 提出 了 连续 非线性 系统 的 神经网络 α 阶逆 系统控制 方法 ， 他们 一方面 用 静态 神经网络 逼近 静态 非线性 函数 ； 另一方面 用 积分器 或 微分 器来 体现 系统 的 动态 特性 ， 并 结合 线性系统 理论 和 方法 ， 从而 构成 一种 满足 系统 要求 的 复合 控制器 ． 可以 说 ， 这种 控制策略 具有 一定 代表性 和 启发性 ． 　 　 Miller ［ ］ 等 人 基于 Albus 在 年 提出 的 小脑 模型 关节 控制器 CMAC ， 研究 了 非线性 动态 系统控制 问题 ， 它 具有 局部 逼近 和 修改权 极小 的 特点 ， 可 用于 实时控制 方面 ， 但 存在 一个 缺陷 ， 即 采用 了 间断 超平面 对 非线性 超曲 的 逼近 ， 有时 出现 精度 不够 ， 也 有 可能 得不到 相应 的 导数 估计 ． 这种 方法 一 开始 就 被 Miller ［ ］ 成功 地 应用 于 商用 机器人 的 实时 动态 轨迹 的 跟踪 控制 中 ． Touretzky 也 成功 应用 于 非线性 时间 序列 分析 上 ． 年 Lane ［ ］ 对 它 作 了 改进 ， 他 采用 高阶 B 样条 ， 使 逼近 超平面 的 光滑性 更好 ， 虽然 计算 量 有所增加 ， 但 在 容忍 范围 之内 ， 逼近 精度 有 一定 提高 ． 年 Bulsari ［ ］ 提出 以 乘积 Sigmoidal 函数 作为 激发 函数 ， 给出 了 非线性 系统 用 神经网络 逼近 的 构造性 描述 ， 得到 了 节点 数目 的 一个 上 界 估计 ． 最近 ， 朱 文革 ［ ］ 引入 小 波 变换 ， 并 对 其 性质 进行 了 分析 ． 在 Lp 范数 下 ， 他 也 构造性 证明 了 单个 隐层 前馈 神经网络 逼近 定理 ． 年罗忠 等 人 ［ ］ 对 CMAC 的 收敛性 以及 hash 编码 对 它 的 影响 作 了 矩阵 分析 和 证明 ． 另外 ， 有些 学者 通过 神经网络 的 训练 来 实现 非线性 系统 的 状态 反馈 控制 ， 其 学习 算法 为 非线性 系统 的 学习 控制 提供 了 有效 的 方法 ． 但 它 需要 全 状态 反馈 信息 ， 给 实际 应用 带来 了 一定 的 困难 ， 同时 它 的 学习 收敛 速度 还有 待 提高 ． 　 　 Davis 在 年 编辑出版 的 HandbookofGeneticAlgorithms ， 这本 工具书 对 该 领域 的 设计 和 应用 人员 有 很大 的 帮助 ． 尤其 是 进化 计算 的 概念 在 年 形成 ， 促进 了 这 一 理论 的 发展 ． 年 诞生 了 国际性 杂志 EvolutionaryComputation ． 随后 ， IEEE 神经网络 委员会 定期 召开 进化 计算 国际 会议 ． 近几年 它 成为 一个 热点 研究 领域 ． 年 Yip 和 Pao 提出 了 一种 带 区域 指引 的 进化 模拟退火 算法 ， 他们 将 进化 策略 引入 区域 指引 ， 它 经过 选优 过程 ， 最终 达到 求解 问题 的 目的 ． 近几年 有些 学者 对 它 进行 了 改进 ， 如 ， 蔚 承建 等 人 ［ ］ 在 随机 搜索 过程 中 引入 区域 指引 ， 并 采用 Cauchy 变异 替换 Gaussian 变异 产生 后代 ， 使 算法 的 可 收敛性 及其 速度 有所提高 ． 他们 将 这种 方法 成功 的 应用 于 转动 圆桌 平衡 摆盘 问题 的 求解 ． 值得一提的是 ， 年 张 讲社 等 人 ［ ］ 将 Markov 链 表示 遗传算法 ， 并 引进 模拟退火 的 方法 ． 还有 类似 的 混合法 及其 改进 ， 如 提高 收敛 速度 ， 避免 过早 收敛 ， 同时 避免 陷进 局部 极值 的 情况 ． 　 　 必须 指出 ， 神经网络 的 计算 复杂性 分析 具有 重要 意义 ． 有些 学者 产生 了 极大 兴趣 ， 如年 Hertz ［ ］ 探讨 了 神经计算 理论 ； 年 Anthony ［ ］ 出版 了 一本 论著 ComputationalLearingTheory ； 年 阎 平凡 ［ ］ 讨论 了 神经网络 的 容量 、 推广 能力 、 学习 性 及其 计算 复杂性 ． 可以 说 ， 这方面 的 理论 成果 越 多 ， 对 应用 的 作用 就 越 大 ． 　 　 从 上述 各个 阶段 发展 轨迹 来看 ， 神经网络 理论 有 更 强 的 数学 性质 和 生物学 特征 ， 尤其 是 神经科学 、 心理学 和 认识 科学 等 方面 提出 一些 重大 问题 ， 是 向 神经网络 理论 研究 的 新 挑战 ， 因而 也 是 它 发展 的 最大 机会 ． 年代 神经网络 理论 日益 变得 更加 外向 ， 注视 着 自身 与 科学技术 之间 的 相互作用 ， 不断 产生 具有 重要 意义 的 概念 和 方法 ， 并 形成 良好 的 工具 ． 　 发展趋向 及 前沿 问题 　 　 展望 世纪 初 ， 在 近十年 神经网络 理论 研究 趋向 的 背景 下 ， 笔者 认为 神经网络 理论 的 主要 前沿 领域 包括 ： 　 　 对 智能 和 机器 关系 问题 的 认识 将 进一步 增长 ． 　 　 研究 人类 智力 一直 是 科学 发展 中 最 有 意义 ， 也 是 空前 困难 的 挑战性 问题 ． 人脑 是 我们 所 知道 的 唯一 智能 系统 ， 它 具有 感知 识别 、 学习 、 联想 、 记忆 、 推理 等 智能 ， 年代 中期 出现 了 “ 联结 主义 ” 的 革命 ， 或 “ 并行 分布 处理 PDP ” ， 它 又 被 普遍 地 称为 神经网络 ， 具有 自 学习 、 自 适应 和 自 组织 的 特点 ， 也 是 神经网络 迫切需要 增强 的 主要 功能 ． 进一步 研究 调节 多层 感知器 的 算法 ， 使 建立 的 模型 和 学习 算法 成为 适应性 神经网络 的 有力 工具 ， 构建 多层 感知器 与 自 组织 特征 图级 联想 的 复合 网络 ， 是 增强 网络 解决 实际 问题 能力 的 一个 有效途径 ． 重视 联结 的 可编程 性 问题 和 通用性 问题 的 研究 ， 从而 促进 智能科学 的 发展 ． 我们 通过 不断 探索 人类 智能 的 本质 以及 联结 机制 ， 并用 人工 系统 复现 或 部分 复现 ， 制造 各种 智能 机器 ， 这样 ， 可 使 人类 有 更 多 的 时间 和 机会 从事 更为 复杂 、 更富 创造性 的 工作 ． 　 　 智能 的 产生 和 变化 经过 了 漫长 的 进化 过程 ， 我们 对 智能 处理 的 新 方法 的 灵感 主要 来自 神经科学 ， 例如 学习 、 记忆 实质 上 是 突触 的 功能 ， 而 海兔 的 小 系统 神经元 是 研究 学习 记忆 突触 机制 的 天然 模型 ， 在 细胞 和 分子 水平 上 研究 ， 为 我们 提供 真正 的 实证 ． 又 如 ， 人类 大脑 的 前额 叶 高度 发育 ， 它 几乎 占 了 大脑 的 表面积 ， 在 其 附近 形成 了 人类 才 出现 的 语言 运动 区 ， 它 与 智能 发育 可能 密切相关 ， 使 神经系统 的 发育 同 环境 的 关系 更加 密切 ， 脑 的 可塑性 很大 ， 能 主动 适应环境 还 能 主动 改造 环境 ， 人类 向 制造 智能工具 方向 迈进 正是 这种 主动性 的 反映 ． 事实上 ， 脑 的 可塑 期越长 ， 经验 对脑 的 影响 就 越 大 ， 而 人类 的 认知 过程 很大 程度 上 不仅 受 经验主义 的 影响 ， 而且 还 接受 理性主义 的 模型 和 解释 ． 因此 ， 对于 智能 和 机器 的 关系 ， 应该 从 进化 的 角度 ， 把 智能 活动 看成 动态 发展 的 过程 ， 并 合理 的 发挥 经验 的 作用 ． 同时 还 应该 从 环境 与 社会 约束 以及 历史 文化 约束 的 角度 加深 对 它 的 理解 与 分析 ． 　 　 神经网络 是 由 大量 处理单元 组成 的 非线性 、 自 适应 、 自 组织系统 ， 它 是 现代 神经科学 研究成果 的 基础 上 提出 的 ， 试图 模拟 神经网络 加工 、 记忆 信息 的 方式 ， 设计 一种 新 的 机器 ， 使 之 具有 人脑 风格 的 信息处理 能力 ． 智能 理论 所 面对 的 课题 来自 “ 环境 — 问题 — 目的 ” ， 有 极大 的 诱惑力 与 压力 ， 它 的 发展 方向 就 将 是 ， 把 基于 联结 主义 的 神经网络 理论 、 基于 符号 主义 的 人工智能 专家系统 理论 和 基于 进化论 的 人工生命 这三大 研究 领域 ， 在 共同 追求 的 总 目标 下 ， 自发 而 有机 的 结合 起来 ． 在 这里 我们 只想 重复 一下 我们 的 信念 并 推测 ： 在 世纪 初 ， 智能 的 机器 实现 问题 的 研究 将 有 新 的 进展 和 突破 ． 　 　 神经计算 和 进化 计算 将 有 重大 的 发展 ． 　 　 计算 和 算法 是 人类 自古以来 十分重视 的 研究 领域 ， 本世纪 年代 ， 符号逻辑 方面 的 研究 非常 活跃 ． 例如 Church 、 Kleene 、 Godel 、 Post 、 Turing 等 数学家 都 给出 了 可计算性 算法 的 精确 数学 定义 ， 对 后来 的 计算 和 算法 的 发展 影响 很大 ． 年代 数学家 Markov 发展 了 Post 系统 ． 年代 以后 ， 神经网络 理论 在 计算 理论 方面 取得 了 引人注目 的 成果 ， 形成 了 神经计算 和 进化 计算 新 概念 ， 激起 了 许多 理论家 的 强烈 兴趣 ， 如前所述 ， 大规模 平行 计算 是 对 基于 Turing 机 的 离散 符号 理论 的 根本性 的 冲击 ， 但 年代 人们 更 多 的 是 批评 的 接受 它 ， 并 将 两者 结合 起来 ， 近年来 ， 神经计算 和 进化 计算 领域 很 活跃 ， 有 新 的 发展 动向 ， 在 从 系统 层次 向 细胞 层次 转化 里 ， 正在 建立 数学 理论 基础 ． 随着 人们 不断 探索 新 的 计算 和 算法 ， 将 推动 计算 理论 向 计算 智能化 方向 发展 ， 在 世纪 人类 将 全面 进入 信息 社会 ， 对 信息 的 获取 、 处理 和 传输 问题 ； 对 网络 路由 优化 问题 ； 对 数据安全 和 保密 问题 等等 将 有 新 的 要求 ， 这些 将 成为 社会 运行 的 首要任务 ， 因此 ， 神经计算 和 进化 计算 与 高速 信息网络 理论 联系 将 更加 密切 ， 并 在 计算机网络 领域 中 发挥 巨大 的 作用 ， 例如 ， 大 范围 计算机网络 的 自 组织 功能 实现 就要 进行 进化 计算 ． 　 　 现有 的 一些 神经网络 模型 并 没有 攻克 组合 爆炸 问题 ， 只是 把 计算 量 转 交给 了 学习 算法 来 完成 ， 具体 说 ， 增加 处理机 数目 一般 不能 明显增加 近似 求解 的 规模 ． 可以 说 ， 有些 神经网络 模型 的 计算 学习 时间 与 神经元 有 多少 事实上 关系 不太大 ， 却 与 学习 的 样本 有 明显 的 依赖 关系 ． 值得注意 的 是 ， 尽管 采用 大规模 并行处理 机是 神经网络 计算 的 重要 特征 ， 但 我们 还应 寻找 其它 有效 方法 ， 建立 具有 计算 复杂性 、 网络 容错性 和 坚韧性 的 计算 理论 ． 　 　 人类 的 思维 方式 正在 转变 ： 从 线性 思维 转 到 非线性 思维 ． 神经元 、 神经网络 都 有 非线性 、 非 局域 性 、 非定常 性 、 非凸性 和 混沌 等 特性 ， 我们 在 计算 智能 的 层次 上 研究 非线性 动力系统 、 混沌 神经网络 以及 对 神经网络 的 数理 研究 ． 进一步 研究 自适应性 子波 、 非线性 神经 场 的 兴奋 模式 、 神经 集团 的 宏观 力学 等 ． 因为 ， 非线性 问题 的 研究 是 神经网络 理论 发展 的 一个 最大 动力 ， 也 是 它 面临 的 最大 挑战 ． 此外 ， 神经网络 与 各种 控制 方法 有机 结合 具有 很大 发展前景 ， 建模 算法 和 控制系统 的 稳定性 等 研究 仍为 热点问题 ， 而 容忍 控制 、 可塑性 研究 可能 成为 新 的 热点问题 ． 开展 进化 并行算法 的 稳定性 分析 及 误差 估计 方面 的 研究 将会 促进 进化 计算 的 发展 ． 把 学习 性 并行算法 与 计算 复杂性 联系 起来 ， 必须 分析 这些 网络 模型 的 计算 复杂性 以及 正确性 ， 从而 确定 计算 是否 经济 合理 ． 关注 神经 信息处理 和 脑 能量 两个 方面 以及 它们 的 综合 分析 研究 的 最新 动态 ， 吸收 当代 脑 构象 等 各种 新 技术 和 新 方法 ． 例如 ， 在 年 Science 杂志 上 ， 生物 化学家 Adleman 发表 了 一篇 论文 ： MolecularComputationofSolutionstoCombinatorialProblems ， 他 采用 超 并行 的 DNA 求解 组合 问题 ， 他 是 DNA 计算 的 创建者 之一 ， 随后 ， 他 制造 的 超 并行 DNA 计算机 TT 取得 了 技术 上 的 突破 ． 这一 具有 重大 价值 的 理论 和 方法 ， 是 对 NP 完全 问题 和 数据 加密 标准 系统 等 发起 了 最 猛烈 的 攻击 ． 因此 ， 神经网络 在 DNA 序列 分析 上 的 应用 会 更 受 人们 的 关注 ． 　 　 很 明显 ， 离散 符号计算 、 神经计算 和 进化 计算 相互促进 ． 从 道理 上 说 ， 也许 最终 导致 这种 计算 统一 起来 ， 这算 得 上 是 我们 回避 不了 的 一个 重大 难题 ． 预计 在 世纪 初 ， 关于 这个 领域 的 研究会 产生 新 的 概念 和 方法 ． 尤其 是 视觉 计算 方面 会 得到 充分 地 发展 ． 我们 应当 抓住 这个 机会 ， 力求 取得 重大意义 的 理论 和 应用 成果 ． 　 　 神经网络 结构 和 神经元 芯片 的 作用 将 不断扩大 ． 　 　 神经网络 结构 的 研究 是 神经网络 的 实现 以及 成功 地 实现 应用 的 前提 ， 又 是 优越 的 物理 前提 ． 它 体现 了 算法 和 结构 的 统一 ， 是 硬件 和 软件 的 混合体 ， 这种 硬软 混合结构 模型 可以 为 意识 的 作用 和 基本 机制 提供 解释 ． 未来 的 研究 主要 是 针对 信息处理 功能 体 ， 将 系统 、 结构 、 电路 、 器件 和 材料 等 方面 的 知识 有机 结合 起来 ， 建构 有关 的 新 概念 和 新 技术 ， 如 ， 结晶 功能 体 、 最子 效应 功能 体 、 高分子 功能 体等 ． 在 硬件 实现 上 ， 研究 材料 的 结构 和 组织 ， 使 它 具有 自然 地 进行 信息处理 的 能力 ， 如 ， 神经元 系统 、 自 组织系统 等 ． 目前 有些 学者 正在 研究 从 硬件 技术 到 应用 之间 的 映射 理论 ， 将会 出现 一些 新 的 方法 ． 　 　 神经 计算机 的 主要 特征 是 具有 并行 分布式 处理 、 学习 功能 ， 这是 一种 提高 计算 性能 的 有效途径 ， 使 计算机 的 功能 向 智能化 发展 ， 与 人 的 大脑 的 功能 相似 ， 并 具有 专家 的 特点 ， 比 普通人 的 反应 更 敏捷 ， 思考 更 周密 ． 光学 神经 计算机 具有 神经元 之间 的 连接 不仅 数量 巨大 而且 结合 强度 可以 动态控制 ， 因为 光波 的 传播 无 交叉 失真 ， 传播 容量 大 ， 并 可能 实现 超高速 运算 ， 这是 一个 重要 的 发展 领域 ， 其 基础科学 涉及 到 激光 物理学 、 非线性 光学 、 光 紊乱 现象 分析 等 ， 这些 与 神经网络 之间 在 数学 构造 上 存在 着 类似性 ． 近年来 ， 人们 采用 交叉 光 互连 技术 ， 保证 了 它们 之间 没有 串扰 ， 它 有着 广阔 的 发展前景 ． 在技术上 主要 有 超高速 、 大规模 的 光 连接 问题 和 学习 的 收敛 以及 稳定性 问题 ， 可望 使 之 得到 突破性 进展 ； 另 一种 是 采用 LSI 技术 制作 硅 神经 芯片 ， 以及 二维 VLSI 技术 用于 处理 具有 局部 和 规则 连接 问题 ． 在 未来 一 、 二十年 里 半导体 神经网络 芯片 仍 将 是 智能 计算机硬件 的 主要 载体 ， 而 大量 的 神经 元器件 ， 如何 实现 互不 干扰 的 高密度 、 高 交叉 互连 ， 这个 问题 可望 尽早 得到 解决 ． 此外 ， 生物 器件 的 研究 正 处于 探索 之中 ， 研究 这种 模型 的 理论 根据 是 ， 当硅 集成块 和 元件 间 的 距离 如果 接近 微米 时 ， 电子 从 邻近 元件 逸入 的 概率 将 很 有限 ， 便 产生 “ 隧道 效应 ” 的 现象 ， 它 是 高 集成电路 块 工作 不 可靠 的 原因 之一 ． 而 生物芯片 由于 元件 是 分子 大小 的 ， 其 包装 密度 可成 数量级 增加 ， 它 的 信号 传播方式 是 孤 电子 ， 将 不会 有 损耗 ， 并且 几乎 不 产生 热 ． 因此 ， 它 有 更 诱人 的 前景 ． 随着 大量 神经 计算机 和 神经元 芯片 应用 于 高科技 领域 ， 给 神经网络 理论 和 方法 赋予 新 的 内容 ， 同时 也 会 提出 一些 新 的 理论 课题 ， 这是 神经网络 迅速 发展 的 一个 动力 ． 　 结束语 　 　 近年来 ， 我国 “ ” 计划 、 攻关 计划 、 “ 攀登 ” 计划 和 国家自然科学基金 等 ， 都 对 神经网络 的 研究 给予 了 资助 ， 吸引 了 大量 的 优秀青年 人才 从事 神经网络 领域 的 研究 工作 ， 促进 我国 在 这个 领域 取得 世界 上 的 领先地位 ． 　 　 由于 神经网络 学科 的 范围 很 广泛 ， 本文 只能 在 那些 有 发展前途 的 领域 中 ， 在 联结 主义 提供 的 各种 机会 中 ， 列举 出 少数几个 方向 ， 并 作出 推测 ． 应该 说明 的 是 ， 除了 上述 列举 的 以外 ， 还有 形形色色 的 、 规模 可观 的 研究 工作 正在 进行 ． 总之 ， 在 世纪 科学技术 发展 征程 中 ， 神经网络 理论 的 发展 将 与日俱增 ． 注释 ： 国家自然科学基金 资助 作者简介 ： 刘永红 ， 男 ， 岁 ， 硕士生 ， 讲师 ． 研究 领域 为 神经网络 理论 、 智能 控制 等 ． 作者 单位 ： 武汉 工业 大学 自动化系 　 武汉 　 参考文献 　 McCullochWSPittsWALogicalCalculusoftheIdeasImmanentinNervous 　 　 ActivityBulletinofMathematicalBiophysics ～ 　 N 维纳 著 ， 郝季仁译 ， 控制论 ， 科学 出版 ， 　 VonNeumannJTheGeneralandLogicalTheoryofAutomataCerebralMechanismsin 　 　 BehaviorTheHixonSympsium 　 TuringAMOnComputableNumberswithanApplicationtotheEntscheidungs 　 　 problemProcLondonMathSoc ～ ～ 　 TuringAMSystemsofLogicBasedonOrdinalsProcLondonMathSoc 　 　 ～ 　 PostELFiniteCombinatoryProcessformulationIJSymbolicLogic 　 　 ～ 　 HebbDOTheOrganizationofBehaviorNewYorkWiley 　 EcclesJCCholinergicandInhibitorySynapsesinAPathwayfromMotoraxon 　 　 CollateralstoMotorneuronesJPhysiol 　 RosenblattFThePerceptronAProbabilisticModelforInformationstorage 　 　 andOrganizationinTheBrainPsychologicalReview ～ 　 WidrowBMEHoffAdaptiveSwitchingCircuitsIREWESCONconvertion 　 　 recordpartcomputersManmachineSystemsLosAngeles ～ 　 RosenblattFPrinciplesofNeurodyNamicsPerceptronsandTheTheoryofBrain 　 　 MechanismsSpartanNewYork 　 GrossbergSOntheSerialLearningofListsMathBiosci ～ 　 GrossbergSSomeNetworksthatCanLeanRemenberandReproduceanyNumberof 　 　 CompialtedSpacetimePatterns Ⅱ studApplMath ～ 　 WillshawDJBunemanOPLonguesthigginsHCNature 　 NilssonNJLearningMachinesFoundationsofTrainublePatternClassifying 　 　 SystemsMcGrawhillNewYork 　 HollandJHGeneticAlgorithmsandtheOptimalAllocationsofTrialsSIAM 　 　 JournalofComputing ～ 　 HollandJHAdaptationinNaturalandArtificialSystemsAnnArborThe 　 　 UniversityofMichiganPress 　 SteinRBLeungKVMangeronDOguztoreliMNImprovedNeuronalModelsfor 　 　 StudyingNeuralNetworksKybernetik ～ 　 HeidenUanderExistenceofPeriodicSolutionsofaNerveEquationBiol 　 　 Cybern ～ 　 GrossbergSAaptivePatternClassificationandUniversalRecodingPartI 　 　 ParallelDevelopmentandCodingofNeuralFeatureDetectorsBiologicalCybern 　 　 etics ～ 　 WerbosPBeyondRegressionNewToolsforPredictionandAnalysisinthe 　 　 BehavioralSciencesPhDDissertationHarvardUniversity 　 FukushimaKNeocognitronASelforganizingMultilayeredNeuralNetwork 　 　 BiologicalCybernetics ～ 　 AmariSICharacteristicsofRandomNetsofAnalogNeuronlikeElements 　 　 IEEETransactionsonSystemsManandCyberneticsaSMC ～ 　 KohonenTAutomaticFormationofTopologicalMapsinSelforgnizingSystems 　 　 ProceedingsofthendScandinavianConfonImageAnalysis ～ 　 KohonenTSelforganizingFormationofTopologicallyCorrectFeatureMaps 　 　 BiolCybern ～ 　 KohonenTSelforganizationandAssociativeMemoryBerlinSpringerVerlag 　 　 　 HopfieldJJNeuralNetworksandPhysicalSystemswithEmergentCollective 　 　 ComputationalAbilitiesProcNatlAcadSciUSA ～ 　 MarrDVisionSanFranciscoWHFreeman 　 HopfieldJJNeuronswithGradedResponehaveCollectiveComputationalPr 　 　 opertiesLikethoseofTwostateNeuronsProcNatlAcadSci 　 　 ～ 　 HopfieldJJTankDWNeuralComputationofDecisionsinOptimizationProb 　 　 lemsBiolCybern ～ 　 HopfieldJJTankDWComputingwithNeuralCircuitsAModelScience 　 　 ～ 　 LeeYCPhysicaD 　 LapedesAPhysicaD 　 KirkpatrickSGellatJrCDVeechiMPOptimizationbySimulatedAnnealing 　 　 Science ～ 　 HintonGESejuowskiTJAckleyDHBoltzmannMachiuesCotraintSatisfaction 　 　 NetworksthatLearnCarnegieMellonUniversityTechReportCMUCS 　 　 　 AckleyDHintonGSejnowskiTALearningAlgorithmforBoltzmannmachines 　 　 CognitiveScience ～ 　 SejnowskiTHigherOrderBoltzmannMachinesInDenkerJedAIPConf 　 　 PrpoceedingNeuralNetworksforComptuingNewYoukAmericanInstituteof 　 　 Physics ～ 　 PoggioTetalAnanalogmodelofComputationforIllposedProblemsofEarly 　 　 VisionArtifIntellLabMemoMIT 　 PoggioTetalComputationalVisionandRegularizationTheoryNetureLond 　 　 ～ 　 HechtNielsenRTheTheoryofBackpropagationNeuralNetworkInReview 　 钱学森 主编 ， 关于 思维科学 ， 上海人民出版社 ， 　 姚国正 ， 汪云九 ， 神经网络 的 集合 运算 ， 信息 与 控制 ， ， ： ～ 　 斯华龄 ［ 美 ］ ， 电脑 人脑 化 ： 神经网络 — 第六代 计算机 普及本 ， 北京大学出版社 ， 　 ChuaLOYangLCellularNeuralNetworksTheoryIEEETransactionson 　 　 CircuitsandSystems ～ 　 ChuaLOYangLCellularNeuralNetworksApplicationIEEETransactionson 　 　 CircuitsandSystems ～ 　 KoskoBAdaptiveBidirectionalAssociativeMemoriesApplOpt 　 　 ～ 　 KoskoBConstructinganAssociativeMemoryByte ～ 　 KoskoBBidirectionalAssociativeMemoriesIEEETransonManSystemsand 　 　 Cybernitics ～ 　 MuhlenbeinHParallelGeneticAlgorithmsPopulationGeneticsandCombina 　 　 torialOptimizationinJDSchafferEdProceedingsoftheThirdInternational 　 　 ConferenceonGeneticAlgorithmsICGA ～ 　 MuhlenbeinHLimitationsofMultilayerPerceptronNetworksstepsTowards 　 　 GeneticNeuralNetworksParallelComputing ～ 　 AleksanderITheLogicofConnectionistSystemsNeuralComputingArchite 　 　 cturesMITPress 　 廖晓昕 细胞 神经网络 的 数学 理论 Ⅰ 、 Ⅱ 中国 科学 A 辑 ， ， ： ～ ； 　 　 ： ～ 　 JenkinsBKARTanguayJrOpticalArchitecturesforNeuralNetwork 　 　 ImplementationHandbookofNeuralComputingandNeuralNetworksMITPress 　 　 Boston ～ 　 McAulayADWangJMaCOpticalHeteroassociativeMemoryUsingSpatialLight 　 　 RebroadcastersApplOpt ～ 　 JewelJLLeeYHSchererAetalSurfaceEmittingMicrolasersforPhotonic 　 　 SwitchingandInterclipConnectionOptEng ～ 　 阮昊 ， 陈述 春 ， 戴凤妹 ， 千福熹 利用 电子 俘获 材料 实现 光学 IPA 神经网络 模型 ， 光学 学报 　 　 ， ： ～ 　 申金媛 ， 常胜 江 ， 张延火斤 ， 母国 光 基于 联想 存储 级联 WTA 模型 的 旋转 不变 识别 ， 光学 学 　 　 报 ， ， ： ～ 　 吴佑寿 ， 赵明生 ， 丁晓青 一种 激励函数 可调 的 新 人工神经网络 及 应用 ， 中国 科学 E 辑 ， 　 　 ， ： ～ 　 郝红卫 ， 戴汝为 集成 手写 汉字 识别方法 与 系统 ， 中国 科学 E 辑 ， ， ： ～ 　 　 　 NarendraKParthasarathyKIdentificationandControlofDynamicalSystems 　 　 UsingNeuralNetworksIEEETransonNeuralNetworksMar ～ 　 戴先 中 ， 刘军 ， 冯纯伯 连续 非线性 系统 的 神经网络 α 阶逆 系统控制 方法 ， 自动化 学报 ， 　 　 ， ： ～ 　 MillerWTRealtimeApplicationofNeuralNetworksforSensorbasedControl 　 　 ofRobotswithVisionIEEETransSystManCybern ～ 　 MillerTWetalEdsNeuralNetworksforControlCambridgeMAMITPress 　 　 　 LaneS 　 HetalTheoryandDevelopmentofHigherOrderCMACNeuralNetworks 　 　 inSpecialIssueonNeuralNetworksinControlSystemsAntsaklisPJEd 　 　 IEEEControlSystemsMagazine ～ 　 BnlsariASomeAnalyticalSolutionstotheGeneralApproximationProblemfor 　 　 FeedforwardNeuralNetworksNeuralNetworks ～ 　 朱 文革 广义 小 波 变换 及其 在 人工神经网络 中 的 应用 ， 应用 数学 学报 ， ， 　 罗忠 ， 谢永斌 ， 朱 重光 CMAC 学习 过程 收敛性 研究 ， 自动化 学报 ， ， ： ～ 　 蔚 承建 ， 姚 更生 更生 ， 何振亚 改进 的 进化 计算 及其 应用 ， 自动化 学报 ， ， ： 　 　 ～ 　 张讲社 ， 徐宗本 ， 梁怡 整体 退火 遗传算法 及其 收敛 充要条件 ， 中国 科学 E 辑 ， ， 　 　 　 ： ～ 　 HertzJetalIntroductiontoTheoryofNeuralComputionSantFeeComplexity 　 　 ScienceSeries 　 AnthonyMBiggsNComputationalLearningTheoryCombridgeUniversityPress 　 　 　 阎 平凡 人工神经网络 的 容量 、 学习 与 计算 复杂性 ， 电子学 报 ， ， ： ～ 　 钟义信 ， 杨义 先 中国 神经网络 首届 学术 大会 论文集 ， 北京 ， 　 焦 李成 神经网络 计算 ， 西安电子科技大学 出版社 ， 　 史忠植 神经计算 ， 电子 工业 出版社 ， 收稿 日期 ：